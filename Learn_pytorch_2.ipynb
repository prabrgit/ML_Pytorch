{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/mrdbourke/pytorch-deep-learning/blob/main/02_pytorch_classification.ipynb"
      ],
      "metadata": {
        "id": "fKkAYhHuwXrX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nXgFtCYyEpV"
      },
      "outputs": [],
      "source": [
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "X, y = make_circles(n_samples,\n",
        "                    noise=0.03,\n",
        "                    random_state=12)"
      ],
      "metadata": {
        "id": "eTQ8Niffwf0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guLguedTw5u_",
        "outputId": "af634d46-62bf-44dc-ff62-b2fa9cdb6616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5],y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lif05SGMw8iV",
        "outputId": "015420e5-adc9-49ca-b50a-46ed780fd7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.76285419,  0.21290457],\n",
              "        [-0.01353444, -0.7827793 ],\n",
              "        [-0.67886261, -0.42597787],\n",
              "        [-1.00609936, -0.32508754],\n",
              "        [-0.58527996, -0.79164499]]),\n",
              " array([1, 1, 1, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "circles = pd.DataFrame({\"X1\": X[:, 0],\n",
        "                        \"X2\": X[:,1],\n",
        "                        \"label\":y})\n",
        "circles.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-EP52RMOw-dU",
        "outputId": "e3ec690e-154e-4e3f-af84-9cc6f1955e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         X1        X2  label\n",
              "0  0.762854  0.212905      1\n",
              "1 -0.013534 -0.782779      1\n",
              "2 -0.678863 -0.425978      1\n",
              "3 -1.006099 -0.325088      0\n",
              "4 -0.585280 -0.791645      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95ba65b4-e0bb-4344-90df-3afc70b79c35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.762854</td>\n",
              "      <td>0.212905</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.013534</td>\n",
              "      <td>-0.782779</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.678863</td>\n",
              "      <td>-0.425978</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.006099</td>\n",
              "      <td>-0.325088</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.585280</td>\n",
              "      <td>-0.791645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95ba65b4-e0bb-4344-90df-3afc70b79c35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95ba65b4-e0bb-4344-90df-3afc70b79c35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95ba65b4-e0bb-4344-90df-3afc70b79c35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x=X[:,0],\n",
        "            y=X[:,1],\n",
        "            c=y,\n",
        "            cmap=plt.cm.RdYlBu);\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "TImR5SKUyKY0",
        "outputId": "fc6b07a9-066b-4022-c3af-51b211dc12e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check input and output shapes**"
      ],
      "metadata": {
        "id": "vqck4xyYz-J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW3H61Epy5eZ",
        "outputId": "27012ebe-1506-4b74-a1e5-fbd78f1b29b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 2), (1000,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_sample = X[0]\n",
        "y_sample = y[0]\n",
        "print(X_sample,y_sample)\n",
        "print(X_sample.shape,y_sample.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "209QDVDO0Hf-",
        "outputId": "7b8a21fd-d7c1-429e-f4d2-57ec642ad49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.76285419 0.21290457] 1\n",
            "(2,) ()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Turn data into tensors and split**"
      ],
      "metadata": {
        "id": "kNc_nTQK0yIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1jjUrOl705u2",
        "outputId": "b9c09eda-0f83-43f4-ef42-b804fef735cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYdi-m_y1mnj",
        "outputId": "5a271bb4-f992-4fa1-d576-78ff9e7b8a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.float)\n",
        "X[:5],y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dc4mmNJ05rZ",
        "outputId": "f3d5730a-5fe4-4e91-ce30-aa0a5873cb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.7629,  0.2129],\n",
              "         [-0.0135, -0.7828],\n",
              "         [-0.6789, -0.4260],\n",
              "         [-1.0061, -0.3251],\n",
              "         [-0.5853, -0.7916]]),\n",
              " tensor([1., 1., 1., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test =train_test_split(X,\n",
        "                                                   y,\n",
        "                                                   test_size=0.2,\n",
        "                                                   random_state=12)"
      ],
      "metadata": {
        "id": "g6_s29L_05oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train),len(X_test),len(y_train),len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVqTkX_-05kx",
        "outputId": "931311ca-eea6-42a8-a08f-95ac32ca7ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 200, 800, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1N08eY9T05hW",
        "outputId": "0b1ae5ff-c5da-4ba4-9773-e43fab5f8273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CircleModelV1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_1 = nn.Linear(in_features=2,\n",
        "                             out_features=15)\n",
        "    self.layer_2 = nn.Linear(in_features=15,\n",
        "                             out_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_2(self.layer_1(x))   #x -> layer1 -> layer_2 ->o/p\n",
        "\n",
        "model_0 = CircleModelV1().to(device)\n",
        "model_0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHXvvkJ132om",
        "outputId": "b8970f94-9561-4469-f080-e65a2b9b24e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CircleModelV1(\n",
              "  (layer_1): Linear(in_features=2, out_features=15, bias=True)\n",
              "  (layer_2): Linear(in_features=15, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_0.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9ZfsQHg6Zze",
        "outputId": "19b6dde2-6734-4507-ed3c-926693988a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model_1 = nn.Sequential(\n",
        "    nn.Linear(in_features=2, out_features=100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=100, out_features=100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=100, out_features=1)\n",
        " ).to(device)\n",
        "\n",
        " model_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf5twS9g6xHY",
        "outputId": "85146902-45c1-4702-c7f2-b461332496a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=100, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6y9aKn_Dx8V",
        "outputId": "10704549-1ea6-4231-cccf-048ae7d847f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_1.weight',\n",
              "              tensor([[ 0.5630,  0.1557],\n",
              "                      [-0.3732,  0.3296],\n",
              "                      [-0.6820, -0.0541],\n",
              "                      [ 0.6615, -0.0093],\n",
              "                      [-0.3063,  0.0671],\n",
              "                      [-0.4310,  0.0996],\n",
              "                      [ 0.1915, -0.3744],\n",
              "                      [ 0.2039,  0.2313],\n",
              "                      [ 0.3475, -0.0937],\n",
              "                      [ 0.3850,  0.6590],\n",
              "                      [-0.0975,  0.6543],\n",
              "                      [ 0.1090,  0.6970],\n",
              "                      [-0.3497, -0.2104],\n",
              "                      [ 0.0856,  0.4703],\n",
              "                      [-0.4532, -0.1831]], device='cuda:0')),\n",
              "             ('layer_1.bias',\n",
              "              tensor([ 0.0209,  0.3330, -0.1544,  0.1171, -0.6829, -0.6044,  0.7007,  0.6392,\n",
              "                      -0.0213, -0.5446,  0.4116, -0.4558, -0.1267,  0.2987, -0.2217],\n",
              "                     device='cuda:0')),\n",
              "             ('layer_2.weight',\n",
              "              tensor([[ 0.2387, -0.1931, -0.2068, -0.0119,  0.1299, -0.0810,  0.0401,  0.1167,\n",
              "                        0.2199, -0.0999,  0.2181, -0.2537, -0.0450, -0.0060, -0.2325]],\n",
              "                     device='cuda:0')),\n",
              "             ('layer_2.bias', tensor([-0.1307], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe2ON3f1Ej8W",
        "outputId": "b11c78e2-c311-4091-87cb-7da68b7f5391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight',\n",
              "              tensor([[ 0.3757, -0.0560],\n",
              "                      [ 0.3375,  0.3291],\n",
              "                      [ 0.1284, -0.3707],\n",
              "                      [-0.5687,  0.1324],\n",
              "                      [ 0.2421,  0.4667],\n",
              "                      [-0.5710, -0.3764],\n",
              "                      [ 0.4046, -0.0354],\n",
              "                      [ 0.4886, -0.2099],\n",
              "                      [ 0.3068, -0.1514],\n",
              "                      [-0.3919, -0.1513],\n",
              "                      [-0.5589,  0.3202],\n",
              "                      [-0.3377,  0.0154],\n",
              "                      [ 0.4170, -0.4664],\n",
              "                      [ 0.3992, -0.4528],\n",
              "                      [ 0.5906, -0.6692],\n",
              "                      [ 0.1370, -0.2934],\n",
              "                      [-0.3980,  0.2739],\n",
              "                      [-0.0175, -0.5866],\n",
              "                      [ 0.1830,  0.4356],\n",
              "                      [ 0.3993,  0.6142],\n",
              "                      [-0.2280,  0.6314],\n",
              "                      [-0.6518,  0.3964],\n",
              "                      [ 0.5533, -0.5539],\n",
              "                      [-0.0624, -0.3246],\n",
              "                      [-0.3622, -0.2994],\n",
              "                      [-0.3355, -0.1998],\n",
              "                      [ 0.4101, -0.1996],\n",
              "                      [ 0.3872, -0.4848],\n",
              "                      [-0.1349, -0.3024],\n",
              "                      [ 0.4486,  0.3557],\n",
              "                      [ 0.0352,  0.1121],\n",
              "                      [ 0.6834,  0.6283],\n",
              "                      [-0.6913,  0.4013],\n",
              "                      [-0.6656, -0.4961],\n",
              "                      [ 0.1507,  0.4077],\n",
              "                      [ 0.1753, -0.0441],\n",
              "                      [-0.2302,  0.3044],\n",
              "                      [ 0.2464,  0.1622],\n",
              "                      [ 0.1215, -0.2727],\n",
              "                      [-0.4066,  0.3528],\n",
              "                      [-0.2149, -0.4355],\n",
              "                      [-0.1975, -0.0541],\n",
              "                      [-0.6401, -0.3221],\n",
              "                      [-0.5336,  0.6083],\n",
              "                      [-0.0288, -0.3931],\n",
              "                      [ 0.1459,  0.4760],\n",
              "                      [ 0.6882,  0.4380],\n",
              "                      [ 0.2892, -0.1846],\n",
              "                      [-0.3679, -0.1170],\n",
              "                      [ 0.0773, -0.2736],\n",
              "                      [ 0.3268, -0.4798],\n",
              "                      [-0.6503,  0.6025],\n",
              "                      [ 0.5767,  0.6052],\n",
              "                      [-0.5102,  0.3515],\n",
              "                      [-0.1901, -0.2739],\n",
              "                      [-0.3086, -0.5675],\n",
              "                      [ 0.1179, -0.2997],\n",
              "                      [-0.1080, -0.4035],\n",
              "                      [-0.2542, -0.4712],\n",
              "                      [ 0.5031,  0.6011],\n",
              "                      [-0.1628,  0.1421],\n",
              "                      [-0.2795,  0.3783],\n",
              "                      [-0.5622, -0.0528],\n",
              "                      [-0.4501, -0.1190],\n",
              "                      [-0.4974, -0.3854],\n",
              "                      [-0.5573, -0.6771],\n",
              "                      [-0.4055, -0.2089],\n",
              "                      [ 0.4076, -0.5246],\n",
              "                      [-0.5577, -0.0615],\n",
              "                      [ 0.3812, -0.0039],\n",
              "                      [-0.4136,  0.2386],\n",
              "                      [ 0.2173, -0.2475],\n",
              "                      [ 0.3004, -0.2186],\n",
              "                      [-0.5684, -0.4108],\n",
              "                      [ 0.5712, -0.5426],\n",
              "                      [-0.3523, -0.5590],\n",
              "                      [ 0.0072,  0.6540],\n",
              "                      [-0.3293,  0.1677],\n",
              "                      [ 0.6976, -0.6758],\n",
              "                      [-0.6386,  0.0013],\n",
              "                      [-0.2331, -0.3914],\n",
              "                      [ 0.5739,  0.3310],\n",
              "                      [ 0.1362, -0.1135],\n",
              "                      [ 0.4926,  0.4985],\n",
              "                      [ 0.1635,  0.3707],\n",
              "                      [-0.6980,  0.6023],\n",
              "                      [-0.4202, -0.5578],\n",
              "                      [-0.6561, -0.5956],\n",
              "                      [ 0.5799, -0.4798],\n",
              "                      [ 0.4301,  0.3269],\n",
              "                      [-0.6978,  0.3891],\n",
              "                      [ 0.1648, -0.1303],\n",
              "                      [-0.0810,  0.3809],\n",
              "                      [ 0.0864,  0.0194],\n",
              "                      [-0.2720,  0.0294],\n",
              "                      [-0.0785, -0.2848],\n",
              "                      [ 0.4232,  0.6129],\n",
              "                      [-0.3603,  0.5347],\n",
              "                      [-0.1396,  0.2689],\n",
              "                      [-0.3282, -0.0443]], device='cuda:0')),\n",
              "             ('0.bias',\n",
              "              tensor([-0.0992, -0.7062,  0.6558, -0.0053, -0.3675,  0.0492,  0.1020,  0.2959,\n",
              "                      -0.4530,  0.0446, -0.3289,  0.6484,  0.0401, -0.6376, -0.1985, -0.1390,\n",
              "                      -0.4902, -0.6408, -0.6394, -0.6562,  0.3068, -0.5459,  0.6114, -0.5624,\n",
              "                      -0.7048, -0.1125, -0.5448, -0.4687, -0.6878,  0.1587, -0.2164,  0.6974,\n",
              "                      -0.0857,  0.6513,  0.7023,  0.4315,  0.2380,  0.1024,  0.6597,  0.1325,\n",
              "                       0.0595,  0.5478, -0.2290, -0.4174, -0.1895,  0.3178,  0.0637, -0.4881,\n",
              "                      -0.4586,  0.4033,  0.4675,  0.1907, -0.0169, -0.2787,  0.4208, -0.2124,\n",
              "                      -0.5013,  0.5295, -0.5933,  0.0710, -0.6869,  0.2468, -0.4366, -0.3785,\n",
              "                       0.4948,  0.6298, -0.4414,  0.6492,  0.3696,  0.3025,  0.5108,  0.6201,\n",
              "                      -0.2586, -0.0066, -0.4987, -0.2129,  0.5281,  0.3668, -0.0133, -0.5842,\n",
              "                      -0.1128, -0.5619, -0.1953, -0.1497, -0.0059, -0.2332, -0.6667,  0.1118,\n",
              "                      -0.0875,  0.5162, -0.6811, -0.2955,  0.6908,  0.2551,  0.5152,  0.3606,\n",
              "                      -0.6650,  0.6976, -0.5463,  0.0070], device='cuda:0')),\n",
              "             ('2.weight',\n",
              "              tensor([[-0.0643,  0.0236,  0.0148,  ...,  0.0883,  0.0502, -0.0005],\n",
              "                      [-0.0281,  0.0609, -0.0623,  ..., -0.0158, -0.0774, -0.0911],\n",
              "                      [-0.0249,  0.0376,  0.0215,  ..., -0.0026,  0.0574, -0.0863],\n",
              "                      ...,\n",
              "                      [-0.0837, -0.0554,  0.0611,  ..., -0.0465, -0.0144,  0.0736],\n",
              "                      [ 0.0736, -0.0552,  0.0796,  ...,  0.0255, -0.0675,  0.0872],\n",
              "                      [-0.0664,  0.0836,  0.0040,  ..., -0.0994, -0.0030,  0.0084]],\n",
              "                     device='cuda:0')),\n",
              "             ('2.bias',\n",
              "              tensor([-0.0629, -0.0905,  0.0882, -0.0706, -0.0957, -0.0209,  0.0547,  0.0571,\n",
              "                       0.0259,  0.0644, -0.0325,  0.0057,  0.0783,  0.0358,  0.0344, -0.0896,\n",
              "                      -0.0661,  0.0626,  0.0225, -0.0738, -0.0540,  0.0082, -0.0744,  0.0831,\n",
              "                       0.0846, -0.0872, -0.0919,  0.0858,  0.0069, -0.0586, -0.0911,  0.0425,\n",
              "                       0.0774, -0.0800,  0.0866, -0.0778, -0.0239, -0.0893, -0.0338, -0.0093,\n",
              "                      -0.0131, -0.0298, -0.0424, -0.0317, -0.0649,  0.0728, -0.0748, -0.0073,\n",
              "                      -0.0721, -0.0319, -0.0853,  0.0402, -0.0648,  0.0816,  0.0650, -0.0817,\n",
              "                       0.0787,  0.0227, -0.0334,  0.0322,  0.0450,  0.0463,  0.0356, -0.0923,\n",
              "                      -0.0527,  0.0617,  0.0471, -0.0093, -0.0579,  0.0549, -0.0676,  0.0090,\n",
              "                      -0.0032, -0.0095,  0.0704, -0.0159, -0.0406,  0.0237,  0.0443, -0.0381,\n",
              "                      -0.0229,  0.0751, -0.0108, -0.0130, -0.0763,  0.0093, -0.0137,  0.0997,\n",
              "                       0.0960,  0.0614,  0.0399, -0.0570,  0.0616,  0.0327, -0.0364, -0.0170,\n",
              "                       0.0857,  0.0843,  0.0126,  0.0259], device='cuda:0')),\n",
              "             ('4.weight',\n",
              "              tensor([[ 0.0331,  0.0107, -0.0871, -0.0112,  0.0332,  0.0211, -0.0232, -0.0993,\n",
              "                        0.0757,  0.0501,  0.0028, -0.0426, -0.0456, -0.0695, -0.0098,  0.0551,\n",
              "                       -0.0185, -0.0735,  0.0609, -0.0438,  0.0161,  0.0667, -0.0132, -0.0868,\n",
              "                       -0.0250, -0.0345, -0.0044,  0.0519,  0.0672,  0.0839,  0.0995,  0.0794,\n",
              "                        0.0512,  0.0578, -0.0544,  0.0468,  0.0514, -0.0981, -0.0796,  0.0548,\n",
              "                       -0.0217,  0.0657,  0.0842, -0.0293,  0.0741,  0.0791,  0.0240, -0.0511,\n",
              "                        0.0945,  0.0729, -0.0377,  0.0860, -0.0439,  0.0766, -0.0283,  0.0289,\n",
              "                       -0.0429,  0.0284,  0.0813, -0.0996,  0.0751,  0.0432,  0.0875, -0.0377,\n",
              "                       -0.0194, -0.0800,  0.0648, -0.0131,  0.0930,  0.0496, -0.0125, -0.0913,\n",
              "                        0.0837, -0.0630, -0.0332, -0.0792, -0.0396,  0.0203, -0.0994, -0.0727,\n",
              "                       -0.0760,  0.0201,  0.0933, -0.0623,  0.0709, -0.0189,  0.0471, -0.0529,\n",
              "                        0.0639, -0.0905, -0.0707, -0.0357,  0.0704,  0.0420, -0.0196,  0.0129,\n",
              "                       -0.0472, -0.0489,  0.0730, -0.0485]], device='cuda:0')),\n",
              "             ('4.bias', tensor([0.0846], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr = 0.1)"
      ],
      "metadata": {
        "id": "J5NJ-T1hErGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) * 100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "j-dxr5_kIGdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train model**"
      ],
      "metadata": {
        "id": "ioXgP5J32MIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0"
      ],
      "metadata": {
        "id": "AXq3eJ-cIpye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7700d05-f5af-44a8-d23f-7419a4188654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CircleModelV1(\n",
              "  (layer_1): Linear(in_features=2, out_features=15, bias=True)\n",
              "  (layer_2): Linear(in_features=15, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_logits = model_0(X_test.to(device))[:5]\n",
        "y_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf57Rend2yA2",
        "outputId": "a7b00ef6-c04f-464e-8055-d5c3de43ac37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1722],\n",
              "        [ 0.4982],\n",
              "        [-0.2249],\n",
              "        [ 0.5831],\n",
              "        [ 0.5003]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lSG90E73gKi",
        "outputId": "a83ef609-7b88-4ef5-a4ae-89b41ae5360d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = torch.sigmoid(y_logits)\n",
        "y_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJtx0hhV4Qbh",
        "outputId": "372bde78-b8cd-4f8c-d0b1-21b51927a2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5430],\n",
              "        [0.6220],\n",
              "        [0.4440],\n",
              "        [0.6418],\n",
              "        [0.6225]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.round(y_pred_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hADszuW24fy9",
        "outputId": "ff17eccf-dc85-41fd-80eb-255c3740779e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels = torch.round(torch.sigmoid(model_0(X_test.to(device))[:5]))\n",
        "y_pred_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awxxyEU-4k0z",
        "outputId": "508b6a39-5171-4063-84c3-a1fda9b44d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.]], device='cuda:0', grad_fn=<RoundBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6cTYSw2q1H2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(12)\n",
        "epochs = 500\n",
        "\n",
        "X_train, y_train, X_test, y_test = X_train.to(device), y_train.to(device), X_test.to(device), y_test.to(device)\n",
        "\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "\n",
        "  y_logits = model_1(X_train).squeeze()\n",
        "  y_pred = torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "\n",
        "  #y_pred = model_0(X_train)\n",
        "\n",
        "  loss = loss_fn(y_logits, y_train)\n",
        "\n",
        "  acc = accuracy_fn(y_true = y_train,\n",
        "                    y_pred=y_pred)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_logits = model_1(X_test).squeeze()\n",
        "    test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "    test_loss = loss_fn(test_logits,\n",
        "                        y_test)\n",
        "    test_acc = accuracy_fn(y_true = y_test,\n",
        "                    y_pred=test_pred)\n",
        "    print(f\"Epoch: {epoch} | Train Loss: {loss} | Train Accuracy: {acc} | Test Loss: {test_loss} | Test Accuracy: {test_acc}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfUnfyYL5cRw",
        "outputId": "936caddb-aac8-4438-bbac-86aebd469e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 0.6955520510673523 | Train Accuracy: 51.5 | Test Loss: 0.6969063878059387 | Test Accuracy: 53.0\n",
            "Epoch: 1 | Train Loss: 0.6948257088661194 | Train Accuracy: 53.37499999999999 | Test Loss: 0.6963618397712708 | Test Accuracy: 50.0\n",
            "Epoch: 2 | Train Loss: 0.6942210793495178 | Train Accuracy: 52.87500000000001 | Test Loss: 0.695903480052948 | Test Accuracy: 51.0\n",
            "Epoch: 3 | Train Loss: 0.6937206387519836 | Train Accuracy: 52.0 | Test Loss: 0.6955087184906006 | Test Accuracy: 53.0\n",
            "Epoch: 4 | Train Loss: 0.6932892203330994 | Train Accuracy: 51.37500000000001 | Test Loss: 0.6951615214347839 | Test Accuracy: 53.0\n",
            "Epoch: 5 | Train Loss: 0.6929063200950623 | Train Accuracy: 51.37500000000001 | Test Loss: 0.6948530673980713 | Test Accuracy: 51.5\n",
            "Epoch: 6 | Train Loss: 0.6925635933876038 | Train Accuracy: 51.5 | Test Loss: 0.6945694088935852 | Test Accuracy: 50.5\n",
            "Epoch: 7 | Train Loss: 0.6922498941421509 | Train Accuracy: 52.75 | Test Loss: 0.6943021416664124 | Test Accuracy: 49.0\n",
            "Epoch: 8 | Train Loss: 0.6919540166854858 | Train Accuracy: 52.5 | Test Loss: 0.6940433979034424 | Test Accuracy: 48.5\n",
            "Epoch: 9 | Train Loss: 0.6916709542274475 | Train Accuracy: 52.25 | Test Loss: 0.6937889456748962 | Test Accuracy: 49.0\n",
            "Epoch: 10 | Train Loss: 0.6913989186286926 | Train Accuracy: 51.87500000000001 | Test Loss: 0.6935514807701111 | Test Accuracy: 50.0\n",
            "Epoch: 11 | Train Loss: 0.6911389827728271 | Train Accuracy: 52.37500000000001 | Test Loss: 0.6933282613754272 | Test Accuracy: 50.0\n",
            "Epoch: 12 | Train Loss: 0.6908904910087585 | Train Accuracy: 52.87500000000001 | Test Loss: 0.6931174397468567 | Test Accuracy: 50.5\n",
            "Epoch: 13 | Train Loss: 0.690650463104248 | Train Accuracy: 53.25 | Test Loss: 0.6929106116294861 | Test Accuracy: 52.0\n",
            "Epoch: 14 | Train Loss: 0.6904171705245972 | Train Accuracy: 53.25 | Test Loss: 0.6927090287208557 | Test Accuracy: 52.0\n",
            "Epoch: 15 | Train Loss: 0.6901929378509521 | Train Accuracy: 53.75 | Test Loss: 0.6925210356712341 | Test Accuracy: 48.5\n",
            "Epoch: 16 | Train Loss: 0.6899795532226562 | Train Accuracy: 53.37499999999999 | Test Loss: 0.6923402547836304 | Test Accuracy: 48.5\n",
            "Epoch: 17 | Train Loss: 0.6897718906402588 | Train Accuracy: 53.5 | Test Loss: 0.6921611428260803 | Test Accuracy: 48.5\n",
            "Epoch: 18 | Train Loss: 0.6895683407783508 | Train Accuracy: 53.87499999999999 | Test Loss: 0.691985011100769 | Test Accuracy: 47.5\n",
            "Epoch: 19 | Train Loss: 0.6893644332885742 | Train Accuracy: 54.37499999999999 | Test Loss: 0.6918126344680786 | Test Accuracy: 47.5\n",
            "Epoch: 20 | Train Loss: 0.6891630291938782 | Train Accuracy: 53.75 | Test Loss: 0.691650390625 | Test Accuracy: 46.5\n",
            "Epoch: 21 | Train Loss: 0.6889697313308716 | Train Accuracy: 54.125 | Test Loss: 0.691494345664978 | Test Accuracy: 46.5\n",
            "Epoch: 22 | Train Loss: 0.6887801885604858 | Train Accuracy: 54.0 | Test Loss: 0.6913416385650635 | Test Accuracy: 47.5\n",
            "Epoch: 23 | Train Loss: 0.688595175743103 | Train Accuracy: 54.0 | Test Loss: 0.6911918520927429 | Test Accuracy: 48.0\n",
            "Epoch: 24 | Train Loss: 0.6884158253669739 | Train Accuracy: 54.37499999999999 | Test Loss: 0.691045880317688 | Test Accuracy: 50.0\n",
            "Epoch: 25 | Train Loss: 0.6882423162460327 | Train Accuracy: 54.37499999999999 | Test Loss: 0.6909022331237793 | Test Accuracy: 51.0\n",
            "Epoch: 26 | Train Loss: 0.6880694627761841 | Train Accuracy: 54.50000000000001 | Test Loss: 0.6907598972320557 | Test Accuracy: 49.5\n",
            "Epoch: 27 | Train Loss: 0.6878994703292847 | Train Accuracy: 54.50000000000001 | Test Loss: 0.6906179785728455 | Test Accuracy: 50.0\n",
            "Epoch: 28 | Train Loss: 0.6877321600914001 | Train Accuracy: 54.25 | Test Loss: 0.6904771327972412 | Test Accuracy: 50.0\n",
            "Epoch: 29 | Train Loss: 0.6875668168067932 | Train Accuracy: 54.75 | Test Loss: 0.6903384327888489 | Test Accuracy: 50.0\n",
            "Epoch: 30 | Train Loss: 0.6874029636383057 | Train Accuracy: 55.25 | Test Loss: 0.6901991367340088 | Test Accuracy: 50.0\n",
            "Epoch: 31 | Train Loss: 0.6872398853302002 | Train Accuracy: 55.375 | Test Loss: 0.6900582909584045 | Test Accuracy: 49.5\n",
            "Epoch: 32 | Train Loss: 0.6870760917663574 | Train Accuracy: 55.375 | Test Loss: 0.6899174451828003 | Test Accuracy: 49.5\n",
            "Epoch: 33 | Train Loss: 0.6869133114814758 | Train Accuracy: 55.625 | Test Loss: 0.6897774934768677 | Test Accuracy: 49.5\n",
            "Epoch: 34 | Train Loss: 0.6867523193359375 | Train Accuracy: 55.625 | Test Loss: 0.6896379590034485 | Test Accuracy: 50.0\n",
            "Epoch: 35 | Train Loss: 0.6865921020507812 | Train Accuracy: 55.50000000000001 | Test Loss: 0.6894969940185547 | Test Accuracy: 50.0\n",
            "Epoch: 36 | Train Loss: 0.6864319443702698 | Train Accuracy: 55.75 | Test Loss: 0.6893560886383057 | Test Accuracy: 49.5\n",
            "Epoch: 37 | Train Loss: 0.6862711906433105 | Train Accuracy: 55.75 | Test Loss: 0.6892149448394775 | Test Accuracy: 49.5\n",
            "Epoch: 38 | Train Loss: 0.6861101984977722 | Train Accuracy: 56.00000000000001 | Test Loss: 0.6890736222267151 | Test Accuracy: 50.5\n",
            "Epoch: 39 | Train Loss: 0.68594890832901 | Train Accuracy: 56.125 | Test Loss: 0.688932478427887 | Test Accuracy: 50.5\n",
            "Epoch: 40 | Train Loss: 0.6857869029045105 | Train Accuracy: 56.375 | Test Loss: 0.6887907385826111 | Test Accuracy: 50.5\n",
            "Epoch: 41 | Train Loss: 0.6856240630149841 | Train Accuracy: 56.49999999999999 | Test Loss: 0.688646674156189 | Test Accuracy: 50.5\n",
            "Epoch: 42 | Train Loss: 0.6854600310325623 | Train Accuracy: 56.75 | Test Loss: 0.6885020136833191 | Test Accuracy: 50.0\n",
            "Epoch: 43 | Train Loss: 0.6852954626083374 | Train Accuracy: 56.99999999999999 | Test Loss: 0.6883566379547119 | Test Accuracy: 50.0\n",
            "Epoch: 44 | Train Loss: 0.6851310729980469 | Train Accuracy: 57.125 | Test Loss: 0.6882101893424988 | Test Accuracy: 50.0\n",
            "Epoch: 45 | Train Loss: 0.6849673390388489 | Train Accuracy: 57.375 | Test Loss: 0.6880613565444946 | Test Accuracy: 50.0\n",
            "Epoch: 46 | Train Loss: 0.6848027110099792 | Train Accuracy: 57.49999999999999 | Test Loss: 0.6879117488861084 | Test Accuracy: 50.0\n",
            "Epoch: 47 | Train Loss: 0.6846373677253723 | Train Accuracy: 57.75 | Test Loss: 0.6877611875534058 | Test Accuracy: 50.0\n",
            "Epoch: 48 | Train Loss: 0.6844708323478699 | Train Accuracy: 58.25 | Test Loss: 0.6876110434532166 | Test Accuracy: 50.0\n",
            "Epoch: 49 | Train Loss: 0.6843046545982361 | Train Accuracy: 58.25 | Test Loss: 0.6874619722366333 | Test Accuracy: 50.0\n",
            "Epoch: 50 | Train Loss: 0.6841391324996948 | Train Accuracy: 58.375 | Test Loss: 0.6873127818107605 | Test Accuracy: 50.0\n",
            "Epoch: 51 | Train Loss: 0.6839739680290222 | Train Accuracy: 58.5 | Test Loss: 0.6871635317802429 | Test Accuracy: 49.5\n",
            "Epoch: 52 | Train Loss: 0.6838087439537048 | Train Accuracy: 58.5 | Test Loss: 0.6870144605636597 | Test Accuracy: 50.0\n",
            "Epoch: 53 | Train Loss: 0.6836432218551636 | Train Accuracy: 58.375 | Test Loss: 0.6868658065795898 | Test Accuracy: 50.0\n",
            "Epoch: 54 | Train Loss: 0.6834771037101746 | Train Accuracy: 58.375 | Test Loss: 0.6867156624794006 | Test Accuracy: 50.0\n",
            "Epoch: 55 | Train Loss: 0.6833100914955139 | Train Accuracy: 58.375 | Test Loss: 0.6865651607513428 | Test Accuracy: 50.0\n",
            "Epoch: 56 | Train Loss: 0.6831420063972473 | Train Accuracy: 58.5 | Test Loss: 0.6864132285118103 | Test Accuracy: 50.0\n",
            "Epoch: 57 | Train Loss: 0.6829725503921509 | Train Accuracy: 58.5 | Test Loss: 0.6862597465515137 | Test Accuracy: 50.0\n",
            "Epoch: 58 | Train Loss: 0.6828022599220276 | Train Accuracy: 58.5 | Test Loss: 0.6861051917076111 | Test Accuracy: 50.0\n",
            "Epoch: 59 | Train Loss: 0.6826305985450745 | Train Accuracy: 58.5 | Test Loss: 0.6859502792358398 | Test Accuracy: 50.0\n",
            "Epoch: 60 | Train Loss: 0.6824576258659363 | Train Accuracy: 58.875 | Test Loss: 0.6857945919036865 | Test Accuracy: 50.5\n",
            "Epoch: 61 | Train Loss: 0.6822836399078369 | Train Accuracy: 59.12500000000001 | Test Loss: 0.6856370568275452 | Test Accuracy: 50.5\n",
            "Epoch: 62 | Train Loss: 0.6821082234382629 | Train Accuracy: 59.25 | Test Loss: 0.6854774951934814 | Test Accuracy: 51.0\n",
            "Epoch: 63 | Train Loss: 0.6819318532943726 | Train Accuracy: 59.375 | Test Loss: 0.685318112373352 | Test Accuracy: 51.0\n",
            "Epoch: 64 | Train Loss: 0.6817536950111389 | Train Accuracy: 59.375 | Test Loss: 0.685157299041748 | Test Accuracy: 51.0\n",
            "Epoch: 65 | Train Loss: 0.6815736889839172 | Train Accuracy: 59.375 | Test Loss: 0.684995174407959 | Test Accuracy: 51.0\n",
            "Epoch: 66 | Train Loss: 0.6813914179801941 | Train Accuracy: 59.375 | Test Loss: 0.684831976890564 | Test Accuracy: 51.0\n",
            "Epoch: 67 | Train Loss: 0.6812070608139038 | Train Accuracy: 59.5 | Test Loss: 0.6846662759780884 | Test Accuracy: 51.0\n",
            "Epoch: 68 | Train Loss: 0.6810196042060852 | Train Accuracy: 60.0 | Test Loss: 0.6844964623451233 | Test Accuracy: 51.0\n",
            "Epoch: 69 | Train Loss: 0.6808270812034607 | Train Accuracy: 60.25 | Test Loss: 0.6843324303627014 | Test Accuracy: 51.5\n",
            "Epoch: 70 | Train Loss: 0.6806434988975525 | Train Accuracy: 60.5 | Test Loss: 0.6841678619384766 | Test Accuracy: 51.5\n",
            "Epoch: 71 | Train Loss: 0.6804609298706055 | Train Accuracy: 60.5 | Test Loss: 0.6840023398399353 | Test Accuracy: 52.0\n",
            "Epoch: 72 | Train Loss: 0.6802778244018555 | Train Accuracy: 60.62499999999999 | Test Loss: 0.6838358640670776 | Test Accuracy: 52.0\n",
            "Epoch: 73 | Train Loss: 0.6800940632820129 | Train Accuracy: 60.75000000000001 | Test Loss: 0.6836681962013245 | Test Accuracy: 52.5\n",
            "Epoch: 74 | Train Loss: 0.6799095273017883 | Train Accuracy: 60.75000000000001 | Test Loss: 0.6834997534751892 | Test Accuracy: 52.5\n",
            "Epoch: 75 | Train Loss: 0.6797241568565369 | Train Accuracy: 60.875 | Test Loss: 0.6833303570747375 | Test Accuracy: 53.0\n",
            "Epoch: 76 | Train Loss: 0.6795376539230347 | Train Accuracy: 60.75000000000001 | Test Loss: 0.6831592321395874 | Test Accuracy: 53.5\n",
            "Epoch: 77 | Train Loss: 0.6793494820594788 | Train Accuracy: 60.875 | Test Loss: 0.6829875707626343 | Test Accuracy: 54.0\n",
            "Epoch: 78 | Train Loss: 0.6791602969169617 | Train Accuracy: 61.0 | Test Loss: 0.6828137040138245 | Test Accuracy: 54.0\n",
            "Epoch: 79 | Train Loss: 0.6789696216583252 | Train Accuracy: 61.25000000000001 | Test Loss: 0.6826395988464355 | Test Accuracy: 54.0\n",
            "Epoch: 80 | Train Loss: 0.6787780523300171 | Train Accuracy: 61.5 | Test Loss: 0.6824634671211243 | Test Accuracy: 54.0\n",
            "Epoch: 81 | Train Loss: 0.6785850524902344 | Train Accuracy: 61.5 | Test Loss: 0.6822862029075623 | Test Accuracy: 54.0\n",
            "Epoch: 82 | Train Loss: 0.6783905029296875 | Train Accuracy: 61.625 | Test Loss: 0.6821061372756958 | Test Accuracy: 54.0\n",
            "Epoch: 83 | Train Loss: 0.6781938076019287 | Train Accuracy: 61.75000000000001 | Test Loss: 0.68192458152771 | Test Accuracy: 54.50000000000001\n",
            "Epoch: 84 | Train Loss: 0.6779952645301819 | Train Accuracy: 61.75000000000001 | Test Loss: 0.6817403435707092 | Test Accuracy: 54.50000000000001\n",
            "Epoch: 85 | Train Loss: 0.6777955293655396 | Train Accuracy: 61.75000000000001 | Test Loss: 0.6815548539161682 | Test Accuracy: 54.50000000000001\n",
            "Epoch: 86 | Train Loss: 0.6775941252708435 | Train Accuracy: 61.75000000000001 | Test Loss: 0.6813673973083496 | Test Accuracy: 54.50000000000001\n",
            "Epoch: 87 | Train Loss: 0.6773899793624878 | Train Accuracy: 61.875 | Test Loss: 0.6811776757240295 | Test Accuracy: 54.50000000000001\n",
            "Epoch: 88 | Train Loss: 0.6771832704544067 | Train Accuracy: 62.0 | Test Loss: 0.680984377861023 | Test Accuracy: 55.00000000000001\n",
            "Epoch: 89 | Train Loss: 0.6769739985466003 | Train Accuracy: 62.0 | Test Loss: 0.6807893514633179 | Test Accuracy: 55.00000000000001\n",
            "Epoch: 90 | Train Loss: 0.676763117313385 | Train Accuracy: 62.0 | Test Loss: 0.6805930733680725 | Test Accuracy: 55.50000000000001\n",
            "Epoch: 91 | Train Loss: 0.6765501499176025 | Train Accuracy: 62.0 | Test Loss: 0.6803951859474182 | Test Accuracy: 55.50000000000001\n",
            "Epoch: 92 | Train Loss: 0.676334798336029 | Train Accuracy: 62.125 | Test Loss: 0.6801918148994446 | Test Accuracy: 56.00000000000001\n",
            "Epoch: 93 | Train Loss: 0.6761158108711243 | Train Accuracy: 62.25000000000001 | Test Loss: 0.6799854040145874 | Test Accuracy: 56.00000000000001\n",
            "Epoch: 94 | Train Loss: 0.6758947372436523 | Train Accuracy: 62.625 | Test Loss: 0.6797755360603333 | Test Accuracy: 56.49999999999999\n",
            "Epoch: 95 | Train Loss: 0.675670325756073 | Train Accuracy: 62.74999999999999 | Test Loss: 0.6795610785484314 | Test Accuracy: 56.49999999999999\n",
            "Epoch: 96 | Train Loss: 0.6754436492919922 | Train Accuracy: 63.0 | Test Loss: 0.6793466210365295 | Test Accuracy: 57.49999999999999\n",
            "Epoch: 97 | Train Loss: 0.6752150058746338 | Train Accuracy: 63.0 | Test Loss: 0.6791276931762695 | Test Accuracy: 57.99999999999999\n",
            "Epoch: 98 | Train Loss: 0.6749821901321411 | Train Accuracy: 63.125 | Test Loss: 0.6789069771766663 | Test Accuracy: 58.5\n",
            "Epoch: 99 | Train Loss: 0.6747463941574097 | Train Accuracy: 63.625 | Test Loss: 0.678685188293457 | Test Accuracy: 58.5\n",
            "Epoch: 100 | Train Loss: 0.6745072603225708 | Train Accuracy: 64.125 | Test Loss: 0.6784608364105225 | Test Accuracy: 58.5\n",
            "Epoch: 101 | Train Loss: 0.6742658019065857 | Train Accuracy: 64.375 | Test Loss: 0.678234338760376 | Test Accuracy: 58.5\n",
            "Epoch: 102 | Train Loss: 0.6740221977233887 | Train Accuracy: 64.375 | Test Loss: 0.6780094504356384 | Test Accuracy: 59.0\n",
            "Epoch: 103 | Train Loss: 0.6737785339355469 | Train Accuracy: 64.625 | Test Loss: 0.6777845621109009 | Test Accuracy: 59.0\n",
            "Epoch: 104 | Train Loss: 0.6735349893569946 | Train Accuracy: 64.625 | Test Loss: 0.6775606870651245 | Test Accuracy: 59.5\n",
            "Epoch: 105 | Train Loss: 0.6732916831970215 | Train Accuracy: 65.0 | Test Loss: 0.6773368716239929 | Test Accuracy: 59.5\n",
            "Epoch: 106 | Train Loss: 0.6730476021766663 | Train Accuracy: 65.5 | Test Loss: 0.6771145462989807 | Test Accuracy: 60.0\n",
            "Epoch: 107 | Train Loss: 0.6728039383888245 | Train Accuracy: 65.625 | Test Loss: 0.6768919825553894 | Test Accuracy: 60.0\n",
            "Epoch: 108 | Train Loss: 0.6725584864616394 | Train Accuracy: 65.75 | Test Loss: 0.6766691207885742 | Test Accuracy: 61.0\n",
            "Epoch: 109 | Train Loss: 0.6723119020462036 | Train Accuracy: 65.625 | Test Loss: 0.6764450669288635 | Test Accuracy: 61.0\n",
            "Epoch: 110 | Train Loss: 0.6720638275146484 | Train Accuracy: 65.75 | Test Loss: 0.6762192249298096 | Test Accuracy: 61.0\n",
            "Epoch: 111 | Train Loss: 0.67181396484375 | Train Accuracy: 65.875 | Test Loss: 0.6759946346282959 | Test Accuracy: 62.0\n",
            "Epoch: 112 | Train Loss: 0.6715642213821411 | Train Accuracy: 66.125 | Test Loss: 0.6757709980010986 | Test Accuracy: 62.0\n",
            "Epoch: 113 | Train Loss: 0.671312689781189 | Train Accuracy: 66.125 | Test Loss: 0.6755475997924805 | Test Accuracy: 62.5\n",
            "Epoch: 114 | Train Loss: 0.671059787273407 | Train Accuracy: 66.25 | Test Loss: 0.6753227114677429 | Test Accuracy: 62.5\n",
            "Epoch: 115 | Train Loss: 0.6708060503005981 | Train Accuracy: 66.375 | Test Loss: 0.6750959753990173 | Test Accuracy: 63.0\n",
            "Epoch: 116 | Train Loss: 0.6705504655838013 | Train Accuracy: 66.375 | Test Loss: 0.6748666763305664 | Test Accuracy: 63.5\n",
            "Epoch: 117 | Train Loss: 0.670292317867279 | Train Accuracy: 66.75 | Test Loss: 0.6746333837509155 | Test Accuracy: 64.0\n",
            "Epoch: 118 | Train Loss: 0.6700301766395569 | Train Accuracy: 66.75 | Test Loss: 0.6743985414505005 | Test Accuracy: 64.5\n",
            "Epoch: 119 | Train Loss: 0.6697648763656616 | Train Accuracy: 67.0 | Test Loss: 0.6741591691970825 | Test Accuracy: 64.5\n",
            "Epoch: 120 | Train Loss: 0.6694952845573425 | Train Accuracy: 67.25 | Test Loss: 0.6739172339439392 | Test Accuracy: 65.0\n",
            "Epoch: 121 | Train Loss: 0.6692228317260742 | Train Accuracy: 67.375 | Test Loss: 0.6736741662025452 | Test Accuracy: 65.5\n",
            "Epoch: 122 | Train Loss: 0.6689515709877014 | Train Accuracy: 67.75 | Test Loss: 0.673428475856781 | Test Accuracy: 66.0\n",
            "Epoch: 123 | Train Loss: 0.6686804294586182 | Train Accuracy: 68.0 | Test Loss: 0.6731809377670288 | Test Accuracy: 66.0\n",
            "Epoch: 124 | Train Loss: 0.6684072017669678 | Train Accuracy: 68.375 | Test Loss: 0.6729322671890259 | Test Accuracy: 67.0\n",
            "Epoch: 125 | Train Loss: 0.6681329011917114 | Train Accuracy: 68.875 | Test Loss: 0.6726813316345215 | Test Accuracy: 67.0\n",
            "Epoch: 126 | Train Loss: 0.6678564548492432 | Train Accuracy: 69.125 | Test Loss: 0.672428548336029 | Test Accuracy: 67.0\n",
            "Epoch: 127 | Train Loss: 0.6675776243209839 | Train Accuracy: 69.375 | Test Loss: 0.6721734404563904 | Test Accuracy: 67.0\n",
            "Epoch: 128 | Train Loss: 0.6672959923744202 | Train Accuracy: 70.0 | Test Loss: 0.6719157099723816 | Test Accuracy: 67.5\n",
            "Epoch: 129 | Train Loss: 0.6670112609863281 | Train Accuracy: 70.5 | Test Loss: 0.6716567277908325 | Test Accuracy: 67.5\n",
            "Epoch: 130 | Train Loss: 0.6667238473892212 | Train Accuracy: 71.0 | Test Loss: 0.6713953018188477 | Test Accuracy: 67.5\n",
            "Epoch: 131 | Train Loss: 0.6664338707923889 | Train Accuracy: 71.0 | Test Loss: 0.6711311340332031 | Test Accuracy: 67.5\n",
            "Epoch: 132 | Train Loss: 0.6661409139633179 | Train Accuracy: 71.125 | Test Loss: 0.6708639860153198 | Test Accuracy: 68.0\n",
            "Epoch: 133 | Train Loss: 0.665844738483429 | Train Accuracy: 71.625 | Test Loss: 0.6705930829048157 | Test Accuracy: 68.5\n",
            "Epoch: 134 | Train Loss: 0.6655443906784058 | Train Accuracy: 71.875 | Test Loss: 0.6703189015388489 | Test Accuracy: 69.5\n",
            "Epoch: 135 | Train Loss: 0.6652389168739319 | Train Accuracy: 72.375 | Test Loss: 0.6700395345687866 | Test Accuracy: 70.0\n",
            "Epoch: 136 | Train Loss: 0.664928674697876 | Train Accuracy: 72.875 | Test Loss: 0.6697575449943542 | Test Accuracy: 70.0\n",
            "Epoch: 137 | Train Loss: 0.6646155118942261 | Train Accuracy: 73.0 | Test Loss: 0.6694725155830383 | Test Accuracy: 70.0\n",
            "Epoch: 138 | Train Loss: 0.6642993092536926 | Train Accuracy: 73.375 | Test Loss: 0.6691843867301941 | Test Accuracy: 70.0\n",
            "Epoch: 139 | Train Loss: 0.6639814376831055 | Train Accuracy: 74.0 | Test Loss: 0.6688941717147827 | Test Accuracy: 70.0\n",
            "Epoch: 140 | Train Loss: 0.6636608839035034 | Train Accuracy: 74.125 | Test Loss: 0.6686034798622131 | Test Accuracy: 72.0\n",
            "Epoch: 141 | Train Loss: 0.663339376449585 | Train Accuracy: 74.5 | Test Loss: 0.668311357498169 | Test Accuracy: 72.0\n",
            "Epoch: 142 | Train Loss: 0.6630180478096008 | Train Accuracy: 74.625 | Test Loss: 0.6680169701576233 | Test Accuracy: 72.0\n",
            "Epoch: 143 | Train Loss: 0.6626953482627869 | Train Accuracy: 74.875 | Test Loss: 0.6677203178405762 | Test Accuracy: 72.5\n",
            "Epoch: 144 | Train Loss: 0.6623707413673401 | Train Accuracy: 75.0 | Test Loss: 0.6674222946166992 | Test Accuracy: 72.5\n",
            "Epoch: 145 | Train Loss: 0.662043571472168 | Train Accuracy: 75.625 | Test Loss: 0.6671231985092163 | Test Accuracy: 72.5\n",
            "Epoch: 146 | Train Loss: 0.6617140769958496 | Train Accuracy: 76.375 | Test Loss: 0.6668211221694946 | Test Accuracy: 73.0\n",
            "Epoch: 147 | Train Loss: 0.6613819599151611 | Train Accuracy: 76.625 | Test Loss: 0.6665170192718506 | Test Accuracy: 74.5\n",
            "Epoch: 148 | Train Loss: 0.6610479354858398 | Train Accuracy: 77.0 | Test Loss: 0.6662102937698364 | Test Accuracy: 74.5\n",
            "Epoch: 149 | Train Loss: 0.6607115268707275 | Train Accuracy: 77.625 | Test Loss: 0.6659015417098999 | Test Accuracy: 74.5\n",
            "Epoch: 150 | Train Loss: 0.6603724360466003 | Train Accuracy: 78.0 | Test Loss: 0.6655901670455933 | Test Accuracy: 74.5\n",
            "Epoch: 151 | Train Loss: 0.6600306630134583 | Train Accuracy: 78.125 | Test Loss: 0.6652766466140747 | Test Accuracy: 75.5\n",
            "Epoch: 152 | Train Loss: 0.6596857905387878 | Train Accuracy: 78.25 | Test Loss: 0.6649603247642517 | Test Accuracy: 76.0\n",
            "Epoch: 153 | Train Loss: 0.6593387722969055 | Train Accuracy: 78.5 | Test Loss: 0.6646393537521362 | Test Accuracy: 76.0\n",
            "Epoch: 154 | Train Loss: 0.6589892506599426 | Train Accuracy: 78.625 | Test Loss: 0.6643168330192566 | Test Accuracy: 76.0\n",
            "Epoch: 155 | Train Loss: 0.6586369276046753 | Train Accuracy: 79.25 | Test Loss: 0.663990318775177 | Test Accuracy: 76.0\n",
            "Epoch: 156 | Train Loss: 0.6582812070846558 | Train Accuracy: 80.0 | Test Loss: 0.6636608839035034 | Test Accuracy: 76.5\n",
            "Epoch: 157 | Train Loss: 0.6579222679138184 | Train Accuracy: 80.125 | Test Loss: 0.6633296012878418 | Test Accuracy: 77.5\n",
            "Epoch: 158 | Train Loss: 0.6575607061386108 | Train Accuracy: 80.5 | Test Loss: 0.6629946231842041 | Test Accuracy: 78.5\n",
            "Epoch: 159 | Train Loss: 0.6571964621543884 | Train Accuracy: 80.875 | Test Loss: 0.6626561880111694 | Test Accuracy: 78.5\n",
            "Epoch: 160 | Train Loss: 0.656829297542572 | Train Accuracy: 81.125 | Test Loss: 0.6623148322105408 | Test Accuracy: 78.5\n",
            "Epoch: 161 | Train Loss: 0.6564586758613586 | Train Accuracy: 81.625 | Test Loss: 0.6619700193405151 | Test Accuracy: 79.0\n",
            "Epoch: 162 | Train Loss: 0.6560847163200378 | Train Accuracy: 82.0 | Test Loss: 0.6616219878196716 | Test Accuracy: 79.5\n",
            "Epoch: 163 | Train Loss: 0.6557072401046753 | Train Accuracy: 83.0 | Test Loss: 0.6612722873687744 | Test Accuracy: 79.5\n",
            "Epoch: 164 | Train Loss: 0.6553266644477844 | Train Accuracy: 83.25 | Test Loss: 0.6609203219413757 | Test Accuracy: 80.0\n",
            "Epoch: 165 | Train Loss: 0.6549428701400757 | Train Accuracy: 83.375 | Test Loss: 0.660565197467804 | Test Accuracy: 80.0\n",
            "Epoch: 166 | Train Loss: 0.6545557975769043 | Train Accuracy: 83.5 | Test Loss: 0.6602062582969666 | Test Accuracy: 80.0\n",
            "Epoch: 167 | Train Loss: 0.654165506362915 | Train Accuracy: 83.875 | Test Loss: 0.6598434448242188 | Test Accuracy: 80.0\n",
            "Epoch: 168 | Train Loss: 0.6537720561027527 | Train Accuracy: 84.125 | Test Loss: 0.6594776511192322 | Test Accuracy: 80.0\n",
            "Epoch: 169 | Train Loss: 0.6533746123313904 | Train Accuracy: 84.875 | Test Loss: 0.6591078042984009 | Test Accuracy: 80.5\n",
            "Epoch: 170 | Train Loss: 0.6529735922813416 | Train Accuracy: 85.0 | Test Loss: 0.6587342619895935 | Test Accuracy: 81.5\n",
            "Epoch: 171 | Train Loss: 0.6525694131851196 | Train Accuracy: 85.375 | Test Loss: 0.6583561301231384 | Test Accuracy: 81.5\n",
            "Epoch: 172 | Train Loss: 0.6521614193916321 | Train Accuracy: 85.625 | Test Loss: 0.6579744815826416 | Test Accuracy: 81.5\n",
            "Epoch: 173 | Train Loss: 0.6517499685287476 | Train Accuracy: 85.875 | Test Loss: 0.6575871109962463 | Test Accuracy: 82.0\n",
            "Epoch: 174 | Train Loss: 0.6513343453407288 | Train Accuracy: 86.25 | Test Loss: 0.6571964621543884 | Test Accuracy: 82.5\n",
            "Epoch: 175 | Train Loss: 0.650915265083313 | Train Accuracy: 86.625 | Test Loss: 0.6568039059638977 | Test Accuracy: 82.5\n",
            "Epoch: 176 | Train Loss: 0.6504925489425659 | Train Accuracy: 87.125 | Test Loss: 0.6564056873321533 | Test Accuracy: 82.5\n",
            "Epoch: 177 | Train Loss: 0.6500657796859741 | Train Accuracy: 87.25 | Test Loss: 0.6560028195381165 | Test Accuracy: 82.5\n",
            "Epoch: 178 | Train Loss: 0.649634599685669 | Train Accuracy: 87.5 | Test Loss: 0.6555973887443542 | Test Accuracy: 83.5\n",
            "Epoch: 179 | Train Loss: 0.6491996049880981 | Train Accuracy: 87.75 | Test Loss: 0.6551870703697205 | Test Accuracy: 83.5\n",
            "Epoch: 180 | Train Loss: 0.6487604975700378 | Train Accuracy: 88.125 | Test Loss: 0.6547731161117554 | Test Accuracy: 84.5\n",
            "Epoch: 181 | Train Loss: 0.6483173966407776 | Train Accuracy: 88.625 | Test Loss: 0.654354989528656 | Test Accuracy: 84.5\n",
            "Epoch: 182 | Train Loss: 0.6478704810142517 | Train Accuracy: 88.875 | Test Loss: 0.6539334654808044 | Test Accuracy: 84.5\n",
            "Epoch: 183 | Train Loss: 0.647419273853302 | Train Accuracy: 88.875 | Test Loss: 0.6535067558288574 | Test Accuracy: 84.5\n",
            "Epoch: 184 | Train Loss: 0.6469636559486389 | Train Accuracy: 89.0 | Test Loss: 0.6530779600143433 | Test Accuracy: 85.0\n",
            "Epoch: 185 | Train Loss: 0.646503746509552 | Train Accuracy: 89.375 | Test Loss: 0.6526442766189575 | Test Accuracy: 85.0\n",
            "Epoch: 186 | Train Loss: 0.6460403203964233 | Train Accuracy: 89.375 | Test Loss: 0.6522064208984375 | Test Accuracy: 85.0\n",
            "Epoch: 187 | Train Loss: 0.645573079586029 | Train Accuracy: 89.375 | Test Loss: 0.6517671346664429 | Test Accuracy: 85.0\n",
            "Epoch: 188 | Train Loss: 0.6451014280319214 | Train Accuracy: 89.375 | Test Loss: 0.6513181924819946 | Test Accuracy: 85.0\n",
            "Epoch: 189 | Train Loss: 0.6446253657341003 | Train Accuracy: 89.375 | Test Loss: 0.6508669853210449 | Test Accuracy: 86.0\n",
            "Epoch: 190 | Train Loss: 0.6441446542739868 | Train Accuracy: 89.5 | Test Loss: 0.6504084467887878 | Test Accuracy: 86.0\n",
            "Epoch: 191 | Train Loss: 0.6436590552330017 | Train Accuracy: 89.875 | Test Loss: 0.6499473452568054 | Test Accuracy: 86.0\n",
            "Epoch: 192 | Train Loss: 0.6431694030761719 | Train Accuracy: 89.875 | Test Loss: 0.6494789719581604 | Test Accuracy: 86.5\n",
            "Epoch: 193 | Train Loss: 0.6426759362220764 | Train Accuracy: 90.0 | Test Loss: 0.6490075588226318 | Test Accuracy: 87.0\n",
            "Epoch: 194 | Train Loss: 0.642177939414978 | Train Accuracy: 90.0 | Test Loss: 0.6485308408737183 | Test Accuracy: 87.5\n",
            "Epoch: 195 | Train Loss: 0.6416752338409424 | Train Accuracy: 90.25 | Test Loss: 0.6480500102043152 | Test Accuracy: 87.5\n",
            "Epoch: 196 | Train Loss: 0.6411675214767456 | Train Accuracy: 90.375 | Test Loss: 0.6475655436515808 | Test Accuracy: 88.0\n",
            "Epoch: 197 | Train Loss: 0.6406551003456116 | Train Accuracy: 90.375 | Test Loss: 0.6470780968666077 | Test Accuracy: 88.0\n",
            "Epoch: 198 | Train Loss: 0.6401380896568298 | Train Accuracy: 90.375 | Test Loss: 0.6465864181518555 | Test Accuracy: 88.0\n",
            "Epoch: 199 | Train Loss: 0.6396161317825317 | Train Accuracy: 90.625 | Test Loss: 0.6460917592048645 | Test Accuracy: 88.5\n",
            "Epoch: 200 | Train Loss: 0.6390896439552307 | Train Accuracy: 90.625 | Test Loss: 0.6455920338630676 | Test Accuracy: 88.5\n",
            "Epoch: 201 | Train Loss: 0.6385588049888611 | Train Accuracy: 90.75 | Test Loss: 0.6450866460800171 | Test Accuracy: 89.5\n",
            "Epoch: 202 | Train Loss: 0.6380231380462646 | Train Accuracy: 90.875 | Test Loss: 0.6445741057395935 | Test Accuracy: 89.5\n",
            "Epoch: 203 | Train Loss: 0.6374824643135071 | Train Accuracy: 90.875 | Test Loss: 0.6440560817718506 | Test Accuracy: 89.5\n",
            "Epoch: 204 | Train Loss: 0.636935830116272 | Train Accuracy: 91.125 | Test Loss: 0.6435307264328003 | Test Accuracy: 89.5\n",
            "Epoch: 205 | Train Loss: 0.6363838315010071 | Train Accuracy: 91.125 | Test Loss: 0.6430010199546814 | Test Accuracy: 89.5\n",
            "Epoch: 206 | Train Loss: 0.6358261108398438 | Train Accuracy: 91.25 | Test Loss: 0.6424645781517029 | Test Accuracy: 89.5\n",
            "Epoch: 207 | Train Loss: 0.6352638006210327 | Train Accuracy: 91.25 | Test Loss: 0.6419219970703125 | Test Accuracy: 90.0\n",
            "Epoch: 208 | Train Loss: 0.6346970796585083 | Train Accuracy: 91.375 | Test Loss: 0.6413746476173401 | Test Accuracy: 90.0\n",
            "Epoch: 209 | Train Loss: 0.6341245174407959 | Train Accuracy: 91.5 | Test Loss: 0.6408201456069946 | Test Accuracy: 90.5\n",
            "Epoch: 210 | Train Loss: 0.6335464119911194 | Train Accuracy: 91.5 | Test Loss: 0.6402627229690552 | Test Accuracy: 91.0\n",
            "Epoch: 211 | Train Loss: 0.6329625248908997 | Train Accuracy: 91.5 | Test Loss: 0.6397005915641785 | Test Accuracy: 91.0\n",
            "Epoch: 212 | Train Loss: 0.6323727965354919 | Train Accuracy: 91.625 | Test Loss: 0.6391334533691406 | Test Accuracy: 91.0\n",
            "Epoch: 213 | Train Loss: 0.6317777037620544 | Train Accuracy: 91.75 | Test Loss: 0.6385613083839417 | Test Accuracy: 91.0\n",
            "Epoch: 214 | Train Loss: 0.6311774849891663 | Train Accuracy: 91.875 | Test Loss: 0.6379806995391846 | Test Accuracy: 91.0\n",
            "Epoch: 215 | Train Loss: 0.6305720210075378 | Train Accuracy: 92.0 | Test Loss: 0.637396514415741 | Test Accuracy: 91.0\n",
            "Epoch: 216 | Train Loss: 0.6299608945846558 | Train Accuracy: 92.125 | Test Loss: 0.6368088722229004 | Test Accuracy: 91.0\n",
            "Epoch: 217 | Train Loss: 0.6293440461158752 | Train Accuracy: 92.125 | Test Loss: 0.6362142562866211 | Test Accuracy: 91.0\n",
            "Epoch: 218 | Train Loss: 0.6287209987640381 | Train Accuracy: 92.125 | Test Loss: 0.6356117129325867 | Test Accuracy: 91.5\n",
            "Epoch: 219 | Train Loss: 0.6280925273895264 | Train Accuracy: 92.25 | Test Loss: 0.6350034475326538 | Test Accuracy: 92.0\n",
            "Epoch: 220 | Train Loss: 0.627458393573761 | Train Accuracy: 92.25 | Test Loss: 0.6343880295753479 | Test Accuracy: 92.0\n",
            "Epoch: 221 | Train Loss: 0.6268181204795837 | Train Accuracy: 92.625 | Test Loss: 0.6337662935256958 | Test Accuracy: 92.5\n",
            "Epoch: 222 | Train Loss: 0.626171350479126 | Train Accuracy: 92.75 | Test Loss: 0.6331380605697632 | Test Accuracy: 92.5\n",
            "Epoch: 223 | Train Loss: 0.6255185008049011 | Train Accuracy: 93.125 | Test Loss: 0.6325026750564575 | Test Accuracy: 92.5\n",
            "Epoch: 224 | Train Loss: 0.624859631061554 | Train Accuracy: 93.25 | Test Loss: 0.6318649053573608 | Test Accuracy: 92.5\n",
            "Epoch: 225 | Train Loss: 0.6241955757141113 | Train Accuracy: 93.375 | Test Loss: 0.631216824054718 | Test Accuracy: 92.5\n",
            "Epoch: 226 | Train Loss: 0.623525083065033 | Train Accuracy: 93.375 | Test Loss: 0.6305626034736633 | Test Accuracy: 92.5\n",
            "Epoch: 227 | Train Loss: 0.6228482127189636 | Train Accuracy: 93.5 | Test Loss: 0.6299049854278564 | Test Accuracy: 92.5\n",
            "Epoch: 228 | Train Loss: 0.6221648454666138 | Train Accuracy: 93.75 | Test Loss: 0.6292411088943481 | Test Accuracy: 92.5\n",
            "Epoch: 229 | Train Loss: 0.6214759945869446 | Train Accuracy: 93.75 | Test Loss: 0.6285688281059265 | Test Accuracy: 92.5\n",
            "Epoch: 230 | Train Loss: 0.6207809448242188 | Train Accuracy: 94.0 | Test Loss: 0.6278923153877258 | Test Accuracy: 92.5\n",
            "Epoch: 231 | Train Loss: 0.6200807094573975 | Train Accuracy: 94.125 | Test Loss: 0.6272112131118774 | Test Accuracy: 92.5\n",
            "Epoch: 232 | Train Loss: 0.6193745136260986 | Train Accuracy: 94.125 | Test Loss: 0.6265249252319336 | Test Accuracy: 92.5\n",
            "Epoch: 233 | Train Loss: 0.6186627745628357 | Train Accuracy: 94.125 | Test Loss: 0.6258335113525391 | Test Accuracy: 92.5\n",
            "Epoch: 234 | Train Loss: 0.6179453730583191 | Train Accuracy: 94.375 | Test Loss: 0.6251384019851685 | Test Accuracy: 92.5\n",
            "Epoch: 235 | Train Loss: 0.6172224879264832 | Train Accuracy: 94.375 | Test Loss: 0.6244363188743591 | Test Accuracy: 92.5\n",
            "Epoch: 236 | Train Loss: 0.6164928674697876 | Train Accuracy: 94.5 | Test Loss: 0.6237301230430603 | Test Accuracy: 92.5\n",
            "Epoch: 237 | Train Loss: 0.6157576441764832 | Train Accuracy: 94.625 | Test Loss: 0.6230145692825317 | Test Accuracy: 92.5\n",
            "Epoch: 238 | Train Loss: 0.6150156855583191 | Train Accuracy: 94.75 | Test Loss: 0.6222924590110779 | Test Accuracy: 92.5\n",
            "Epoch: 239 | Train Loss: 0.6142670512199402 | Train Accuracy: 94.75 | Test Loss: 0.6215639114379883 | Test Accuracy: 92.5\n",
            "Epoch: 240 | Train Loss: 0.6135121583938599 | Train Accuracy: 94.75 | Test Loss: 0.6208289861679077 | Test Accuracy: 92.5\n",
            "Epoch: 241 | Train Loss: 0.6127516627311707 | Train Accuracy: 94.875 | Test Loss: 0.620084822177887 | Test Accuracy: 92.5\n",
            "Epoch: 242 | Train Loss: 0.6119851469993591 | Train Accuracy: 95.125 | Test Loss: 0.6193389892578125 | Test Accuracy: 92.5\n",
            "Epoch: 243 | Train Loss: 0.611211895942688 | Train Accuracy: 95.25 | Test Loss: 0.6185848712921143 | Test Accuracy: 92.5\n",
            "Epoch: 244 | Train Loss: 0.6104322075843811 | Train Accuracy: 95.375 | Test Loss: 0.6178261637687683 | Test Accuracy: 92.5\n",
            "Epoch: 245 | Train Loss: 0.6096453070640564 | Train Accuracy: 95.5 | Test Loss: 0.6170591115951538 | Test Accuracy: 92.5\n",
            "Epoch: 246 | Train Loss: 0.6088517904281616 | Train Accuracy: 95.5 | Test Loss: 0.6162885427474976 | Test Accuracy: 92.5\n",
            "Epoch: 247 | Train Loss: 0.6080512404441833 | Train Accuracy: 95.5 | Test Loss: 0.6155073642730713 | Test Accuracy: 92.5\n",
            "Epoch: 248 | Train Loss: 0.6072439551353455 | Train Accuracy: 95.5 | Test Loss: 0.6147184371948242 | Test Accuracy: 92.5\n",
            "Epoch: 249 | Train Loss: 0.6064291000366211 | Train Accuracy: 95.625 | Test Loss: 0.6139221787452698 | Test Accuracy: 92.5\n",
            "Epoch: 250 | Train Loss: 0.6056068539619446 | Train Accuracy: 95.625 | Test Loss: 0.6131203174591064 | Test Accuracy: 92.5\n",
            "Epoch: 251 | Train Loss: 0.6047772765159607 | Train Accuracy: 95.875 | Test Loss: 0.6123086214065552 | Test Accuracy: 93.0\n",
            "Epoch: 252 | Train Loss: 0.6039406657218933 | Train Accuracy: 95.875 | Test Loss: 0.6114928126335144 | Test Accuracy: 93.0\n",
            "Epoch: 253 | Train Loss: 0.6030974388122559 | Train Accuracy: 95.875 | Test Loss: 0.6106669902801514 | Test Accuracy: 93.0\n",
            "Epoch: 254 | Train Loss: 0.6022467613220215 | Train Accuracy: 96.0 | Test Loss: 0.6098361015319824 | Test Accuracy: 93.0\n",
            "Epoch: 255 | Train Loss: 0.6013892889022827 | Train Accuracy: 96.125 | Test Loss: 0.6089969873428345 | Test Accuracy: 93.0\n",
            "Epoch: 256 | Train Loss: 0.6005244851112366 | Train Accuracy: 96.25 | Test Loss: 0.6081506609916687 | Test Accuracy: 94.0\n",
            "Epoch: 257 | Train Loss: 0.5996525287628174 | Train Accuracy: 96.25 | Test Loss: 0.6072973608970642 | Test Accuracy: 94.5\n",
            "Epoch: 258 | Train Loss: 0.5987734198570251 | Train Accuracy: 96.375 | Test Loss: 0.6064344048500061 | Test Accuracy: 94.5\n",
            "Epoch: 259 | Train Loss: 0.5978870391845703 | Train Accuracy: 96.375 | Test Loss: 0.6055696606636047 | Test Accuracy: 95.0\n",
            "Epoch: 260 | Train Loss: 0.5969933271408081 | Train Accuracy: 96.375 | Test Loss: 0.6046909689903259 | Test Accuracy: 95.0\n",
            "Epoch: 261 | Train Loss: 0.5960929989814758 | Train Accuracy: 96.375 | Test Loss: 0.6038071513175964 | Test Accuracy: 95.0\n",
            "Epoch: 262 | Train Loss: 0.5951852202415466 | Train Accuracy: 96.625 | Test Loss: 0.6029170751571655 | Test Accuracy: 95.0\n",
            "Epoch: 263 | Train Loss: 0.594269871711731 | Train Accuracy: 96.625 | Test Loss: 0.6020158529281616 | Test Accuracy: 95.0\n",
            "Epoch: 264 | Train Loss: 0.593346893787384 | Train Accuracy: 96.625 | Test Loss: 0.6011104583740234 | Test Accuracy: 95.0\n",
            "Epoch: 265 | Train Loss: 0.5924162864685059 | Train Accuracy: 96.625 | Test Loss: 0.6001967191696167 | Test Accuracy: 95.0\n",
            "Epoch: 266 | Train Loss: 0.5914785861968994 | Train Accuracy: 96.625 | Test Loss: 0.5992732644081116 | Test Accuracy: 95.5\n",
            "Epoch: 267 | Train Loss: 0.5905333757400513 | Train Accuracy: 96.75 | Test Loss: 0.5983445048332214 | Test Accuracy: 95.5\n",
            "Epoch: 268 | Train Loss: 0.5895804166793823 | Train Accuracy: 96.75 | Test Loss: 0.5974066853523254 | Test Accuracy: 95.5\n",
            "Epoch: 269 | Train Loss: 0.5886198878288269 | Train Accuracy: 96.875 | Test Loss: 0.5964604020118713 | Test Accuracy: 95.5\n",
            "Epoch: 270 | Train Loss: 0.5876513719558716 | Train Accuracy: 96.875 | Test Loss: 0.5955081582069397 | Test Accuracy: 96.0\n",
            "Epoch: 271 | Train Loss: 0.5866751670837402 | Train Accuracy: 96.875 | Test Loss: 0.5945470929145813 | Test Accuracy: 96.0\n",
            "Epoch: 272 | Train Loss: 0.5856911540031433 | Train Accuracy: 96.875 | Test Loss: 0.5935803651809692 | Test Accuracy: 96.0\n",
            "Epoch: 273 | Train Loss: 0.5846994519233704 | Train Accuracy: 97.0 | Test Loss: 0.5926035642623901 | Test Accuracy: 96.0\n",
            "Epoch: 274 | Train Loss: 0.5836994647979736 | Train Accuracy: 97.0 | Test Loss: 0.5916250944137573 | Test Accuracy: 96.0\n",
            "Epoch: 275 | Train Loss: 0.5826913118362427 | Train Accuracy: 97.0 | Test Loss: 0.5906323790550232 | Test Accuracy: 96.0\n",
            "Epoch: 276 | Train Loss: 0.581675112247467 | Train Accuracy: 97.125 | Test Loss: 0.5896312594413757 | Test Accuracy: 96.0\n",
            "Epoch: 277 | Train Loss: 0.5806499719619751 | Train Accuracy: 97.125 | Test Loss: 0.5886235237121582 | Test Accuracy: 96.0\n",
            "Epoch: 278 | Train Loss: 0.5796164274215698 | Train Accuracy: 97.25 | Test Loss: 0.5876051783561707 | Test Accuracy: 96.0\n",
            "Epoch: 279 | Train Loss: 0.5785741209983826 | Train Accuracy: 97.25 | Test Loss: 0.5865768790245056 | Test Accuracy: 96.5\n",
            "Epoch: 280 | Train Loss: 0.5775226354598999 | Train Accuracy: 97.25 | Test Loss: 0.5855374932289124 | Test Accuracy: 96.5\n",
            "Epoch: 281 | Train Loss: 0.5764620900154114 | Train Accuracy: 97.25 | Test Loss: 0.5844907164573669 | Test Accuracy: 96.5\n",
            "Epoch: 282 | Train Loss: 0.5753934979438782 | Train Accuracy: 97.25 | Test Loss: 0.5834343433380127 | Test Accuracy: 96.5\n",
            "Epoch: 283 | Train Loss: 0.5743160247802734 | Train Accuracy: 97.25 | Test Loss: 0.5823667049407959 | Test Accuracy: 96.5\n",
            "Epoch: 284 | Train Loss: 0.5732297301292419 | Train Accuracy: 97.25 | Test Loss: 0.5812888741493225 | Test Accuracy: 96.5\n",
            "Epoch: 285 | Train Loss: 0.5721353888511658 | Train Accuracy: 97.25 | Test Loss: 0.5802062153816223 | Test Accuracy: 97.0\n",
            "Epoch: 286 | Train Loss: 0.5710322260856628 | Train Accuracy: 97.25 | Test Loss: 0.579111635684967 | Test Accuracy: 97.0\n",
            "Epoch: 287 | Train Loss: 0.5699198246002197 | Train Accuracy: 97.25 | Test Loss: 0.5780074596405029 | Test Accuracy: 97.0\n",
            "Epoch: 288 | Train Loss: 0.5687983632087708 | Train Accuracy: 97.25 | Test Loss: 0.5768933892250061 | Test Accuracy: 97.0\n",
            "Epoch: 289 | Train Loss: 0.5676684975624084 | Train Accuracy: 97.25 | Test Loss: 0.575770378112793 | Test Accuracy: 97.0\n",
            "Epoch: 290 | Train Loss: 0.5665296316146851 | Train Accuracy: 97.25 | Test Loss: 0.5746357440948486 | Test Accuracy: 97.0\n",
            "Epoch: 291 | Train Loss: 0.5653819441795349 | Train Accuracy: 97.25 | Test Loss: 0.573492705821991 | Test Accuracy: 97.5\n",
            "Epoch: 292 | Train Loss: 0.5642258524894714 | Train Accuracy: 97.375 | Test Loss: 0.5723419785499573 | Test Accuracy: 97.5\n",
            "Epoch: 293 | Train Loss: 0.5630615949630737 | Train Accuracy: 97.375 | Test Loss: 0.5711835622787476 | Test Accuracy: 97.5\n",
            "Epoch: 294 | Train Loss: 0.5618889331817627 | Train Accuracy: 97.375 | Test Loss: 0.5700129866600037 | Test Accuracy: 98.0\n",
            "Epoch: 295 | Train Loss: 0.5607070922851562 | Train Accuracy: 97.625 | Test Loss: 0.5688362717628479 | Test Accuracy: 98.0\n",
            "Epoch: 296 | Train Loss: 0.559516966342926 | Train Accuracy: 97.75 | Test Loss: 0.5676522850990295 | Test Accuracy: 98.0\n",
            "Epoch: 297 | Train Loss: 0.5583187937736511 | Train Accuracy: 97.75 | Test Loss: 0.5664556622505188 | Test Accuracy: 98.0\n",
            "Epoch: 298 | Train Loss: 0.5571112632751465 | Train Accuracy: 97.75 | Test Loss: 0.5652508735656738 | Test Accuracy: 98.0\n",
            "Epoch: 299 | Train Loss: 0.5558943748474121 | Train Accuracy: 97.75 | Test Loss: 0.5640363097190857 | Test Accuracy: 98.0\n",
            "Epoch: 300 | Train Loss: 0.5546676516532898 | Train Accuracy: 97.75 | Test Loss: 0.5628126263618469 | Test Accuracy: 98.0\n",
            "Epoch: 301 | Train Loss: 0.5534321069717407 | Train Accuracy: 97.75 | Test Loss: 0.5615766048431396 | Test Accuracy: 98.0\n",
            "Epoch: 302 | Train Loss: 0.5521863698959351 | Train Accuracy: 97.75 | Test Loss: 0.5603322386741638 | Test Accuracy: 98.0\n",
            "Epoch: 303 | Train Loss: 0.5509312152862549 | Train Accuracy: 97.75 | Test Loss: 0.5590776801109314 | Test Accuracy: 98.0\n",
            "Epoch: 304 | Train Loss: 0.5496676564216614 | Train Accuracy: 98.0 | Test Loss: 0.557816207408905 | Test Accuracy: 98.0\n",
            "Epoch: 305 | Train Loss: 0.5483953952789307 | Train Accuracy: 98.0 | Test Loss: 0.5565465688705444 | Test Accuracy: 98.0\n",
            "Epoch: 306 | Train Loss: 0.5471137166023254 | Train Accuracy: 98.0 | Test Loss: 0.555272102355957 | Test Accuracy: 98.0\n",
            "Epoch: 307 | Train Loss: 0.5458217263221741 | Train Accuracy: 98.0 | Test Loss: 0.5539884567260742 | Test Accuracy: 98.0\n",
            "Epoch: 308 | Train Loss: 0.5445210933685303 | Train Accuracy: 98.125 | Test Loss: 0.5526939034461975 | Test Accuracy: 98.0\n",
            "Epoch: 309 | Train Loss: 0.5432113409042358 | Train Accuracy: 98.125 | Test Loss: 0.5513926148414612 | Test Accuracy: 98.0\n",
            "Epoch: 310 | Train Loss: 0.541891872882843 | Train Accuracy: 98.125 | Test Loss: 0.5500811338424683 | Test Accuracy: 98.5\n",
            "Epoch: 311 | Train Loss: 0.5405629873275757 | Train Accuracy: 98.125 | Test Loss: 0.5487593412399292 | Test Accuracy: 98.5\n",
            "Epoch: 312 | Train Loss: 0.5392247438430786 | Train Accuracy: 98.125 | Test Loss: 0.5474249720573425 | Test Accuracy: 99.0\n",
            "Epoch: 313 | Train Loss: 0.5378772020339966 | Train Accuracy: 98.125 | Test Loss: 0.5460867881774902 | Test Accuracy: 99.0\n",
            "Epoch: 314 | Train Loss: 0.536520779132843 | Train Accuracy: 98.125 | Test Loss: 0.5447391867637634 | Test Accuracy: 99.0\n",
            "Epoch: 315 | Train Loss: 0.5351552963256836 | Train Accuracy: 98.125 | Test Loss: 0.5433812141418457 | Test Accuracy: 99.0\n",
            "Epoch: 316 | Train Loss: 0.5337802171707153 | Train Accuracy: 98.25 | Test Loss: 0.5420106649398804 | Test Accuracy: 99.0\n",
            "Epoch: 317 | Train Loss: 0.5323965549468994 | Train Accuracy: 98.25 | Test Loss: 0.5406285524368286 | Test Accuracy: 99.0\n",
            "Epoch: 318 | Train Loss: 0.5310031175613403 | Train Accuracy: 98.125 | Test Loss: 0.5392324328422546 | Test Accuracy: 99.0\n",
            "Epoch: 319 | Train Loss: 0.5296003222465515 | Train Accuracy: 98.125 | Test Loss: 0.5378276109695435 | Test Accuracy: 99.0\n",
            "Epoch: 320 | Train Loss: 0.5281884074211121 | Train Accuracy: 98.125 | Test Loss: 0.5364147424697876 | Test Accuracy: 99.0\n",
            "Epoch: 321 | Train Loss: 0.5267666578292847 | Train Accuracy: 98.125 | Test Loss: 0.5349918007850647 | Test Accuracy: 99.0\n",
            "Epoch: 322 | Train Loss: 0.5253347754478455 | Train Accuracy: 98.125 | Test Loss: 0.5335634350776672 | Test Accuracy: 99.0\n",
            "Epoch: 323 | Train Loss: 0.5238937139511108 | Train Accuracy: 98.25 | Test Loss: 0.5321193337440491 | Test Accuracy: 99.0\n",
            "Epoch: 324 | Train Loss: 0.5224425196647644 | Train Accuracy: 98.25 | Test Loss: 0.5306676626205444 | Test Accuracy: 99.0\n",
            "Epoch: 325 | Train Loss: 0.5209825038909912 | Train Accuracy: 98.375 | Test Loss: 0.5292083621025085 | Test Accuracy: 99.0\n",
            "Epoch: 326 | Train Loss: 0.5195133686065674 | Train Accuracy: 98.375 | Test Loss: 0.5277384519577026 | Test Accuracy: 99.0\n",
            "Epoch: 327 | Train Loss: 0.5180346965789795 | Train Accuracy: 98.375 | Test Loss: 0.5262550115585327 | Test Accuracy: 99.0\n",
            "Epoch: 328 | Train Loss: 0.5165462493896484 | Train Accuracy: 98.375 | Test Loss: 0.5247615575790405 | Test Accuracy: 99.0\n",
            "Epoch: 329 | Train Loss: 0.5150498747825623 | Train Accuracy: 98.5 | Test Loss: 0.5232616662979126 | Test Accuracy: 99.0\n",
            "Epoch: 330 | Train Loss: 0.5135454535484314 | Train Accuracy: 98.625 | Test Loss: 0.5217497944831848 | Test Accuracy: 99.0\n",
            "Epoch: 331 | Train Loss: 0.5120322108268738 | Train Accuracy: 98.75 | Test Loss: 0.5202340483665466 | Test Accuracy: 99.0\n",
            "Epoch: 332 | Train Loss: 0.510509192943573 | Train Accuracy: 98.75 | Test Loss: 0.5187084674835205 | Test Accuracy: 99.0\n",
            "Epoch: 333 | Train Loss: 0.5089764595031738 | Train Accuracy: 98.875 | Test Loss: 0.5171765685081482 | Test Accuracy: 99.0\n",
            "Epoch: 334 | Train Loss: 0.5074329376220703 | Train Accuracy: 99.0 | Test Loss: 0.5156280994415283 | Test Accuracy: 99.0\n",
            "Epoch: 335 | Train Loss: 0.5058811902999878 | Train Accuracy: 99.25 | Test Loss: 0.5140705108642578 | Test Accuracy: 99.0\n",
            "Epoch: 336 | Train Loss: 0.5043209195137024 | Train Accuracy: 99.25 | Test Loss: 0.512499213218689 | Test Accuracy: 99.0\n",
            "Epoch: 337 | Train Loss: 0.5027515292167664 | Train Accuracy: 99.25 | Test Loss: 0.5109235048294067 | Test Accuracy: 99.0\n",
            "Epoch: 338 | Train Loss: 0.5011734366416931 | Train Accuracy: 99.25 | Test Loss: 0.5093403458595276 | Test Accuracy: 99.0\n",
            "Epoch: 339 | Train Loss: 0.4995872378349304 | Train Accuracy: 99.25 | Test Loss: 0.5077455639839172 | Test Accuracy: 99.0\n",
            "Epoch: 340 | Train Loss: 0.4979923963546753 | Train Accuracy: 99.375 | Test Loss: 0.5061470866203308 | Test Accuracy: 99.0\n",
            "Epoch: 341 | Train Loss: 0.4963897466659546 | Train Accuracy: 99.375 | Test Loss: 0.5045422911643982 | Test Accuracy: 99.5\n",
            "Epoch: 342 | Train Loss: 0.49477893114089966 | Train Accuracy: 99.375 | Test Loss: 0.5029211044311523 | Test Accuracy: 99.5\n",
            "Epoch: 343 | Train Loss: 0.4931600093841553 | Train Accuracy: 99.375 | Test Loss: 0.5012891888618469 | Test Accuracy: 99.5\n",
            "Epoch: 344 | Train Loss: 0.49153172969818115 | Train Accuracy: 99.375 | Test Loss: 0.4996472895145416 | Test Accuracy: 99.5\n",
            "Epoch: 345 | Train Loss: 0.48989337682724 | Train Accuracy: 99.375 | Test Loss: 0.4979952871799469 | Test Accuracy: 99.5\n",
            "Epoch: 346 | Train Loss: 0.4882463812828064 | Train Accuracy: 99.375 | Test Loss: 0.49633318185806274 | Test Accuracy: 99.5\n",
            "Epoch: 347 | Train Loss: 0.4865904152393341 | Train Accuracy: 99.375 | Test Loss: 0.4946594536304474 | Test Accuracy: 99.5\n",
            "Epoch: 348 | Train Loss: 0.4849262535572052 | Train Accuracy: 99.375 | Test Loss: 0.49297577142715454 | Test Accuracy: 99.5\n",
            "Epoch: 349 | Train Loss: 0.48325514793395996 | Train Accuracy: 99.375 | Test Loss: 0.4912906587123871 | Test Accuracy: 99.5\n",
            "Epoch: 350 | Train Loss: 0.4815780222415924 | Train Accuracy: 99.375 | Test Loss: 0.4895983040332794 | Test Accuracy: 99.5\n",
            "Epoch: 351 | Train Loss: 0.4798925817012787 | Train Accuracy: 99.375 | Test Loss: 0.4878922998905182 | Test Accuracy: 99.5\n",
            "Epoch: 352 | Train Loss: 0.47819754481315613 | Train Accuracy: 99.375 | Test Loss: 0.4861813187599182 | Test Accuracy: 99.5\n",
            "Epoch: 353 | Train Loss: 0.47649458050727844 | Train Accuracy: 99.375 | Test Loss: 0.4844644069671631 | Test Accuracy: 99.5\n",
            "Epoch: 354 | Train Loss: 0.47478383779525757 | Train Accuracy: 99.375 | Test Loss: 0.48273923993110657 | Test Accuracy: 99.5\n",
            "Epoch: 355 | Train Loss: 0.4730648696422577 | Train Accuracy: 99.375 | Test Loss: 0.4809991717338562 | Test Accuracy: 99.5\n",
            "Epoch: 356 | Train Loss: 0.4713357388973236 | Train Accuracy: 99.375 | Test Loss: 0.4792524576187134 | Test Accuracy: 99.5\n",
            "Epoch: 357 | Train Loss: 0.46959906816482544 | Train Accuracy: 99.375 | Test Loss: 0.4774983525276184 | Test Accuracy: 99.5\n",
            "Epoch: 358 | Train Loss: 0.4678560197353363 | Train Accuracy: 99.375 | Test Loss: 0.475738525390625 | Test Accuracy: 99.5\n",
            "Epoch: 359 | Train Loss: 0.46610626578330994 | Train Accuracy: 99.375 | Test Loss: 0.47397518157958984 | Test Accuracy: 99.5\n",
            "Epoch: 360 | Train Loss: 0.4643495976924896 | Train Accuracy: 99.375 | Test Loss: 0.4722040593624115 | Test Accuracy: 99.5\n",
            "Epoch: 361 | Train Loss: 0.46258509159088135 | Train Accuracy: 99.5 | Test Loss: 0.47042524814605713 | Test Accuracy: 99.5\n",
            "Epoch: 362 | Train Loss: 0.4608146548271179 | Train Accuracy: 99.5 | Test Loss: 0.46864160895347595 | Test Accuracy: 99.5\n",
            "Epoch: 363 | Train Loss: 0.4590415358543396 | Train Accuracy: 99.5 | Test Loss: 0.4668518602848053 | Test Accuracy: 99.5\n",
            "Epoch: 364 | Train Loss: 0.4572643041610718 | Train Accuracy: 99.5 | Test Loss: 0.46506384015083313 | Test Accuracy: 99.5\n",
            "Epoch: 365 | Train Loss: 0.4554816782474518 | Train Accuracy: 99.5 | Test Loss: 0.4632699489593506 | Test Accuracy: 99.5\n",
            "Epoch: 366 | Train Loss: 0.4536924660205841 | Train Accuracy: 99.5 | Test Loss: 0.46146658062934875 | Test Accuracy: 99.5\n",
            "Epoch: 367 | Train Loss: 0.45189711451530457 | Train Accuracy: 99.5 | Test Loss: 0.45966437458992004 | Test Accuracy: 99.5\n",
            "Epoch: 368 | Train Loss: 0.4500964283943176 | Train Accuracy: 99.5 | Test Loss: 0.4578610956668854 | Test Accuracy: 99.5\n",
            "Epoch: 369 | Train Loss: 0.448290079832077 | Train Accuracy: 99.5 | Test Loss: 0.4560563564300537 | Test Accuracy: 99.5\n",
            "Epoch: 370 | Train Loss: 0.44647789001464844 | Train Accuracy: 99.5 | Test Loss: 0.4542383551597595 | Test Accuracy: 100.0\n",
            "Epoch: 371 | Train Loss: 0.444659948348999 | Train Accuracy: 99.5 | Test Loss: 0.45241492986679077 | Test Accuracy: 100.0\n",
            "Epoch: 372 | Train Loss: 0.4428355395793915 | Train Accuracy: 99.5 | Test Loss: 0.45058223605155945 | Test Accuracy: 100.0\n",
            "Epoch: 373 | Train Loss: 0.4410015046596527 | Train Accuracy: 99.5 | Test Loss: 0.4487403631210327 | Test Accuracy: 100.0\n",
            "Epoch: 374 | Train Loss: 0.43916288018226624 | Train Accuracy: 99.5 | Test Loss: 0.4468905031681061 | Test Accuracy: 100.0\n",
            "Epoch: 375 | Train Loss: 0.4373210072517395 | Train Accuracy: 99.5 | Test Loss: 0.4450336694717407 | Test Accuracy: 100.0\n",
            "Epoch: 376 | Train Loss: 0.4354747533798218 | Train Accuracy: 99.5 | Test Loss: 0.44316980242729187 | Test Accuracy: 100.0\n",
            "Epoch: 377 | Train Loss: 0.4336242079734802 | Train Accuracy: 99.5 | Test Loss: 0.44130241870880127 | Test Accuracy: 100.0\n",
            "Epoch: 378 | Train Loss: 0.4317677915096283 | Train Accuracy: 99.5 | Test Loss: 0.43942931294441223 | Test Accuracy: 100.0\n",
            "Epoch: 379 | Train Loss: 0.42990657687187195 | Train Accuracy: 99.5 | Test Loss: 0.4375568926334381 | Test Accuracy: 100.0\n",
            "Epoch: 380 | Train Loss: 0.42804327607154846 | Train Accuracy: 99.5 | Test Loss: 0.4356774091720581 | Test Accuracy: 100.0\n",
            "Epoch: 381 | Train Loss: 0.4261748492717743 | Train Accuracy: 99.5 | Test Loss: 0.4337923228740692 | Test Accuracy: 100.0\n",
            "Epoch: 382 | Train Loss: 0.42430150508880615 | Train Accuracy: 99.5 | Test Loss: 0.4318971037864685 | Test Accuracy: 100.0\n",
            "Epoch: 383 | Train Loss: 0.4224244952201843 | Train Accuracy: 99.5 | Test Loss: 0.4300067126750946 | Test Accuracy: 100.0\n",
            "Epoch: 384 | Train Loss: 0.4205456078052521 | Train Accuracy: 99.5 | Test Loss: 0.42811447381973267 | Test Accuracy: 100.0\n",
            "Epoch: 385 | Train Loss: 0.41866621375083923 | Train Accuracy: 99.5 | Test Loss: 0.42622366547584534 | Test Accuracy: 100.0\n",
            "Epoch: 386 | Train Loss: 0.4167834520339966 | Train Accuracy: 99.5 | Test Loss: 0.42432600259780884 | Test Accuracy: 100.0\n",
            "Epoch: 387 | Train Loss: 0.41489875316619873 | Train Accuracy: 99.5 | Test Loss: 0.4224260151386261 | Test Accuracy: 100.0\n",
            "Epoch: 388 | Train Loss: 0.41301053762435913 | Train Accuracy: 99.625 | Test Loss: 0.4205224812030792 | Test Accuracy: 100.0\n",
            "Epoch: 389 | Train Loss: 0.4111176133155823 | Train Accuracy: 99.625 | Test Loss: 0.4186197817325592 | Test Accuracy: 100.0\n",
            "Epoch: 390 | Train Loss: 0.40922239422798157 | Train Accuracy: 99.625 | Test Loss: 0.41671064496040344 | Test Accuracy: 100.0\n",
            "Epoch: 391 | Train Loss: 0.40732645988464355 | Train Accuracy: 99.625 | Test Loss: 0.41479945182800293 | Test Accuracy: 100.0\n",
            "Epoch: 392 | Train Loss: 0.40542879700660706 | Train Accuracy: 99.625 | Test Loss: 0.41288259625434875 | Test Accuracy: 100.0\n",
            "Epoch: 393 | Train Loss: 0.40352919697761536 | Train Accuracy: 99.625 | Test Loss: 0.4109656810760498 | Test Accuracy: 100.0\n",
            "Epoch: 394 | Train Loss: 0.4016279876232147 | Train Accuracy: 99.625 | Test Loss: 0.40905246138572693 | Test Accuracy: 100.0\n",
            "Epoch: 395 | Train Loss: 0.3997255563735962 | Train Accuracy: 99.625 | Test Loss: 0.4071313440799713 | Test Accuracy: 100.0\n",
            "Epoch: 396 | Train Loss: 0.3978201150894165 | Train Accuracy: 99.625 | Test Loss: 0.40521207451820374 | Test Accuracy: 100.0\n",
            "Epoch: 397 | Train Loss: 0.3959142863750458 | Train Accuracy: 99.75 | Test Loss: 0.40329989790916443 | Test Accuracy: 100.0\n",
            "Epoch: 398 | Train Loss: 0.39400747418403625 | Train Accuracy: 99.75 | Test Loss: 0.40138354897499084 | Test Accuracy: 100.0\n",
            "Epoch: 399 | Train Loss: 0.3921002447605133 | Train Accuracy: 99.75 | Test Loss: 0.39946311712265015 | Test Accuracy: 100.0\n",
            "Epoch: 400 | Train Loss: 0.3901922106742859 | Train Accuracy: 99.75 | Test Loss: 0.39754626154899597 | Test Accuracy: 100.0\n",
            "Epoch: 401 | Train Loss: 0.3882843255996704 | Train Accuracy: 99.75 | Test Loss: 0.39562857151031494 | Test Accuracy: 100.0\n",
            "Epoch: 402 | Train Loss: 0.38637617230415344 | Train Accuracy: 99.875 | Test Loss: 0.39370661973953247 | Test Accuracy: 100.0\n",
            "Epoch: 403 | Train Loss: 0.3844667673110962 | Train Accuracy: 99.875 | Test Loss: 0.3917822241783142 | Test Accuracy: 100.0\n",
            "Epoch: 404 | Train Loss: 0.3825564384460449 | Train Accuracy: 99.875 | Test Loss: 0.3898574709892273 | Test Accuracy: 100.0\n",
            "Epoch: 405 | Train Loss: 0.3806482255458832 | Train Accuracy: 99.875 | Test Loss: 0.387938916683197 | Test Accuracy: 100.0\n",
            "Epoch: 406 | Train Loss: 0.3787415623664856 | Train Accuracy: 99.875 | Test Loss: 0.38602346181869507 | Test Accuracy: 100.0\n",
            "Epoch: 407 | Train Loss: 0.37683525681495667 | Train Accuracy: 99.875 | Test Loss: 0.3841058909893036 | Test Accuracy: 100.0\n",
            "Epoch: 408 | Train Loss: 0.37492793798446655 | Train Accuracy: 99.875 | Test Loss: 0.3821863532066345 | Test Accuracy: 100.0\n",
            "Epoch: 409 | Train Loss: 0.3730216920375824 | Train Accuracy: 99.875 | Test Loss: 0.38026952743530273 | Test Accuracy: 100.0\n",
            "Epoch: 410 | Train Loss: 0.37111786007881165 | Train Accuracy: 99.875 | Test Loss: 0.3783622682094574 | Test Accuracy: 100.0\n",
            "Epoch: 411 | Train Loss: 0.36921751499176025 | Train Accuracy: 99.875 | Test Loss: 0.3764595091342926 | Test Accuracy: 100.0\n",
            "Epoch: 412 | Train Loss: 0.3673197031021118 | Train Accuracy: 99.875 | Test Loss: 0.3745582103729248 | Test Accuracy: 100.0\n",
            "Epoch: 413 | Train Loss: 0.3654249906539917 | Train Accuracy: 99.875 | Test Loss: 0.3726590573787689 | Test Accuracy: 100.0\n",
            "Epoch: 414 | Train Loss: 0.36353346705436707 | Train Accuracy: 99.875 | Test Loss: 0.3707656264305115 | Test Accuracy: 100.0\n",
            "Epoch: 415 | Train Loss: 0.36164426803588867 | Train Accuracy: 99.875 | Test Loss: 0.3688713312149048 | Test Accuracy: 100.0\n",
            "Epoch: 416 | Train Loss: 0.359756737947464 | Train Accuracy: 99.875 | Test Loss: 0.36697906255722046 | Test Accuracy: 100.0\n",
            "Epoch: 417 | Train Loss: 0.3578714430332184 | Train Accuracy: 99.875 | Test Loss: 0.3650895953178406 | Test Accuracy: 100.0\n",
            "Epoch: 418 | Train Loss: 0.3559879958629608 | Train Accuracy: 99.875 | Test Loss: 0.3632022738456726 | Test Accuracy: 100.0\n",
            "Epoch: 419 | Train Loss: 0.35410651564598083 | Train Accuracy: 99.875 | Test Loss: 0.36131468415260315 | Test Accuracy: 100.0\n",
            "Epoch: 420 | Train Loss: 0.3522273898124695 | Train Accuracy: 99.875 | Test Loss: 0.3594282567501068 | Test Accuracy: 100.0\n",
            "Epoch: 421 | Train Loss: 0.3503497242927551 | Train Accuracy: 99.875 | Test Loss: 0.35754096508026123 | Test Accuracy: 100.0\n",
            "Epoch: 422 | Train Loss: 0.34847384691238403 | Train Accuracy: 99.875 | Test Loss: 0.35565751791000366 | Test Accuracy: 100.0\n",
            "Epoch: 423 | Train Loss: 0.3466012477874756 | Train Accuracy: 99.875 | Test Loss: 0.35377776622772217 | Test Accuracy: 100.0\n",
            "Epoch: 424 | Train Loss: 0.3447321355342865 | Train Accuracy: 99.875 | Test Loss: 0.35190653800964355 | Test Accuracy: 100.0\n",
            "Epoch: 425 | Train Loss: 0.3428672254085541 | Train Accuracy: 99.875 | Test Loss: 0.3500324785709381 | Test Accuracy: 100.0\n",
            "Epoch: 426 | Train Loss: 0.34100615978240967 | Train Accuracy: 99.875 | Test Loss: 0.3481694757938385 | Test Accuracy: 100.0\n",
            "Epoch: 427 | Train Loss: 0.3391473591327667 | Train Accuracy: 99.875 | Test Loss: 0.346303790807724 | Test Accuracy: 100.0\n",
            "Epoch: 428 | Train Loss: 0.3372924029827118 | Train Accuracy: 99.875 | Test Loss: 0.34444916248321533 | Test Accuracy: 100.0\n",
            "Epoch: 429 | Train Loss: 0.33544081449508667 | Train Accuracy: 99.875 | Test Loss: 0.3425944149494171 | Test Accuracy: 100.0\n",
            "Epoch: 430 | Train Loss: 0.33359235525131226 | Train Accuracy: 99.875 | Test Loss: 0.34074679017066956 | Test Accuracy: 100.0\n",
            "Epoch: 431 | Train Loss: 0.33174705505371094 | Train Accuracy: 99.875 | Test Loss: 0.3388970196247101 | Test Accuracy: 100.0\n",
            "Epoch: 432 | Train Loss: 0.32990509271621704 | Train Accuracy: 99.875 | Test Loss: 0.33705368638038635 | Test Accuracy: 100.0\n",
            "Epoch: 433 | Train Loss: 0.3280687928199768 | Train Accuracy: 99.875 | Test Loss: 0.33521509170532227 | Test Accuracy: 100.0\n",
            "Epoch: 434 | Train Loss: 0.32623663544654846 | Train Accuracy: 99.875 | Test Loss: 0.3333813548088074 | Test Accuracy: 100.0\n",
            "Epoch: 435 | Train Loss: 0.3244091868400574 | Train Accuracy: 99.875 | Test Loss: 0.3315545320510864 | Test Accuracy: 100.0\n",
            "Epoch: 436 | Train Loss: 0.3225860595703125 | Train Accuracy: 99.875 | Test Loss: 0.3297339677810669 | Test Accuracy: 100.0\n",
            "Epoch: 437 | Train Loss: 0.32076650857925415 | Train Accuracy: 99.875 | Test Loss: 0.32791417837142944 | Test Accuracy: 100.0\n",
            "Epoch: 438 | Train Loss: 0.3189496099948883 | Train Accuracy: 99.875 | Test Loss: 0.32609686255455017 | Test Accuracy: 100.0\n",
            "Epoch: 439 | Train Loss: 0.3171379864215851 | Train Accuracy: 99.875 | Test Loss: 0.3242872953414917 | Test Accuracy: 100.0\n",
            "Epoch: 440 | Train Loss: 0.3153310716152191 | Train Accuracy: 99.875 | Test Loss: 0.3224776089191437 | Test Accuracy: 100.0\n",
            "Epoch: 441 | Train Loss: 0.31352880597114563 | Train Accuracy: 99.875 | Test Loss: 0.32067614793777466 | Test Accuracy: 100.0\n",
            "Epoch: 442 | Train Loss: 0.3117319345474243 | Train Accuracy: 99.875 | Test Loss: 0.31887635588645935 | Test Accuracy: 100.0\n",
            "Epoch: 443 | Train Loss: 0.3099396526813507 | Train Accuracy: 99.875 | Test Loss: 0.3170868456363678 | Test Accuracy: 100.0\n",
            "Epoch: 444 | Train Loss: 0.308153361082077 | Train Accuracy: 99.875 | Test Loss: 0.3152991831302643 | Test Accuracy: 100.0\n",
            "Epoch: 445 | Train Loss: 0.30637145042419434 | Train Accuracy: 99.875 | Test Loss: 0.3135104775428772 | Test Accuracy: 100.0\n",
            "Epoch: 446 | Train Loss: 0.3045954406261444 | Train Accuracy: 99.875 | Test Loss: 0.3117374777793884 | Test Accuracy: 100.0\n",
            "Epoch: 447 | Train Loss: 0.3028261959552765 | Train Accuracy: 99.875 | Test Loss: 0.30996015667915344 | Test Accuracy: 100.0\n",
            "Epoch: 448 | Train Loss: 0.30106377601623535 | Train Accuracy: 99.875 | Test Loss: 0.30819404125213623 | Test Accuracy: 100.0\n",
            "Epoch: 449 | Train Loss: 0.29930657148361206 | Train Accuracy: 99.875 | Test Loss: 0.3064247667789459 | Test Accuracy: 100.0\n",
            "Epoch: 450 | Train Loss: 0.2975565791130066 | Train Accuracy: 99.875 | Test Loss: 0.3046763241291046 | Test Accuracy: 100.0\n",
            "Epoch: 451 | Train Loss: 0.29581379890441895 | Train Accuracy: 99.875 | Test Loss: 0.30292072892189026 | Test Accuracy: 100.0\n",
            "Epoch: 452 | Train Loss: 0.29407742619514465 | Train Accuracy: 99.875 | Test Loss: 0.3011830151081085 | Test Accuracy: 100.0\n",
            "Epoch: 453 | Train Loss: 0.2923482358455658 | Train Accuracy: 99.875 | Test Loss: 0.29943934082984924 | Test Accuracy: 100.0\n",
            "Epoch: 454 | Train Loss: 0.2906264364719391 | Train Accuracy: 99.875 | Test Loss: 0.2977280616760254 | Test Accuracy: 100.0\n",
            "Epoch: 455 | Train Loss: 0.28891071677207947 | Train Accuracy: 99.875 | Test Loss: 0.2959909439086914 | Test Accuracy: 100.0\n",
            "Epoch: 456 | Train Loss: 0.28719979524612427 | Train Accuracy: 99.875 | Test Loss: 0.29429247975349426 | Test Accuracy: 100.0\n",
            "Epoch: 457 | Train Loss: 0.28549614548683167 | Train Accuracy: 99.875 | Test Loss: 0.29256415367126465 | Test Accuracy: 100.0\n",
            "Epoch: 458 | Train Loss: 0.2837992310523987 | Train Accuracy: 99.875 | Test Loss: 0.29089027643203735 | Test Accuracy: 100.0\n",
            "Epoch: 459 | Train Loss: 0.28211110830307007 | Train Accuracy: 99.875 | Test Loss: 0.289169579744339 | Test Accuracy: 100.0\n",
            "Epoch: 460 | Train Loss: 0.28042975068092346 | Train Accuracy: 99.875 | Test Loss: 0.2875220477581024 | Test Accuracy: 100.0\n",
            "Epoch: 461 | Train Loss: 0.2787540853023529 | Train Accuracy: 99.875 | Test Loss: 0.28579771518707275 | Test Accuracy: 100.0\n",
            "Epoch: 462 | Train Loss: 0.27708491683006287 | Train Accuracy: 99.875 | Test Loss: 0.28417396545410156 | Test Accuracy: 100.0\n",
            "Epoch: 463 | Train Loss: 0.2754227817058563 | Train Accuracy: 99.875 | Test Loss: 0.28244397044181824 | Test Accuracy: 100.0\n",
            "Epoch: 464 | Train Loss: 0.2737695574760437 | Train Accuracy: 99.875 | Test Loss: 0.2808554470539093 | Test Accuracy: 100.0\n",
            "Epoch: 465 | Train Loss: 0.27212271094322205 | Train Accuracy: 99.875 | Test Loss: 0.27911022305488586 | Test Accuracy: 100.0\n",
            "Epoch: 466 | Train Loss: 0.27048298716545105 | Train Accuracy: 99.875 | Test Loss: 0.27755674719810486 | Test Accuracy: 100.0\n",
            "Epoch: 467 | Train Loss: 0.26884880661964417 | Train Accuracy: 99.875 | Test Loss: 0.27579373121261597 | Test Accuracy: 100.0\n",
            "Epoch: 468 | Train Loss: 0.2672223150730133 | Train Accuracy: 99.875 | Test Loss: 0.27428901195526123 | Test Accuracy: 100.0\n",
            "Epoch: 469 | Train Loss: 0.2656039297580719 | Train Accuracy: 99.875 | Test Loss: 0.2724960744380951 | Test Accuracy: 100.0\n",
            "Epoch: 470 | Train Loss: 0.26399683952331543 | Train Accuracy: 99.875 | Test Loss: 0.2710714042186737 | Test Accuracy: 100.0\n",
            "Epoch: 471 | Train Loss: 0.26240089535713196 | Train Accuracy: 99.75 | Test Loss: 0.26923424005508423 | Test Accuracy: 100.0\n",
            "Epoch: 472 | Train Loss: 0.260820597410202 | Train Accuracy: 99.875 | Test Loss: 0.2679271996021271 | Test Accuracy: 100.0\n",
            "Epoch: 473 | Train Loss: 0.2592551112174988 | Train Accuracy: 99.75 | Test Loss: 0.26602402329444885 | Test Accuracy: 99.5\n",
            "Epoch: 474 | Train Loss: 0.25770971179008484 | Train Accuracy: 99.875 | Test Loss: 0.26488691568374634 | Test Accuracy: 100.0\n",
            "Epoch: 475 | Train Loss: 0.25618788599967957 | Train Accuracy: 99.75 | Test Loss: 0.26288843154907227 | Test Accuracy: 99.5\n",
            "Epoch: 476 | Train Loss: 0.2546983063220978 | Train Accuracy: 99.875 | Test Loss: 0.2620201110839844 | Test Accuracy: 100.0\n",
            "Epoch: 477 | Train Loss: 0.2532593309879303 | Train Accuracy: 99.875 | Test Loss: 0.2599082887172699 | Test Accuracy: 99.5\n",
            "Epoch: 478 | Train Loss: 0.2518830895423889 | Train Accuracy: 99.875 | Test Loss: 0.25949928164482117 | Test Accuracy: 100.0\n",
            "Epoch: 479 | Train Loss: 0.25061631202697754 | Train Accuracy: 99.875 | Test Loss: 0.2572817802429199 | Test Accuracy: 99.5\n",
            "Epoch: 480 | Train Loss: 0.249485582113266 | Train Accuracy: 99.875 | Test Loss: 0.2577010691165924 | Test Accuracy: 100.0\n",
            "Epoch: 481 | Train Loss: 0.24860137701034546 | Train Accuracy: 99.875 | Test Loss: 0.25552308559417725 | Test Accuracy: 99.5\n",
            "Epoch: 482 | Train Loss: 0.24804656207561493 | Train Accuracy: 99.875 | Test Loss: 0.2575650215148926 | Test Accuracy: 100.0\n",
            "Epoch: 483 | Train Loss: 0.24808216094970703 | Train Accuracy: 99.5 | Test Loss: 0.2559017241001129 | Test Accuracy: 99.5\n",
            "Epoch: 484 | Train Loss: 0.2488844096660614 | Train Accuracy: 99.75 | Test Loss: 0.2613123953342438 | Test Accuracy: 100.0\n",
            "Epoch: 485 | Train Loss: 0.2511754631996155 | Train Accuracy: 99.125 | Test Loss: 0.26158562302589417 | Test Accuracy: 98.5\n",
            "Epoch: 486 | Train Loss: 0.2552475035190582 | Train Accuracy: 99.25 | Test Loss: 0.27468520402908325 | Test Accuracy: 98.5\n",
            "Epoch: 487 | Train Loss: 0.26337140798568726 | Train Accuracy: 98.5 | Test Loss: 0.28082725405693054 | Test Accuracy: 94.5\n",
            "Epoch: 488 | Train Loss: 0.2754213511943817 | Train Accuracy: 96.125 | Test Loss: 0.31183311343193054 | Test Accuracy: 91.0\n",
            "Epoch: 489 | Train Loss: 0.29828551411628723 | Train Accuracy: 93.0 | Test Loss: 0.3323219120502472 | Test Accuracy: 87.5\n",
            "Epoch: 490 | Train Loss: 0.3282935321331024 | Train Accuracy: 86.375 | Test Loss: 0.4017447531223297 | Test Accuracy: 71.5\n",
            "Epoch: 491 | Train Loss: 0.3840441107749939 | Train Accuracy: 75.25 | Test Loss: 0.4456394612789154 | Test Accuracy: 67.5\n",
            "Epoch: 492 | Train Loss: 0.44348227977752686 | Train Accuracy: 68.0 | Test Loss: 0.566819429397583 | Test Accuracy: 52.5\n",
            "Epoch: 493 | Train Loss: 0.542962372303009 | Train Accuracy: 55.75 | Test Loss: 0.5930481553077698 | Test Accuracy: 54.0\n",
            "Epoch: 494 | Train Loss: 0.5925610065460205 | Train Accuracy: 54.125 | Test Loss: 0.6956099271774292 | Test Accuracy: 50.5\n",
            "Epoch: 495 | Train Loss: 0.6665758490562439 | Train Accuracy: 51.87500000000001 | Test Loss: 0.6311031579971313 | Test Accuracy: 52.5\n",
            "Epoch: 496 | Train Loss: 0.6308361887931824 | Train Accuracy: 52.625 | Test Loss: 0.6757687330245972 | Test Accuracy: 51.0\n",
            "Epoch: 497 | Train Loss: 0.6452906131744385 | Train Accuracy: 52.37500000000001 | Test Loss: 0.576775074005127 | Test Accuracy: 55.00000000000001\n",
            "Epoch: 498 | Train Loss: 0.5763975977897644 | Train Accuracy: 55.25 | Test Loss: 0.5977236032485962 | Test Accuracy: 52.0\n",
            "Epoch: 499 | Train Loss: 0.5685611367225647 | Train Accuracy: 54.37499999999999 | Test Loss: 0.5064626932144165 | Test Accuracy: 60.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device\n"
      ],
      "metadata": {
        "id": "q4_-3LKc-w6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e7a01df8-3262-4735-eb84-9d24d0d69f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GIT code**"
      ],
      "metadata": {
        "id": "BtrjgiW50lqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_PEKs_l0PN8",
        "outputId": "cd830a0b-035b-48b3-986c-c194246de65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_1.weight',\n",
              "              tensor([[ 0.5630,  0.1557],\n",
              "                      [-0.3732,  0.3296],\n",
              "                      [-0.6820, -0.0541],\n",
              "                      [ 0.6615, -0.0093],\n",
              "                      [-0.3063,  0.0671],\n",
              "                      [-0.4310,  0.0996],\n",
              "                      [ 0.1915, -0.3744],\n",
              "                      [ 0.2039,  0.2313],\n",
              "                      [ 0.3475, -0.0937],\n",
              "                      [ 0.3850,  0.6590],\n",
              "                      [-0.0975,  0.6543],\n",
              "                      [ 0.1090,  0.6970],\n",
              "                      [-0.3497, -0.2104],\n",
              "                      [ 0.0856,  0.4703],\n",
              "                      [-0.4532, -0.1831]], device='cuda:0')),\n",
              "             ('layer_1.bias',\n",
              "              tensor([ 0.0209,  0.3330, -0.1544,  0.1171, -0.6829, -0.6044,  0.7007,  0.6392,\n",
              "                      -0.0213, -0.5446,  0.4116, -0.4558, -0.1267,  0.2987, -0.2217],\n",
              "                     device='cuda:0')),\n",
              "             ('layer_2.weight',\n",
              "              tensor([[ 0.2387, -0.1931, -0.2068, -0.0119,  0.1299, -0.0810,  0.0401,  0.1167,\n",
              "                        0.2199, -0.0999,  0.2181, -0.2537, -0.0450, -0.0060, -0.2325]],\n",
              "                     device='cuda:0')),\n",
              "             ('layer_2.bias', tensor([-0.1307], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OOP Model Creation**"
      ],
      "metadata": {
        "id": "wMIXurZDSoH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class Model_V(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(in_features=2, out_features=10)\n",
        "    self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
        "    self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
        "\n",
        "model_2 = Model_V().to(device)\n",
        "print(model_2)"
      ],
      "metadata": {
        "id": "_Lo5q7eq0snF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6732f607-7909-41e3-935b-e992bbb10a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model_V(\n",
            "  (layer_1): Linear(in_features=2, out_features=10, bias=True)\n",
            "  (layer_2): Linear(in_features=10, out_features=10, bias=True)\n",
            "  (layer_3): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqR1ylfUc-8",
        "outputId": "841c4aae-33f0-4117-df3d-4557b3f6e501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Model_V(\n",
              "  (layer_1): Linear(in_features=2, out_features=10, bias=True)\n",
              "  (layer_2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (layer_3): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr = 0.1)"
      ],
      "metadata": {
        "id": "ToAM9y5JVuT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "5gmcEJIHdkMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(12)\n",
        "epochs = 1000\n",
        "\n",
        "X_train, y_train, X_test, y_test = X_train.to(device), y_train.to(device), X_test.to(device), y_test.to(device)\n",
        "\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_2.train()\n",
        "\n",
        "  y_logits = model_2(X_train).squeeze()\n",
        "  y_pred = torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "\n",
        "  #y_pred = model_0(X_train)\n",
        "\n",
        "  loss = loss_fn(y_logits, y_train)\n",
        "\n",
        "  acc = accuracy_fn(y_true = y_train,\n",
        "                    y_pred=y_pred)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  model_2.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_logits = model_2(X_test).squeeze()\n",
        "    test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "    test_loss = loss_fn(test_logits,\n",
        "                        y_test)\n",
        "    test_acc = accuracy_fn(y_true = y_test,\n",
        "                    y_pred=test_pred)\n",
        "    print(f\"Epoch: {epoch} | Train Loss: {loss} | Train Accuracy: {acc} | Test Loss: {test_loss} | Test Accuracy: {test_acc}\")\n",
        "\n",
        "    print(type(loss))\n",
        "    loss1 = loss.to(\"cpu\")\n",
        "    test_loss1 = test_loss.to(\"cpu\")\n",
        "    print(type(test_loss1.detach().numpy()))\n",
        "    #epoch1= epoch.to(\"cpu\")\n",
        "    train_loss_values.append(loss1.detach())\n",
        "    test_loss_values.append(test_loss1.detach().numpy())\n",
        "    epoch_count.append(np.float32(epoch))\n",
        "\n",
        "    print(type(test_loss_values[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ZHatvqVJnK",
        "outputId": "065dad06-845e-4934-a6de-7aace3acb9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 0.4065709710121155 | Train Accuracy: 95.5 | Test Loss: 0.4218076467514038 | Test Accuracy: 96.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 1 | Train Loss: 0.4054504632949829 | Train Accuracy: 95.5 | Test Loss: 0.42069220542907715 | Test Accuracy: 96.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 2 | Train Loss: 0.40432602167129517 | Train Accuracy: 95.75 | Test Loss: 0.41958415508270264 | Test Accuracy: 96.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 3 | Train Loss: 0.40320196747779846 | Train Accuracy: 95.75 | Test Loss: 0.418474406003952 | Test Accuracy: 96.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 4 | Train Loss: 0.40207526087760925 | Train Accuracy: 95.875 | Test Loss: 0.41735559701919556 | Test Accuracy: 96.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 5 | Train Loss: 0.40094515681266785 | Train Accuracy: 96.0 | Test Loss: 0.41622912883758545 | Test Accuracy: 96.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 6 | Train Loss: 0.39981138706207275 | Train Accuracy: 96.125 | Test Loss: 0.41510480642318726 | Test Accuracy: 96.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 7 | Train Loss: 0.39866903424263 | Train Accuracy: 96.25 | Test Loss: 0.4139515459537506 | Test Accuracy: 96.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 8 | Train Loss: 0.3975222408771515 | Train Accuracy: 96.375 | Test Loss: 0.4127711355686188 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 9 | Train Loss: 0.39637312293052673 | Train Accuracy: 96.375 | Test Loss: 0.4116063714027405 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 10 | Train Loss: 0.39522334933280945 | Train Accuracy: 96.375 | Test Loss: 0.4104185402393341 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 11 | Train Loss: 0.394072562456131 | Train Accuracy: 96.375 | Test Loss: 0.4092390239238739 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 12 | Train Loss: 0.3929172456264496 | Train Accuracy: 96.5 | Test Loss: 0.40804141759872437 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 13 | Train Loss: 0.39175787568092346 | Train Accuracy: 96.5 | Test Loss: 0.4068395495414734 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 14 | Train Loss: 0.39059919118881226 | Train Accuracy: 96.625 | Test Loss: 0.40564215183258057 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 15 | Train Loss: 0.38943952322006226 | Train Accuracy: 96.75 | Test Loss: 0.4044495224952698 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 16 | Train Loss: 0.38827842473983765 | Train Accuracy: 96.75 | Test Loss: 0.403268963098526 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 17 | Train Loss: 0.38711169362068176 | Train Accuracy: 96.875 | Test Loss: 0.4020863175392151 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 18 | Train Loss: 0.38594403862953186 | Train Accuracy: 96.875 | Test Loss: 0.4008994996547699 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 19 | Train Loss: 0.3847759962081909 | Train Accuracy: 97.0 | Test Loss: 0.3996938169002533 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 20 | Train Loss: 0.38360685110092163 | Train Accuracy: 97.0 | Test Loss: 0.3985041677951813 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 21 | Train Loss: 0.38243675231933594 | Train Accuracy: 97.25 | Test Loss: 0.3973115384578705 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 22 | Train Loss: 0.38126564025878906 | Train Accuracy: 97.375 | Test Loss: 0.3961241543292999 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 23 | Train Loss: 0.38009345531463623 | Train Accuracy: 97.5 | Test Loss: 0.39494574069976807 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 24 | Train Loss: 0.37892046570777893 | Train Accuracy: 97.5 | Test Loss: 0.3937632739543915 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 25 | Train Loss: 0.3777479827404022 | Train Accuracy: 97.5 | Test Loss: 0.39258047938346863 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 26 | Train Loss: 0.3765771687030792 | Train Accuracy: 97.5 | Test Loss: 0.3914088308811188 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 27 | Train Loss: 0.3754080832004547 | Train Accuracy: 97.5 | Test Loss: 0.39022621512413025 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 28 | Train Loss: 0.3742375075817108 | Train Accuracy: 97.5 | Test Loss: 0.3890543282032013 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 29 | Train Loss: 0.37306272983551025 | Train Accuracy: 97.625 | Test Loss: 0.3878767192363739 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 30 | Train Loss: 0.37188687920570374 | Train Accuracy: 97.625 | Test Loss: 0.38669806718826294 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 31 | Train Loss: 0.3707100450992584 | Train Accuracy: 97.625 | Test Loss: 0.38552001118659973 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 32 | Train Loss: 0.36953237652778625 | Train Accuracy: 97.625 | Test Loss: 0.3843378722667694 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 33 | Train Loss: 0.36835402250289917 | Train Accuracy: 97.75 | Test Loss: 0.3831551671028137 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 34 | Train Loss: 0.36717870831489563 | Train Accuracy: 97.75 | Test Loss: 0.3819689452648163 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 35 | Train Loss: 0.3660029172897339 | Train Accuracy: 97.75 | Test Loss: 0.38076597452163696 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 36 | Train Loss: 0.36482641100883484 | Train Accuracy: 98.0 | Test Loss: 0.37959423661231995 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 37 | Train Loss: 0.36364901065826416 | Train Accuracy: 98.0 | Test Loss: 0.3783785104751587 | Test Accuracy: 97.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 38 | Train Loss: 0.36246833205223083 | Train Accuracy: 98.0 | Test Loss: 0.37718942761421204 | Test Accuracy: 97.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 39 | Train Loss: 0.36128729581832886 | Train Accuracy: 98.0 | Test Loss: 0.3759933114051819 | Test Accuracy: 97.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 40 | Train Loss: 0.36010468006134033 | Train Accuracy: 98.0 | Test Loss: 0.3747960329055786 | Test Accuracy: 97.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 41 | Train Loss: 0.3589184880256653 | Train Accuracy: 98.125 | Test Loss: 0.3735826313495636 | Test Accuracy: 97.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 42 | Train Loss: 0.3577297031879425 | Train Accuracy: 98.125 | Test Loss: 0.3723662495613098 | Test Accuracy: 97.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 43 | Train Loss: 0.35653984546661377 | Train Accuracy: 98.125 | Test Loss: 0.37115225195884705 | Test Accuracy: 98.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 44 | Train Loss: 0.355344295501709 | Train Accuracy: 98.125 | Test Loss: 0.3699372410774231 | Test Accuracy: 98.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 45 | Train Loss: 0.3541484773159027 | Train Accuracy: 98.125 | Test Loss: 0.36872583627700806 | Test Accuracy: 98.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 46 | Train Loss: 0.3529508411884308 | Train Accuracy: 98.125 | Test Loss: 0.36751073598861694 | Test Accuracy: 98.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 47 | Train Loss: 0.351748526096344 | Train Accuracy: 98.125 | Test Loss: 0.366294801235199 | Test Accuracy: 98.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 48 | Train Loss: 0.3505372405052185 | Train Accuracy: 98.125 | Test Loss: 0.36506912112236023 | Test Accuracy: 98.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 49 | Train Loss: 0.3493242561817169 | Train Accuracy: 98.125 | Test Loss: 0.36384275555610657 | Test Accuracy: 98.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 50 | Train Loss: 0.3481104075908661 | Train Accuracy: 98.125 | Test Loss: 0.3626013398170471 | Test Accuracy: 99.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 51 | Train Loss: 0.3469027578830719 | Train Accuracy: 98.375 | Test Loss: 0.361368864774704 | Test Accuracy: 99.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 52 | Train Loss: 0.3456951081752777 | Train Accuracy: 98.625 | Test Loss: 0.3601436913013458 | Test Accuracy: 99.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 53 | Train Loss: 0.3444875180721283 | Train Accuracy: 98.625 | Test Loss: 0.358921080827713 | Test Accuracy: 99.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 54 | Train Loss: 0.34328049421310425 | Train Accuracy: 98.875 | Test Loss: 0.35769617557525635 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 55 | Train Loss: 0.3420751094818115 | Train Accuracy: 98.875 | Test Loss: 0.3564806282520294 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 56 | Train Loss: 0.3408738672733307 | Train Accuracy: 98.875 | Test Loss: 0.3552582561969757 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 57 | Train Loss: 0.3396718502044678 | Train Accuracy: 98.875 | Test Loss: 0.35401445627212524 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 58 | Train Loss: 0.33846670389175415 | Train Accuracy: 98.875 | Test Loss: 0.3527759611606598 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 59 | Train Loss: 0.33726248145103455 | Train Accuracy: 98.875 | Test Loss: 0.351539671421051 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 60 | Train Loss: 0.3360602557659149 | Train Accuracy: 98.875 | Test Loss: 0.3503090441226959 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 61 | Train Loss: 0.3348585069179535 | Train Accuracy: 98.875 | Test Loss: 0.3490791916847229 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 62 | Train Loss: 0.3336575925350189 | Train Accuracy: 98.875 | Test Loss: 0.34784889221191406 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 63 | Train Loss: 0.3324573338031769 | Train Accuracy: 98.875 | Test Loss: 0.3466270864009857 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 64 | Train Loss: 0.3312590718269348 | Train Accuracy: 98.875 | Test Loss: 0.3453918695449829 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 65 | Train Loss: 0.3300664722919464 | Train Accuracy: 99.0 | Test Loss: 0.34416741132736206 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 66 | Train Loss: 0.32887619733810425 | Train Accuracy: 99.0 | Test Loss: 0.3429417610168457 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 67 | Train Loss: 0.3276872932910919 | Train Accuracy: 99.0 | Test Loss: 0.34171655774116516 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 68 | Train Loss: 0.32649821043014526 | Train Accuracy: 99.0 | Test Loss: 0.3404937982559204 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 69 | Train Loss: 0.3253099024295807 | Train Accuracy: 99.0 | Test Loss: 0.339272141456604 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 70 | Train Loss: 0.32412275671958923 | Train Accuracy: 99.0 | Test Loss: 0.3380526006221771 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 71 | Train Loss: 0.3229371905326843 | Train Accuracy: 99.0 | Test Loss: 0.3368319869041443 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 72 | Train Loss: 0.32175350189208984 | Train Accuracy: 99.0 | Test Loss: 0.3356146514415741 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 73 | Train Loss: 0.3205706775188446 | Train Accuracy: 99.0 | Test Loss: 0.3343975245952606 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 74 | Train Loss: 0.31938764452934265 | Train Accuracy: 99.0 | Test Loss: 0.3331529200077057 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 75 | Train Loss: 0.3182034194469452 | Train Accuracy: 99.0 | Test Loss: 0.33191898465156555 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 76 | Train Loss: 0.31701844930648804 | Train Accuracy: 99.0 | Test Loss: 0.3306739032268524 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 77 | Train Loss: 0.3158365786075592 | Train Accuracy: 99.125 | Test Loss: 0.32943207025527954 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 78 | Train Loss: 0.31465333700180054 | Train Accuracy: 99.125 | Test Loss: 0.32818740606307983 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 79 | Train Loss: 0.31347355246543884 | Train Accuracy: 99.25 | Test Loss: 0.32693779468536377 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 80 | Train Loss: 0.31229346990585327 | Train Accuracy: 99.375 | Test Loss: 0.3257083296775818 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 81 | Train Loss: 0.3111121952533722 | Train Accuracy: 99.375 | Test Loss: 0.3244718909263611 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 82 | Train Loss: 0.3099327087402344 | Train Accuracy: 99.5 | Test Loss: 0.32324618101119995 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 83 | Train Loss: 0.30875444412231445 | Train Accuracy: 99.5 | Test Loss: 0.32200977206230164 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 84 | Train Loss: 0.30757221579551697 | Train Accuracy: 99.5 | Test Loss: 0.32076847553253174 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 85 | Train Loss: 0.3063918948173523 | Train Accuracy: 99.5 | Test Loss: 0.3195246160030365 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 86 | Train Loss: 0.3052138388156891 | Train Accuracy: 99.5 | Test Loss: 0.31828567385673523 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 87 | Train Loss: 0.30403727293014526 | Train Accuracy: 99.5 | Test Loss: 0.3170454800128937 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 88 | Train Loss: 0.3028644025325775 | Train Accuracy: 99.5 | Test Loss: 0.31580105423927307 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 89 | Train Loss: 0.3016960322856903 | Train Accuracy: 99.5 | Test Loss: 0.3145560920238495 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 90 | Train Loss: 0.3005293905735016 | Train Accuracy: 99.5 | Test Loss: 0.3133101463317871 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 91 | Train Loss: 0.29936495423316956 | Train Accuracy: 99.5 | Test Loss: 0.31206122040748596 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 92 | Train Loss: 0.2982037365436554 | Train Accuracy: 99.5 | Test Loss: 0.31082090735435486 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 93 | Train Loss: 0.29704561829566956 | Train Accuracy: 99.5 | Test Loss: 0.3095957934856415 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 94 | Train Loss: 0.2958894371986389 | Train Accuracy: 99.5 | Test Loss: 0.3083692789077759 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 95 | Train Loss: 0.29473432898521423 | Train Accuracy: 99.5 | Test Loss: 0.30714333057403564 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 96 | Train Loss: 0.2935788929462433 | Train Accuracy: 99.5 | Test Loss: 0.30591681599617004 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 97 | Train Loss: 0.2924252450466156 | Train Accuracy: 99.5 | Test Loss: 0.3046913146972656 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 98 | Train Loss: 0.2912735044956207 | Train Accuracy: 99.5 | Test Loss: 0.30346986651420593 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 99 | Train Loss: 0.29012352228164673 | Train Accuracy: 99.5 | Test Loss: 0.3022461533546448 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 100 | Train Loss: 0.28897544741630554 | Train Accuracy: 99.5 | Test Loss: 0.3010300099849701 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 101 | Train Loss: 0.28782913088798523 | Train Accuracy: 99.5 | Test Loss: 0.2998025715351105 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 102 | Train Loss: 0.2866832911968231 | Train Accuracy: 99.5 | Test Loss: 0.2985813319683075 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 103 | Train Loss: 0.2855396568775177 | Train Accuracy: 99.5 | Test Loss: 0.2973761558532715 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 104 | Train Loss: 0.2843977212905884 | Train Accuracy: 99.5 | Test Loss: 0.2961336374282837 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 105 | Train Loss: 0.2832542359828949 | Train Accuracy: 99.5 | Test Loss: 0.2949465215206146 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 106 | Train Loss: 0.28211334347724915 | Train Accuracy: 99.5 | Test Loss: 0.29367202520370483 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 107 | Train Loss: 0.28096523880958557 | Train Accuracy: 99.5 | Test Loss: 0.29248589277267456 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 108 | Train Loss: 0.2798202931880951 | Train Accuracy: 99.5 | Test Loss: 0.2912236154079437 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 109 | Train Loss: 0.2786768972873688 | Train Accuracy: 99.5 | Test Loss: 0.2900492548942566 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 110 | Train Loss: 0.27753621339797974 | Train Accuracy: 99.5 | Test Loss: 0.28880080580711365 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 111 | Train Loss: 0.2763971984386444 | Train Accuracy: 99.5 | Test Loss: 0.2876313030719757 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 112 | Train Loss: 0.27526208758354187 | Train Accuracy: 99.5 | Test Loss: 0.2863868772983551 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 113 | Train Loss: 0.27412864565849304 | Train Accuracy: 99.5 | Test Loss: 0.28521013259887695 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 114 | Train Loss: 0.27299827337265015 | Train Accuracy: 99.5 | Test Loss: 0.28397607803344727 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 115 | Train Loss: 0.27186939120292664 | Train Accuracy: 99.5 | Test Loss: 0.2827930152416229 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 116 | Train Loss: 0.27073532342910767 | Train Accuracy: 99.5 | Test Loss: 0.28154119849205017 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 117 | Train Loss: 0.26959702372550964 | Train Accuracy: 99.5 | Test Loss: 0.2803414762020111 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 118 | Train Loss: 0.2684617340564728 | Train Accuracy: 99.5 | Test Loss: 0.27911144495010376 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 119 | Train Loss: 0.26733002066612244 | Train Accuracy: 99.5 | Test Loss: 0.2779242992401123 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 120 | Train Loss: 0.26620107889175415 | Train Accuracy: 99.5 | Test Loss: 0.276701420545578 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 121 | Train Loss: 0.2650756537914276 | Train Accuracy: 99.5 | Test Loss: 0.2755240499973297 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 122 | Train Loss: 0.2639535367488861 | Train Accuracy: 99.5 | Test Loss: 0.27433639764785767 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 123 | Train Loss: 0.26283523440361023 | Train Accuracy: 99.5 | Test Loss: 0.2731620967388153 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 124 | Train Loss: 0.2617206275463104 | Train Accuracy: 99.5 | Test Loss: 0.27197203040122986 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 125 | Train Loss: 0.26061031222343445 | Train Accuracy: 99.5 | Test Loss: 0.27079230546951294 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 126 | Train Loss: 0.259504497051239 | Train Accuracy: 99.5 | Test Loss: 0.2696096897125244 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 127 | Train Loss: 0.2584017515182495 | Train Accuracy: 99.5 | Test Loss: 0.26842108368873596 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 128 | Train Loss: 0.2573012113571167 | Train Accuracy: 99.5 | Test Loss: 0.2672451436519623 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 129 | Train Loss: 0.25620418787002563 | Train Accuracy: 99.5 | Test Loss: 0.2660769522190094 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 130 | Train Loss: 0.2551122307777405 | Train Accuracy: 99.5 | Test Loss: 0.2649102807044983 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 131 | Train Loss: 0.25402286648750305 | Train Accuracy: 99.5 | Test Loss: 0.263741672039032 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 132 | Train Loss: 0.25293681025505066 | Train Accuracy: 99.5 | Test Loss: 0.26258447766304016 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 133 | Train Loss: 0.2518543601036072 | Train Accuracy: 99.5 | Test Loss: 0.2614381015300751 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 134 | Train Loss: 0.2507748305797577 | Train Accuracy: 99.5 | Test Loss: 0.26027530431747437 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 135 | Train Loss: 0.2496950477361679 | Train Accuracy: 99.5 | Test Loss: 0.25911110639572144 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 136 | Train Loss: 0.24861492216587067 | Train Accuracy: 99.5 | Test Loss: 0.25795117020606995 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 137 | Train Loss: 0.24753837287425995 | Train Accuracy: 99.5 | Test Loss: 0.2568034827709198 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 138 | Train Loss: 0.2464652955532074 | Train Accuracy: 99.625 | Test Loss: 0.2556542754173279 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 139 | Train Loss: 0.245395690202713 | Train Accuracy: 99.625 | Test Loss: 0.2545170783996582 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 140 | Train Loss: 0.24432986974716187 | Train Accuracy: 99.625 | Test Loss: 0.25338417291641235 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 141 | Train Loss: 0.24326762557029724 | Train Accuracy: 99.625 | Test Loss: 0.25225237011909485 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 142 | Train Loss: 0.2422088235616684 | Train Accuracy: 99.625 | Test Loss: 0.2511303722858429 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 143 | Train Loss: 0.24115347862243652 | Train Accuracy: 99.625 | Test Loss: 0.25001394748687744 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 144 | Train Loss: 0.2400997430086136 | Train Accuracy: 99.625 | Test Loss: 0.2489156275987625 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 145 | Train Loss: 0.23904673755168915 | Train Accuracy: 99.625 | Test Loss: 0.24780654907226562 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 146 | Train Loss: 0.23799602687358856 | Train Accuracy: 99.625 | Test Loss: 0.24670051038265228 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 147 | Train Loss: 0.2369457632303238 | Train Accuracy: 99.75 | Test Loss: 0.24558620154857635 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 148 | Train Loss: 0.23590019345283508 | Train Accuracy: 99.75 | Test Loss: 0.24449874460697174 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 149 | Train Loss: 0.23486003279685974 | Train Accuracy: 99.75 | Test Loss: 0.2434052973985672 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 150 | Train Loss: 0.23382282257080078 | Train Accuracy: 99.75 | Test Loss: 0.24232344329357147 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 151 | Train Loss: 0.23278659582138062 | Train Accuracy: 99.75 | Test Loss: 0.2412407249212265 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 152 | Train Loss: 0.23175424337387085 | Train Accuracy: 99.75 | Test Loss: 0.240162193775177 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 153 | Train Loss: 0.23072576522827148 | Train Accuracy: 99.75 | Test Loss: 0.2390863597393036 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 154 | Train Loss: 0.2297009974718094 | Train Accuracy: 99.75 | Test Loss: 0.23801295459270477 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 155 | Train Loss: 0.22867541015148163 | Train Accuracy: 99.75 | Test Loss: 0.23693770170211792 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 156 | Train Loss: 0.2276429384946823 | Train Accuracy: 99.75 | Test Loss: 0.2358497977256775 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 157 | Train Loss: 0.22661560773849487 | Train Accuracy: 99.875 | Test Loss: 0.23479293286800385 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 158 | Train Loss: 0.22559192776679993 | Train Accuracy: 99.875 | Test Loss: 0.23369723558425903 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 159 | Train Loss: 0.22456492483615875 | Train Accuracy: 99.875 | Test Loss: 0.23260903358459473 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 160 | Train Loss: 0.22353051602840424 | Train Accuracy: 99.875 | Test Loss: 0.23151132464408875 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 161 | Train Loss: 0.22250251471996307 | Train Accuracy: 99.875 | Test Loss: 0.23044559359550476 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 162 | Train Loss: 0.22148193418979645 | Train Accuracy: 99.875 | Test Loss: 0.22936950623989105 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 163 | Train Loss: 0.22046644985675812 | Train Accuracy: 99.875 | Test Loss: 0.22832606732845306 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 164 | Train Loss: 0.21945437788963318 | Train Accuracy: 99.875 | Test Loss: 0.2272491455078125 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 165 | Train Loss: 0.21844437718391418 | Train Accuracy: 99.875 | Test Loss: 0.22622078657150269 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 166 | Train Loss: 0.21743910014629364 | Train Accuracy: 99.875 | Test Loss: 0.2251487374305725 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 167 | Train Loss: 0.21644006669521332 | Train Accuracy: 99.875 | Test Loss: 0.22412478923797607 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 168 | Train Loss: 0.2154458910226822 | Train Accuracy: 99.875 | Test Loss: 0.22306367754936218 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 169 | Train Loss: 0.21445630490779877 | Train Accuracy: 99.875 | Test Loss: 0.22204965353012085 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 170 | Train Loss: 0.21347114443778992 | Train Accuracy: 99.875 | Test Loss: 0.22100292146205902 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 171 | Train Loss: 0.2124905288219452 | Train Accuracy: 99.875 | Test Loss: 0.21999014914035797 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 172 | Train Loss: 0.2115144282579422 | Train Accuracy: 99.875 | Test Loss: 0.2189507633447647 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 173 | Train Loss: 0.2105427086353302 | Train Accuracy: 99.875 | Test Loss: 0.2179495245218277 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 174 | Train Loss: 0.20957538485527039 | Train Accuracy: 99.875 | Test Loss: 0.21692584455013275 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 175 | Train Loss: 0.20861373841762543 | Train Accuracy: 99.875 | Test Loss: 0.2159423828125 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 176 | Train Loss: 0.20765967667102814 | Train Accuracy: 99.875 | Test Loss: 0.2149476259946823 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 177 | Train Loss: 0.20670969784259796 | Train Accuracy: 99.875 | Test Loss: 0.2139786034822464 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 178 | Train Loss: 0.20576582849025726 | Train Accuracy: 99.875 | Test Loss: 0.21299636363983154 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 179 | Train Loss: 0.2048266977071762 | Train Accuracy: 99.875 | Test Loss: 0.2120404839515686 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 180 | Train Loss: 0.20389220118522644 | Train Accuracy: 99.875 | Test Loss: 0.2110644280910492 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 181 | Train Loss: 0.20296189188957214 | Train Accuracy: 99.875 | Test Loss: 0.21011655032634735 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 182 | Train Loss: 0.20203593373298645 | Train Accuracy: 99.875 | Test Loss: 0.20914378762245178 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 183 | Train Loss: 0.20111411809921265 | Train Accuracy: 99.875 | Test Loss: 0.20820483565330505 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 184 | Train Loss: 0.20019687712192535 | Train Accuracy: 99.875 | Test Loss: 0.20723119378089905 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 185 | Train Loss: 0.1992841362953186 | Train Accuracy: 99.875 | Test Loss: 0.2063063383102417 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 186 | Train Loss: 0.19837559759616852 | Train Accuracy: 99.875 | Test Loss: 0.2053455263376236 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 187 | Train Loss: 0.1974695473909378 | Train Accuracy: 99.875 | Test Loss: 0.20441897213459015 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 188 | Train Loss: 0.19656850397586823 | Train Accuracy: 99.875 | Test Loss: 0.20347118377685547 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 189 | Train Loss: 0.1956716924905777 | Train Accuracy: 99.875 | Test Loss: 0.20255248248577118 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 190 | Train Loss: 0.19477935135364532 | Train Accuracy: 99.875 | Test Loss: 0.20162153244018555 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 191 | Train Loss: 0.193892702460289 | Train Accuracy: 99.875 | Test Loss: 0.20071183145046234 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 192 | Train Loss: 0.19301143288612366 | Train Accuracy: 99.875 | Test Loss: 0.19980831444263458 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 193 | Train Loss: 0.1921357363462448 | Train Accuracy: 99.875 | Test Loss: 0.19891242682933807 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 194 | Train Loss: 0.1912636011838913 | Train Accuracy: 99.875 | Test Loss: 0.19801823794841766 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 195 | Train Loss: 0.19039523601531982 | Train Accuracy: 99.875 | Test Loss: 0.19711728394031525 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 196 | Train Loss: 0.18953116238117218 | Train Accuracy: 99.875 | Test Loss: 0.19622573256492615 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 197 | Train Loss: 0.18867185711860657 | Train Accuracy: 99.875 | Test Loss: 0.19532044231891632 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 198 | Train Loss: 0.18781737983226776 | Train Accuracy: 99.875 | Test Loss: 0.19444675743579865 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 199 | Train Loss: 0.18696743249893188 | Train Accuracy: 99.875 | Test Loss: 0.19354502856731415 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 200 | Train Loss: 0.18612094223499298 | Train Accuracy: 99.875 | Test Loss: 0.19268527626991272 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 201 | Train Loss: 0.18527741730213165 | Train Accuracy: 99.875 | Test Loss: 0.19178207218647003 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 202 | Train Loss: 0.18443794548511505 | Train Accuracy: 99.875 | Test Loss: 0.1909298300743103 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 203 | Train Loss: 0.183602973818779 | Train Accuracy: 99.875 | Test Loss: 0.19005049765110016 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 204 | Train Loss: 0.18276965618133545 | Train Accuracy: 99.875 | Test Loss: 0.1892024576663971 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 205 | Train Loss: 0.18194173276424408 | Train Accuracy: 99.875 | Test Loss: 0.18833637237548828 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 206 | Train Loss: 0.1811157912015915 | Train Accuracy: 99.875 | Test Loss: 0.18749213218688965 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 207 | Train Loss: 0.18029344081878662 | Train Accuracy: 99.875 | Test Loss: 0.18662086129188538 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 208 | Train Loss: 0.1794722080230713 | Train Accuracy: 99.875 | Test Loss: 0.1857689768075943 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 209 | Train Loss: 0.17865528166294098 | Train Accuracy: 99.875 | Test Loss: 0.18491290509700775 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 210 | Train Loss: 0.17784255743026733 | Train Accuracy: 99.875 | Test Loss: 0.18407048285007477 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 211 | Train Loss: 0.17703399062156677 | Train Accuracy: 99.875 | Test Loss: 0.1832277625799179 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 212 | Train Loss: 0.17622894048690796 | Train Accuracy: 99.875 | Test Loss: 0.18239156901836395 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 213 | Train Loss: 0.17542514204978943 | Train Accuracy: 99.875 | Test Loss: 0.1815512478351593 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 214 | Train Loss: 0.17462380230426788 | Train Accuracy: 99.875 | Test Loss: 0.18072067201137543 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 215 | Train Loss: 0.1738247126340866 | Train Accuracy: 99.875 | Test Loss: 0.17988631129264832 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 216 | Train Loss: 0.17302733659744263 | Train Accuracy: 99.875 | Test Loss: 0.17905890941619873 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 217 | Train Loss: 0.1722344011068344 | Train Accuracy: 99.875 | Test Loss: 0.17824086546897888 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 218 | Train Loss: 0.17144665122032166 | Train Accuracy: 99.875 | Test Loss: 0.17742721736431122 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 219 | Train Loss: 0.17066428065299988 | Train Accuracy: 99.875 | Test Loss: 0.1766171157360077 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 220 | Train Loss: 0.16988803446292877 | Train Accuracy: 99.875 | Test Loss: 0.17581889033317566 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 221 | Train Loss: 0.16911587119102478 | Train Accuracy: 99.875 | Test Loss: 0.17501698434352875 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 222 | Train Loss: 0.16834776103496552 | Train Accuracy: 99.875 | Test Loss: 0.1742345243692398 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 223 | Train Loss: 0.16758368909358978 | Train Accuracy: 99.875 | Test Loss: 0.17344026267528534 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 224 | Train Loss: 0.1668228805065155 | Train Accuracy: 99.875 | Test Loss: 0.17268022894859314 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 225 | Train Loss: 0.16606494784355164 | Train Accuracy: 99.875 | Test Loss: 0.1718960851430893 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 226 | Train Loss: 0.1653113067150116 | Train Accuracy: 99.875 | Test Loss: 0.17115096747875214 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 227 | Train Loss: 0.16456195712089539 | Train Accuracy: 99.875 | Test Loss: 0.17037400603294373 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 228 | Train Loss: 0.16381774842739105 | Train Accuracy: 99.875 | Test Loss: 0.1696329116821289 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 229 | Train Loss: 0.16307838261127472 | Train Accuracy: 99.875 | Test Loss: 0.16886310279369354 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 230 | Train Loss: 0.16234329342842102 | Train Accuracy: 99.875 | Test Loss: 0.1681307554244995 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 231 | Train Loss: 0.1616119146347046 | Train Accuracy: 99.875 | Test Loss: 0.16736730933189392 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 232 | Train Loss: 0.16088342666625977 | Train Accuracy: 99.875 | Test Loss: 0.166642427444458 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 233 | Train Loss: 0.16015945374965668 | Train Accuracy: 99.875 | Test Loss: 0.1658797264099121 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 234 | Train Loss: 0.1594386249780655 | Train Accuracy: 99.875 | Test Loss: 0.16517114639282227 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 235 | Train Loss: 0.15872211754322052 | Train Accuracy: 99.875 | Test Loss: 0.16440489888191223 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 236 | Train Loss: 0.158009871840477 | Train Accuracy: 99.875 | Test Loss: 0.1636950671672821 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 237 | Train Loss: 0.15730150043964386 | Train Accuracy: 99.875 | Test Loss: 0.1629425436258316 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 238 | Train Loss: 0.15659640729427338 | Train Accuracy: 99.875 | Test Loss: 0.16223934292793274 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 239 | Train Loss: 0.15589430928230286 | Train Accuracy: 99.875 | Test Loss: 0.16149120032787323 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 240 | Train Loss: 0.15519608557224274 | Train Accuracy: 99.875 | Test Loss: 0.16079947352409363 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 241 | Train Loss: 0.1545015126466751 | Train Accuracy: 99.875 | Test Loss: 0.16005727648735046 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 242 | Train Loss: 0.1538103222846985 | Train Accuracy: 99.875 | Test Loss: 0.15937493741512299 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 243 | Train Loss: 0.15312449634075165 | Train Accuracy: 99.875 | Test Loss: 0.15864750742912292 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 244 | Train Loss: 0.15244252979755402 | Train Accuracy: 99.875 | Test Loss: 0.1579703539609909 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 245 | Train Loss: 0.15176333487033844 | Train Accuracy: 99.875 | Test Loss: 0.1572525054216385 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 246 | Train Loss: 0.1510857790708542 | Train Accuracy: 99.875 | Test Loss: 0.15657489001750946 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 247 | Train Loss: 0.15041135251522064 | Train Accuracy: 99.875 | Test Loss: 0.15585777163505554 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 248 | Train Loss: 0.14973866939544678 | Train Accuracy: 99.875 | Test Loss: 0.15516746044158936 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 249 | Train Loss: 0.14907090365886688 | Train Accuracy: 99.875 | Test Loss: 0.15446051955223083 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 250 | Train Loss: 0.14840829372406006 | Train Accuracy: 99.875 | Test Loss: 0.15378601849079132 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 251 | Train Loss: 0.14774951338768005 | Train Accuracy: 99.875 | Test Loss: 0.15308460593223572 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 252 | Train Loss: 0.14709420502185822 | Train Accuracy: 99.875 | Test Loss: 0.15241901576519012 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 253 | Train Loss: 0.14644089341163635 | Train Accuracy: 99.875 | Test Loss: 0.1517266035079956 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 254 | Train Loss: 0.1457911878824234 | Train Accuracy: 99.875 | Test Loss: 0.1510576754808426 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 255 | Train Loss: 0.14514555037021637 | Train Accuracy: 99.875 | Test Loss: 0.15038323402404785 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 256 | Train Loss: 0.14450381696224213 | Train Accuracy: 100.0 | Test Loss: 0.14972254633903503 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 257 | Train Loss: 0.14386563003063202 | Train Accuracy: 100.0 | Test Loss: 0.1490548998117447 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 258 | Train Loss: 0.1432306468486786 | Train Accuracy: 100.0 | Test Loss: 0.14840009808540344 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 259 | Train Loss: 0.14259938895702362 | Train Accuracy: 100.0 | Test Loss: 0.1477375328540802 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 260 | Train Loss: 0.1419706493616104 | Train Accuracy: 100.0 | Test Loss: 0.1470966935157776 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 261 | Train Loss: 0.1413450539112091 | Train Accuracy: 100.0 | Test Loss: 0.14643897116184235 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 262 | Train Loss: 0.14072173833847046 | Train Accuracy: 100.0 | Test Loss: 0.14581076800823212 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 263 | Train Loss: 0.14010216295719147 | Train Accuracy: 100.0 | Test Loss: 0.14515021443367004 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 264 | Train Loss: 0.13948379456996918 | Train Accuracy: 100.0 | Test Loss: 0.14453038573265076 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 265 | Train Loss: 0.13886916637420654 | Train Accuracy: 100.0 | Test Loss: 0.1438605785369873 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 266 | Train Loss: 0.13825824856758118 | Train Accuracy: 100.0 | Test Loss: 0.14326244592666626 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 267 | Train Loss: 0.1376509964466095 | Train Accuracy: 100.0 | Test Loss: 0.14258845150470734 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 268 | Train Loss: 0.13704800605773926 | Train Accuracy: 100.0 | Test Loss: 0.14201940596103668 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 269 | Train Loss: 0.13644912838935852 | Train Accuracy: 100.0 | Test Loss: 0.1413317620754242 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 270 | Train Loss: 0.1358548253774643 | Train Accuracy: 100.0 | Test Loss: 0.14079605042934418 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 271 | Train Loss: 0.13526363670825958 | Train Accuracy: 100.0 | Test Loss: 0.14009195566177368 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 272 | Train Loss: 0.13467659056186676 | Train Accuracy: 100.0 | Test Loss: 0.13959145545959473 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 273 | Train Loss: 0.13409020006656647 | Train Accuracy: 100.0 | Test Loss: 0.13886304199695587 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 274 | Train Loss: 0.1335083544254303 | Train Accuracy: 100.0 | Test Loss: 0.13839904963970184 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 275 | Train Loss: 0.132928729057312 | Train Accuracy: 100.0 | Test Loss: 0.13764873147010803 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 276 | Train Loss: 0.13235360383987427 | Train Accuracy: 100.0 | Test Loss: 0.13722358644008636 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 277 | Train Loss: 0.131782665848732 | Train Accuracy: 100.0 | Test Loss: 0.13645276427268982 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 278 | Train Loss: 0.1312170922756195 | Train Accuracy: 100.0 | Test Loss: 0.13608700037002563 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 279 | Train Loss: 0.13065896928310394 | Train Accuracy: 100.0 | Test Loss: 0.1352684497833252 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 280 | Train Loss: 0.13010908663272858 | Train Accuracy: 100.0 | Test Loss: 0.13498981297016144 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 281 | Train Loss: 0.1295618861913681 | Train Accuracy: 100.0 | Test Loss: 0.1341107189655304 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 282 | Train Loss: 0.12902158498764038 | Train Accuracy: 100.0 | Test Loss: 0.13391590118408203 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 283 | Train Loss: 0.1284824013710022 | Train Accuracy: 100.0 | Test Loss: 0.13296645879745483 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 284 | Train Loss: 0.1279517114162445 | Train Accuracy: 100.0 | Test Loss: 0.13286148011684418 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 285 | Train Loss: 0.1274230033159256 | Train Accuracy: 99.875 | Test Loss: 0.13183894753456116 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 286 | Train Loss: 0.12690308690071106 | Train Accuracy: 100.0 | Test Loss: 0.1318379044532776 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 287 | Train Loss: 0.12638884782791138 | Train Accuracy: 99.875 | Test Loss: 0.13073214888572693 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 288 | Train Loss: 0.1258859485387802 | Train Accuracy: 100.0 | Test Loss: 0.13085126876831055 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 289 | Train Loss: 0.12538813054561615 | Train Accuracy: 99.875 | Test Loss: 0.12965436279773712 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 290 | Train Loss: 0.12490398436784744 | Train Accuracy: 100.0 | Test Loss: 0.1299036145210266 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 291 | Train Loss: 0.1244218572974205 | Train Accuracy: 99.875 | Test Loss: 0.12861080467700958 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 292 | Train Loss: 0.12395860254764557 | Train Accuracy: 100.0 | Test Loss: 0.12906543910503387 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 293 | Train Loss: 0.12353182584047318 | Train Accuracy: 99.875 | Test Loss: 0.12764279544353485 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 294 | Train Loss: 0.12311214208602905 | Train Accuracy: 100.0 | Test Loss: 0.12831948697566986 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 295 | Train Loss: 0.12271727621555328 | Train Accuracy: 99.875 | Test Loss: 0.1267441213130951 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 296 | Train Loss: 0.12233888357877731 | Train Accuracy: 100.0 | Test Loss: 0.12771344184875488 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 297 | Train Loss: 0.12201344966888428 | Train Accuracy: 99.875 | Test Loss: 0.12594610452651978 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 298 | Train Loss: 0.12167458981275558 | Train Accuracy: 100.0 | Test Loss: 0.12727883458137512 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 299 | Train Loss: 0.12145031988620758 | Train Accuracy: 99.75 | Test Loss: 0.12529955804347992 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 300 | Train Loss: 0.1211853101849556 | Train Accuracy: 100.0 | Test Loss: 0.12703557312488556 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 301 | Train Loss: 0.12105131149291992 | Train Accuracy: 99.75 | Test Loss: 0.12482704967260361 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 302 | Train Loss: 0.12087608128786087 | Train Accuracy: 99.875 | Test Loss: 0.12708111107349396 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 303 | Train Loss: 0.12090551108121872 | Train Accuracy: 99.75 | Test Loss: 0.12465931475162506 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 304 | Train Loss: 0.12089799344539642 | Train Accuracy: 99.875 | Test Loss: 0.12762191891670227 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 305 | Train Loss: 0.12118474394083023 | Train Accuracy: 99.75 | Test Loss: 0.12499547004699707 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 306 | Train Loss: 0.12147006392478943 | Train Accuracy: 99.75 | Test Loss: 0.1290442943572998 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 307 | Train Loss: 0.12224187701940536 | Train Accuracy: 99.5 | Test Loss: 0.12616729736328125 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 308 | Train Loss: 0.12295234203338623 | Train Accuracy: 99.375 | Test Loss: 0.13207532465457916 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 309 | Train Loss: 0.12469585239887238 | Train Accuracy: 99.5 | Test Loss: 0.12896299362182617 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 310 | Train Loss: 0.12612603604793549 | Train Accuracy: 99.25 | Test Loss: 0.1370806097984314 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 311 | Train Loss: 0.12892675399780273 | Train Accuracy: 99.25 | Test Loss: 0.13427938520908356 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 312 | Train Loss: 0.1318768858909607 | Train Accuracy: 99.125 | Test Loss: 0.14672541618347168 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 313 | Train Loss: 0.1373630166053772 | Train Accuracy: 98.5 | Test Loss: 0.14530611038208008 | Test Accuracy: 98.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 314 | Train Loss: 0.1434449702501297 | Train Accuracy: 98.625 | Test Loss: 0.16617503762245178 | Test Accuracy: 99.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 315 | Train Loss: 0.1547151505947113 | Train Accuracy: 98.0 | Test Loss: 0.16988137364387512 | Test Accuracy: 97.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 316 | Train Loss: 0.16863791644573212 | Train Accuracy: 96.5 | Test Loss: 0.21276041865348816 | Test Accuracy: 94.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 317 | Train Loss: 0.1970396339893341 | Train Accuracy: 94.875 | Test Loss: 0.24095185101032257 | Test Accuracy: 89.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 318 | Train Loss: 0.24032580852508545 | Train Accuracy: 90.625 | Test Loss: 0.37468889355659485 | Test Accuracy: 77.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 319 | Train Loss: 0.34604528546333313 | Train Accuracy: 79.25 | Test Loss: 0.5680074691772461 | Test Accuracy: 65.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 320 | Train Loss: 0.5700675249099731 | Train Accuracy: 65.75 | Test Loss: 1.1391139030456543 | Test Accuracy: 49.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 321 | Train Loss: 1.0681356191635132 | Train Accuracy: 51.5 | Test Loss: 1.4317684173583984 | Test Accuracy: 50.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 322 | Train Loss: 1.4448583126068115 | Train Accuracy: 49.875 | Test Loss: 0.4419507384300232 | Test Accuracy: 68.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 323 | Train Loss: 0.40940093994140625 | Train Accuracy: 75.125 | Test Loss: 0.5338076949119568 | Test Accuracy: 70.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 324 | Train Loss: 0.5312255620956421 | Train Accuracy: 68.375 | Test Loss: 0.8299363255500793 | Test Accuracy: 52.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 325 | Train Loss: 0.7630233764648438 | Train Accuracy: 55.00000000000001 | Test Loss: 1.024055004119873 | Test Accuracy: 52.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 326 | Train Loss: 1.0392297506332397 | Train Accuracy: 51.87500000000001 | Test Loss: 0.55519700050354 | Test Accuracy: 63.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 327 | Train Loss: 0.511953592300415 | Train Accuracy: 67.0 | Test Loss: 0.6179779171943665 | Test Accuracy: 65.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 328 | Train Loss: 0.6237709522247314 | Train Accuracy: 64.875 | Test Loss: 0.6173617243766785 | Test Accuracy: 59.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 329 | Train Loss: 0.561489999294281 | Train Accuracy: 61.5 | Test Loss: 0.6704641580581665 | Test Accuracy: 62.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 330 | Train Loss: 0.6818714737892151 | Train Accuracy: 62.0 | Test Loss: 0.47590383887290955 | Test Accuracy: 65.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 331 | Train Loss: 0.43234264850616455 | Train Accuracy: 71.75 | Test Loss: 0.45953452587127686 | Test Accuracy: 76.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 332 | Train Loss: 0.46279898285865784 | Train Accuracy: 72.625 | Test Loss: 0.40040165185928345 | Test Accuracy: 73.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 333 | Train Loss: 0.36047953367233276 | Train Accuracy: 79.375 | Test Loss: 0.36723312735557556 | Test Accuracy: 81.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 334 | Train Loss: 0.36486366391181946 | Train Accuracy: 80.5 | Test Loss: 0.3338872790336609 | Test Accuracy: 80.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 335 | Train Loss: 0.3002361059188843 | Train Accuracy: 84.625 | Test Loss: 0.2982819378376007 | Test Accuracy: 85.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 336 | Train Loss: 0.29080164432525635 | Train Accuracy: 86.125 | Test Loss: 0.2835598886013031 | Test Accuracy: 86.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 337 | Train Loss: 0.25567883253097534 | Train Accuracy: 89.375 | Test Loss: 0.24815766513347626 | Test Accuracy: 90.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 338 | Train Loss: 0.23978537321090698 | Train Accuracy: 90.375 | Test Loss: 0.23731951415538788 | Test Accuracy: 90.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 339 | Train Loss: 0.21500936150550842 | Train Accuracy: 92.375 | Test Loss: 0.20443163812160492 | Test Accuracy: 94.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 340 | Train Loss: 0.1980789452791214 | Train Accuracy: 94.75 | Test Loss: 0.19653885066509247 | Test Accuracy: 95.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 341 | Train Loss: 0.17932431399822235 | Train Accuracy: 95.625 | Test Loss: 0.1713428497314453 | Test Accuracy: 97.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 342 | Train Loss: 0.1662982553243637 | Train Accuracy: 97.125 | Test Loss: 0.16755475103855133 | Test Accuracy: 98.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 343 | Train Loss: 0.1541796177625656 | Train Accuracy: 97.375 | Test Loss: 0.14907503128051758 | Test Accuracy: 98.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 344 | Train Loss: 0.144767627120018 | Train Accuracy: 98.375 | Test Loss: 0.14763547480106354 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 345 | Train Loss: 0.13704121112823486 | Train Accuracy: 98.875 | Test Loss: 0.13545234501361847 | Test Accuracy: 98.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 346 | Train Loss: 0.1315138041973114 | Train Accuracy: 99.25 | Test Loss: 0.13623513281345367 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 347 | Train Loss: 0.1272832453250885 | Train Accuracy: 99.0 | Test Loss: 0.12801885604858398 | Test Accuracy: 99.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 348 | Train Loss: 0.12402936816215515 | Train Accuracy: 99.375 | Test Loss: 0.1292400360107422 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 349 | Train Loss: 0.12131950259208679 | Train Accuracy: 99.5 | Test Loss: 0.1234491690993309 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 350 | Train Loss: 0.1191873699426651 | Train Accuracy: 99.5 | Test Loss: 0.12460681796073914 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 351 | Train Loss: 0.1173812747001648 | Train Accuracy: 99.5 | Test Loss: 0.1204671710729599 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 352 | Train Loss: 0.11585303395986557 | Train Accuracy: 99.625 | Test Loss: 0.12116651237010956 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 353 | Train Loss: 0.11449289321899414 | Train Accuracy: 99.5 | Test Loss: 0.11820529401302338 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 354 | Train Loss: 0.11333896964788437 | Train Accuracy: 99.625 | Test Loss: 0.11866949498653412 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 355 | Train Loss: 0.11236274242401123 | Train Accuracy: 99.625 | Test Loss: 0.11646993458271027 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 356 | Train Loss: 0.1114659458398819 | Train Accuracy: 99.625 | Test Loss: 0.11663908511400223 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 357 | Train Loss: 0.11062860488891602 | Train Accuracy: 99.625 | Test Loss: 0.11495012789964676 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 358 | Train Loss: 0.10987033694982529 | Train Accuracy: 99.625 | Test Loss: 0.11489821970462799 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 359 | Train Loss: 0.10913043469190598 | Train Accuracy: 99.625 | Test Loss: 0.1135370209813118 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 360 | Train Loss: 0.10843972861766815 | Train Accuracy: 99.75 | Test Loss: 0.11340747773647308 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 361 | Train Loss: 0.10779222100973129 | Train Accuracy: 99.625 | Test Loss: 0.11222995817661285 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 362 | Train Loss: 0.10715445876121521 | Train Accuracy: 99.75 | Test Loss: 0.11202540993690491 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 363 | Train Loss: 0.10654880106449127 | Train Accuracy: 99.625 | Test Loss: 0.11100815236568451 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 364 | Train Loss: 0.10596548020839691 | Train Accuracy: 99.75 | Test Loss: 0.11078250408172607 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 365 | Train Loss: 0.1053846925497055 | Train Accuracy: 99.625 | Test Loss: 0.10982892662286758 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 366 | Train Loss: 0.10482706874608994 | Train Accuracy: 99.75 | Test Loss: 0.10959159582853317 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 367 | Train Loss: 0.104282908141613 | Train Accuracy: 99.75 | Test Loss: 0.10867921262979507 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 368 | Train Loss: 0.10376942157745361 | Train Accuracy: 99.75 | Test Loss: 0.10850469022989273 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 369 | Train Loss: 0.10325858741998672 | Train Accuracy: 99.75 | Test Loss: 0.10757805407047272 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 370 | Train Loss: 0.10274631530046463 | Train Accuracy: 99.75 | Test Loss: 0.10740233212709427 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 371 | Train Loss: 0.10225215554237366 | Train Accuracy: 99.875 | Test Loss: 0.10651299357414246 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 372 | Train Loss: 0.10174493491649628 | Train Accuracy: 99.75 | Test Loss: 0.10633691400289536 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 373 | Train Loss: 0.1012636125087738 | Train Accuracy: 99.875 | Test Loss: 0.1054854765534401 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 374 | Train Loss: 0.10076936334371567 | Train Accuracy: 99.75 | Test Loss: 0.10527117550373077 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 375 | Train Loss: 0.10028889775276184 | Train Accuracy: 99.875 | Test Loss: 0.10448642820119858 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 376 | Train Loss: 0.09980729967355728 | Train Accuracy: 99.75 | Test Loss: 0.10421311110258102 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 377 | Train Loss: 0.09933771938085556 | Train Accuracy: 99.875 | Test Loss: 0.10351550579071045 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 378 | Train Loss: 0.09887433797121048 | Train Accuracy: 99.75 | Test Loss: 0.10320041328668594 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 379 | Train Loss: 0.09842131286859512 | Train Accuracy: 99.875 | Test Loss: 0.10257323831319809 | Test Accuracy: 99.5\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 380 | Train Loss: 0.0979793518781662 | Train Accuracy: 99.75 | Test Loss: 0.1022513285279274 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 381 | Train Loss: 0.09754350781440735 | Train Accuracy: 99.875 | Test Loss: 0.10166319459676743 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 382 | Train Loss: 0.09711296856403351 | Train Accuracy: 99.875 | Test Loss: 0.10132436454296112 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 383 | Train Loss: 0.09668681025505066 | Train Accuracy: 99.875 | Test Loss: 0.10077331960201263 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 384 | Train Loss: 0.0962623730301857 | Train Accuracy: 99.875 | Test Loss: 0.10042529553174973 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 385 | Train Loss: 0.09584008902311325 | Train Accuracy: 99.875 | Test Loss: 0.09990546852350235 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 386 | Train Loss: 0.09542176127433777 | Train Accuracy: 99.875 | Test Loss: 0.09954389184713364 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 387 | Train Loss: 0.09500854462385178 | Train Accuracy: 99.875 | Test Loss: 0.0990583598613739 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 388 | Train Loss: 0.09459976106882095 | Train Accuracy: 99.875 | Test Loss: 0.09868770092725754 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 389 | Train Loss: 0.0941958948969841 | Train Accuracy: 99.875 | Test Loss: 0.09822402894496918 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 390 | Train Loss: 0.09379683434963226 | Train Accuracy: 99.875 | Test Loss: 0.09785348922014236 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 391 | Train Loss: 0.09340238571166992 | Train Accuracy: 99.875 | Test Loss: 0.09740758687257767 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 392 | Train Loss: 0.09301189333200455 | Train Accuracy: 99.875 | Test Loss: 0.09703359752893448 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 393 | Train Loss: 0.09262603521347046 | Train Accuracy: 99.875 | Test Loss: 0.09660957008600235 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 394 | Train Loss: 0.09224401414394379 | Train Accuracy: 99.875 | Test Loss: 0.09624256193637848 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 395 | Train Loss: 0.09186574816703796 | Train Accuracy: 99.875 | Test Loss: 0.09583476930856705 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 396 | Train Loss: 0.09149093180894852 | Train Accuracy: 99.875 | Test Loss: 0.0954708680510521 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 397 | Train Loss: 0.09111994504928589 | Train Accuracy: 99.875 | Test Loss: 0.09507009387016296 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 398 | Train Loss: 0.09075254201889038 | Train Accuracy: 99.875 | Test Loss: 0.09471166133880615 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 399 | Train Loss: 0.09038805961608887 | Train Accuracy: 99.875 | Test Loss: 0.09433011710643768 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 400 | Train Loss: 0.09002337604761124 | Train Accuracy: 99.875 | Test Loss: 0.09397044777870178 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 401 | Train Loss: 0.08966095000505447 | Train Accuracy: 99.875 | Test Loss: 0.09357922524213791 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 402 | Train Loss: 0.08929801732301712 | Train Accuracy: 100.0 | Test Loss: 0.09320546686649323 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 403 | Train Loss: 0.08893821388483047 | Train Accuracy: 100.0 | Test Loss: 0.09282677620649338 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 404 | Train Loss: 0.08857938647270203 | Train Accuracy: 100.0 | Test Loss: 0.09245770424604416 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 405 | Train Loss: 0.08822464942932129 | Train Accuracy: 100.0 | Test Loss: 0.09207750111818314 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 406 | Train Loss: 0.08787356317043304 | Train Accuracy: 100.0 | Test Loss: 0.09171224385499954 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 407 | Train Loss: 0.08752436190843582 | Train Accuracy: 100.0 | Test Loss: 0.0913388580083847 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 408 | Train Loss: 0.08717802166938782 | Train Accuracy: 100.0 | Test Loss: 0.0909743383526802 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 409 | Train Loss: 0.08683469891548157 | Train Accuracy: 100.0 | Test Loss: 0.09060093015432358 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 410 | Train Loss: 0.08649444580078125 | Train Accuracy: 100.0 | Test Loss: 0.0902344211935997 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 411 | Train Loss: 0.08615770190954208 | Train Accuracy: 100.0 | Test Loss: 0.08986057341098785 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 412 | Train Loss: 0.08582508563995361 | Train Accuracy: 100.0 | Test Loss: 0.08950889110565186 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 413 | Train Loss: 0.08549495786428452 | Train Accuracy: 100.0 | Test Loss: 0.08914798498153687 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 414 | Train Loss: 0.08516744524240494 | Train Accuracy: 100.0 | Test Loss: 0.08879833668470383 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 415 | Train Loss: 0.08484382182359695 | Train Accuracy: 100.0 | Test Loss: 0.08844832330942154 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 416 | Train Loss: 0.08452130854129791 | Train Accuracy: 100.0 | Test Loss: 0.08808255940675735 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 417 | Train Loss: 0.08419149369001389 | Train Accuracy: 100.0 | Test Loss: 0.08772344142198563 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 418 | Train Loss: 0.08386268466711044 | Train Accuracy: 100.0 | Test Loss: 0.08738095313310623 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 419 | Train Loss: 0.08353665471076965 | Train Accuracy: 100.0 | Test Loss: 0.08703231811523438 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 420 | Train Loss: 0.08321291953325272 | Train Accuracy: 100.0 | Test Loss: 0.0867014080286026 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 421 | Train Loss: 0.08289165049791336 | Train Accuracy: 100.0 | Test Loss: 0.08636230230331421 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 422 | Train Loss: 0.08257322013378143 | Train Accuracy: 100.0 | Test Loss: 0.08602946251630783 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 423 | Train Loss: 0.08225832879543304 | Train Accuracy: 100.0 | Test Loss: 0.08569789677858353 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 424 | Train Loss: 0.08194608241319656 | Train Accuracy: 100.0 | Test Loss: 0.08536939322948456 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 425 | Train Loss: 0.08163652569055557 | Train Accuracy: 100.0 | Test Loss: 0.08504625409841537 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 426 | Train Loss: 0.08132939040660858 | Train Accuracy: 100.0 | Test Loss: 0.0847245380282402 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 427 | Train Loss: 0.08102491497993469 | Train Accuracy: 100.0 | Test Loss: 0.08440644294023514 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 428 | Train Loss: 0.08072246611118317 | Train Accuracy: 100.0 | Test Loss: 0.08408895134925842 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 429 | Train Loss: 0.08042117208242416 | Train Accuracy: 100.0 | Test Loss: 0.08377375453710556 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 430 | Train Loss: 0.08012145757675171 | Train Accuracy: 100.0 | Test Loss: 0.08346422016620636 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 431 | Train Loss: 0.07982390373945236 | Train Accuracy: 100.0 | Test Loss: 0.08315496891736984 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 432 | Train Loss: 0.0795285776257515 | Train Accuracy: 100.0 | Test Loss: 0.08285047113895416 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 433 | Train Loss: 0.07923560589551926 | Train Accuracy: 100.0 | Test Loss: 0.08254627883434296 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 434 | Train Loss: 0.07894503325223923 | Train Accuracy: 100.0 | Test Loss: 0.08224235475063324 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 435 | Train Loss: 0.0786576047539711 | Train Accuracy: 100.0 | Test Loss: 0.08194600045681 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 436 | Train Loss: 0.07837210595607758 | Train Accuracy: 100.0 | Test Loss: 0.08164508640766144 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 437 | Train Loss: 0.0780886560678482 | Train Accuracy: 100.0 | Test Loss: 0.08135280758142471 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 438 | Train Loss: 0.07780709117650986 | Train Accuracy: 100.0 | Test Loss: 0.08105678111314774 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 439 | Train Loss: 0.07752735167741776 | Train Accuracy: 100.0 | Test Loss: 0.08077070116996765 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 440 | Train Loss: 0.07724928110837936 | Train Accuracy: 100.0 | Test Loss: 0.08047936856746674 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 441 | Train Loss: 0.07697295397520065 | Train Accuracy: 100.0 | Test Loss: 0.080196313560009 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 442 | Train Loss: 0.0766986757516861 | Train Accuracy: 100.0 | Test Loss: 0.0799117386341095 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 443 | Train Loss: 0.07642601430416107 | Train Accuracy: 100.0 | Test Loss: 0.0796339139342308 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 444 | Train Loss: 0.07615426182746887 | Train Accuracy: 100.0 | Test Loss: 0.07935148477554321 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 445 | Train Loss: 0.07588423043489456 | Train Accuracy: 100.0 | Test Loss: 0.07908062636852264 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 446 | Train Loss: 0.07561560720205307 | Train Accuracy: 100.0 | Test Loss: 0.07879388332366943 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 447 | Train Loss: 0.07534537464380264 | Train Accuracy: 100.0 | Test Loss: 0.07851618528366089 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 448 | Train Loss: 0.07507701218128204 | Train Accuracy: 100.0 | Test Loss: 0.07823877036571503 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 449 | Train Loss: 0.07480974495410919 | Train Accuracy: 100.0 | Test Loss: 0.07796275615692139 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 450 | Train Loss: 0.07454429566860199 | Train Accuracy: 100.0 | Test Loss: 0.07768821716308594 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 451 | Train Loss: 0.07428057491779327 | Train Accuracy: 100.0 | Test Loss: 0.0774165689945221 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 452 | Train Loss: 0.07401848584413528 | Train Accuracy: 100.0 | Test Loss: 0.07715143263339996 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 453 | Train Loss: 0.07375900447368622 | Train Accuracy: 100.0 | Test Loss: 0.07688527554273605 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 454 | Train Loss: 0.07350127398967743 | Train Accuracy: 100.0 | Test Loss: 0.07662053406238556 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 455 | Train Loss: 0.07324498891830444 | Train Accuracy: 100.0 | Test Loss: 0.07634810358285904 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 456 | Train Loss: 0.07298659533262253 | Train Accuracy: 100.0 | Test Loss: 0.07607761025428772 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 457 | Train Loss: 0.07273003458976746 | Train Accuracy: 100.0 | Test Loss: 0.07581495493650436 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 458 | Train Loss: 0.07247520983219147 | Train Accuracy: 100.0 | Test Loss: 0.07555137574672699 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 459 | Train Loss: 0.07222213596105576 | Train Accuracy: 100.0 | Test Loss: 0.07529347389936447 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 460 | Train Loss: 0.07197088748216629 | Train Accuracy: 100.0 | Test Loss: 0.07503724098205566 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 461 | Train Loss: 0.07172135263681412 | Train Accuracy: 100.0 | Test Loss: 0.07478302717208862 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 462 | Train Loss: 0.071473628282547 | Train Accuracy: 100.0 | Test Loss: 0.07453402131795883 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 463 | Train Loss: 0.07122756540775299 | Train Accuracy: 100.0 | Test Loss: 0.07428164035081863 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 464 | Train Loss: 0.07098305970430374 | Train Accuracy: 100.0 | Test Loss: 0.07403523474931717 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 465 | Train Loss: 0.07074011862277985 | Train Accuracy: 100.0 | Test Loss: 0.0737837627530098 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 466 | Train Loss: 0.07049871981143951 | Train Accuracy: 100.0 | Test Loss: 0.07354117929935455 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 467 | Train Loss: 0.07025863975286484 | Train Accuracy: 100.0 | Test Loss: 0.07329577952623367 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 468 | Train Loss: 0.07001996040344238 | Train Accuracy: 100.0 | Test Loss: 0.07305476069450378 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 469 | Train Loss: 0.06978257745504379 | Train Accuracy: 100.0 | Test Loss: 0.0728115364909172 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 470 | Train Loss: 0.06954644620418549 | Train Accuracy: 100.0 | Test Loss: 0.07257211953401566 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 471 | Train Loss: 0.06931172311306 | Train Accuracy: 100.0 | Test Loss: 0.07233323156833649 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 472 | Train Loss: 0.06907845288515091 | Train Accuracy: 100.0 | Test Loss: 0.07209409773349762 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 473 | Train Loss: 0.06884642690420151 | Train Accuracy: 100.0 | Test Loss: 0.07185288518667221 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 474 | Train Loss: 0.0686153694987297 | Train Accuracy: 100.0 | Test Loss: 0.07161737978458405 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 475 | Train Loss: 0.06838571280241013 | Train Accuracy: 100.0 | Test Loss: 0.07138228416442871 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 476 | Train Loss: 0.06815724819898605 | Train Accuracy: 100.0 | Test Loss: 0.0711522176861763 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 477 | Train Loss: 0.06793026626110077 | Train Accuracy: 100.0 | Test Loss: 0.07092172652482986 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 478 | Train Loss: 0.06770489364862442 | Train Accuracy: 100.0 | Test Loss: 0.07069627940654755 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 479 | Train Loss: 0.06748085469007492 | Train Accuracy: 100.0 | Test Loss: 0.07046842575073242 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 480 | Train Loss: 0.06725811958312988 | Train Accuracy: 100.0 | Test Loss: 0.07024484127759933 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 481 | Train Loss: 0.06703662127256393 | Train Accuracy: 100.0 | Test Loss: 0.07002009451389313 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 482 | Train Loss: 0.06681627035140991 | Train Accuracy: 100.0 | Test Loss: 0.06979837268590927 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 483 | Train Loss: 0.06659720838069916 | Train Accuracy: 100.0 | Test Loss: 0.06957656890153885 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 484 | Train Loss: 0.06637948751449585 | Train Accuracy: 100.0 | Test Loss: 0.06935690343379974 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 485 | Train Loss: 0.06616314500570297 | Train Accuracy: 100.0 | Test Loss: 0.06913825124502182 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 486 | Train Loss: 0.06594807654619217 | Train Accuracy: 100.0 | Test Loss: 0.06892335414886475 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 487 | Train Loss: 0.0657341405749321 | Train Accuracy: 100.0 | Test Loss: 0.06870846450328827 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 488 | Train Loss: 0.06552101671695709 | Train Accuracy: 100.0 | Test Loss: 0.06849372386932373 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 489 | Train Loss: 0.06530844420194626 | Train Accuracy: 100.0 | Test Loss: 0.06827965378761292 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 490 | Train Loss: 0.06509661674499512 | Train Accuracy: 100.0 | Test Loss: 0.06806842982769012 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 491 | Train Loss: 0.06488614529371262 | Train Accuracy: 100.0 | Test Loss: 0.06785682588815689 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 492 | Train Loss: 0.0646766945719719 | Train Accuracy: 100.0 | Test Loss: 0.06764587759971619 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 493 | Train Loss: 0.06446873396635056 | Train Accuracy: 100.0 | Test Loss: 0.06743654608726501 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 494 | Train Loss: 0.06426235288381577 | Train Accuracy: 100.0 | Test Loss: 0.0672295093536377 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 495 | Train Loss: 0.06405714154243469 | Train Accuracy: 100.0 | Test Loss: 0.06702270358800888 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 496 | Train Loss: 0.06385350972414017 | Train Accuracy: 100.0 | Test Loss: 0.06681656837463379 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 497 | Train Loss: 0.06365147233009338 | Train Accuracy: 100.0 | Test Loss: 0.06661605834960938 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 498 | Train Loss: 0.06345023959875107 | Train Accuracy: 100.0 | Test Loss: 0.06641753762960434 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 499 | Train Loss: 0.0632483959197998 | Train Accuracy: 100.0 | Test Loss: 0.06621959805488586 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 500 | Train Loss: 0.06304769963026047 | Train Accuracy: 100.0 | Test Loss: 0.06602083891630173 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 501 | Train Loss: 0.06284793466329575 | Train Accuracy: 100.0 | Test Loss: 0.06582362204790115 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 502 | Train Loss: 0.06264857947826385 | Train Accuracy: 100.0 | Test Loss: 0.06562530249357224 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 503 | Train Loss: 0.0624503493309021 | Train Accuracy: 100.0 | Test Loss: 0.0654294416308403 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 504 | Train Loss: 0.062253206968307495 | Train Accuracy: 100.0 | Test Loss: 0.06523247808218002 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 505 | Train Loss: 0.062057193368673325 | Train Accuracy: 100.0 | Test Loss: 0.06503812223672867 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 506 | Train Loss: 0.0618622861802578 | Train Accuracy: 100.0 | Test Loss: 0.0648452416062355 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 507 | Train Loss: 0.061668261885643005 | Train Accuracy: 100.0 | Test Loss: 0.06465411186218262 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 508 | Train Loss: 0.06147529557347298 | Train Accuracy: 100.0 | Test Loss: 0.06446380168199539 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 509 | Train Loss: 0.061283424496650696 | Train Accuracy: 100.0 | Test Loss: 0.06427374482154846 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 510 | Train Loss: 0.061092596501111984 | Train Accuracy: 100.0 | Test Loss: 0.0640842542052269 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 511 | Train Loss: 0.06090281531214714 | Train Accuracy: 100.0 | Test Loss: 0.06389587372541428 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 512 | Train Loss: 0.06071405112743378 | Train Accuracy: 100.0 | Test Loss: 0.06370799988508224 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 513 | Train Loss: 0.06052623316645622 | Train Accuracy: 100.0 | Test Loss: 0.06352154165506363 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 514 | Train Loss: 0.06033928692340851 | Train Accuracy: 100.0 | Test Loss: 0.06333398073911667 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 515 | Train Loss: 0.06015333905816078 | Train Accuracy: 100.0 | Test Loss: 0.06315142661333084 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 516 | Train Loss: 0.05996842682361603 | Train Accuracy: 100.0 | Test Loss: 0.06296562403440475 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 517 | Train Loss: 0.05978452414274216 | Train Accuracy: 100.0 | Test Loss: 0.06278442591428757 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 518 | Train Loss: 0.05960157886147499 | Train Accuracy: 100.0 | Test Loss: 0.06260045617818832 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 519 | Train Loss: 0.059419624507427216 | Train Accuracy: 100.0 | Test Loss: 0.06242143362760544 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 520 | Train Loss: 0.059238631278276443 | Train Accuracy: 100.0 | Test Loss: 0.06223936751484871 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 521 | Train Loss: 0.05905861780047417 | Train Accuracy: 100.0 | Test Loss: 0.06206154823303223 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 522 | Train Loss: 0.0588795505464077 | Train Accuracy: 100.0 | Test Loss: 0.06188291311264038 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 523 | Train Loss: 0.05870115011930466 | Train Accuracy: 100.0 | Test Loss: 0.061707887798547745 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 524 | Train Loss: 0.05852331966161728 | Train Accuracy: 100.0 | Test Loss: 0.06152884289622307 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 525 | Train Loss: 0.058346375823020935 | Train Accuracy: 100.0 | Test Loss: 0.061355311423540115 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 526 | Train Loss: 0.058170385658741 | Train Accuracy: 100.0 | Test Loss: 0.061177920550107956 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 527 | Train Loss: 0.05799530819058418 | Train Accuracy: 100.0 | Test Loss: 0.061005037277936935 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 528 | Train Loss: 0.05782109126448631 | Train Accuracy: 100.0 | Test Loss: 0.06082964688539505 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 529 | Train Loss: 0.057647477835416794 | Train Accuracy: 100.0 | Test Loss: 0.06065814942121506 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 530 | Train Loss: 0.05747441574931145 | Train Accuracy: 100.0 | Test Loss: 0.06048431620001793 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 531 | Train Loss: 0.05730224400758743 | Train Accuracy: 100.0 | Test Loss: 0.06031544506549835 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 532 | Train Loss: 0.05713098496198654 | Train Accuracy: 100.0 | Test Loss: 0.06014379486441612 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 533 | Train Loss: 0.05696059390902519 | Train Accuracy: 100.0 | Test Loss: 0.05997607111930847 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 534 | Train Loss: 0.05679110437631607 | Train Accuracy: 100.0 | Test Loss: 0.05980619415640831 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 535 | Train Loss: 0.056622304022312164 | Train Accuracy: 100.0 | Test Loss: 0.05963932350277901 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 536 | Train Loss: 0.056454017758369446 | Train Accuracy: 100.0 | Test Loss: 0.05947026237845421 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 537 | Train Loss: 0.0562865249812603 | Train Accuracy: 100.0 | Test Loss: 0.05930589511990547 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 538 | Train Loss: 0.056119851768016815 | Train Accuracy: 100.0 | Test Loss: 0.0591401644051075 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 539 | Train Loss: 0.05595429614186287 | Train Accuracy: 100.0 | Test Loss: 0.058976657688617706 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 540 | Train Loss: 0.05578910559415817 | Train Accuracy: 100.0 | Test Loss: 0.0588141605257988 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 541 | Train Loss: 0.055624645203351974 | Train Accuracy: 100.0 | Test Loss: 0.05865401029586792 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 542 | Train Loss: 0.05546062812209129 | Train Accuracy: 100.0 | Test Loss: 0.05848686024546623 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 543 | Train Loss: 0.05529593676328659 | Train Accuracy: 100.0 | Test Loss: 0.05832388252019882 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 544 | Train Loss: 0.055132050067186356 | Train Accuracy: 100.0 | Test Loss: 0.05816096067428589 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 545 | Train Loss: 0.05496906489133835 | Train Accuracy: 100.0 | Test Loss: 0.05799628049135208 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 546 | Train Loss: 0.05480562150478363 | Train Accuracy: 100.0 | Test Loss: 0.05783059075474739 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 547 | Train Loss: 0.054642800241708755 | Train Accuracy: 100.0 | Test Loss: 0.057668883353471756 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 548 | Train Loss: 0.054480962455272675 | Train Accuracy: 100.0 | Test Loss: 0.05750654637813568 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 549 | Train Loss: 0.054320078343153 | Train Accuracy: 100.0 | Test Loss: 0.05734220892190933 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 550 | Train Loss: 0.05415993928909302 | Train Accuracy: 100.0 | Test Loss: 0.0571775808930397 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 551 | Train Loss: 0.05400106683373451 | Train Accuracy: 100.0 | Test Loss: 0.05701455846428871 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 552 | Train Loss: 0.05384291708469391 | Train Accuracy: 100.0 | Test Loss: 0.05685141310095787 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 553 | Train Loss: 0.05368504300713539 | Train Accuracy: 100.0 | Test Loss: 0.056690387427806854 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 554 | Train Loss: 0.05352783203125 | Train Accuracy: 100.0 | Test Loss: 0.05652929097414017 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 555 | Train Loss: 0.05337105318903923 | Train Accuracy: 100.0 | Test Loss: 0.05637017637491226 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 556 | Train Loss: 0.05321478098630905 | Train Accuracy: 100.0 | Test Loss: 0.05620820075273514 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 557 | Train Loss: 0.05305783450603485 | Train Accuracy: 100.0 | Test Loss: 0.056046776473522186 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 558 | Train Loss: 0.05290144309401512 | Train Accuracy: 100.0 | Test Loss: 0.05588642135262489 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 559 | Train Loss: 0.05274493992328644 | Train Accuracy: 100.0 | Test Loss: 0.05572415143251419 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 560 | Train Loss: 0.05258876830339432 | Train Accuracy: 100.0 | Test Loss: 0.0555642768740654 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 561 | Train Loss: 0.052433013916015625 | Train Accuracy: 100.0 | Test Loss: 0.05540650337934494 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 562 | Train Loss: 0.05227767303586006 | Train Accuracy: 100.0 | Test Loss: 0.05524653196334839 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 563 | Train Loss: 0.05212078616023064 | Train Accuracy: 100.0 | Test Loss: 0.055086053907871246 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 564 | Train Loss: 0.05196499824523926 | Train Accuracy: 100.0 | Test Loss: 0.05492468550801277 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 565 | Train Loss: 0.05180945247411728 | Train Accuracy: 100.0 | Test Loss: 0.05476192384958267 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 566 | Train Loss: 0.05165240168571472 | Train Accuracy: 100.0 | Test Loss: 0.05458866059780121 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 567 | Train Loss: 0.05149249732494354 | Train Accuracy: 100.0 | Test Loss: 0.05441345274448395 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 568 | Train Loss: 0.05133220553398132 | Train Accuracy: 100.0 | Test Loss: 0.05423871800303459 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 569 | Train Loss: 0.05117124319076538 | Train Accuracy: 100.0 | Test Loss: 0.054064493626356125 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 570 | Train Loss: 0.051011428236961365 | Train Accuracy: 100.0 | Test Loss: 0.05389261618256569 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 571 | Train Loss: 0.05085330456495285 | Train Accuracy: 100.0 | Test Loss: 0.053719013929367065 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 572 | Train Loss: 0.05069296061992645 | Train Accuracy: 100.0 | Test Loss: 0.053544268012046814 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 573 | Train Loss: 0.050530340522527695 | Train Accuracy: 100.0 | Test Loss: 0.05336982011795044 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 574 | Train Loss: 0.05036671459674835 | Train Accuracy: 100.0 | Test Loss: 0.053181588649749756 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 575 | Train Loss: 0.05020177736878395 | Train Accuracy: 100.0 | Test Loss: 0.05300111696124077 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 576 | Train Loss: 0.050038184970617294 | Train Accuracy: 100.0 | Test Loss: 0.05282469466328621 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 577 | Train Loss: 0.04987601190805435 | Train Accuracy: 100.0 | Test Loss: 0.052649617195129395 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 578 | Train Loss: 0.04971176013350487 | Train Accuracy: 100.0 | Test Loss: 0.05247682332992554 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 579 | Train Loss: 0.049549076706171036 | Train Accuracy: 100.0 | Test Loss: 0.05230443924665451 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 580 | Train Loss: 0.04938776418566704 | Train Accuracy: 100.0 | Test Loss: 0.05213463306427002 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 581 | Train Loss: 0.04922787472605705 | Train Accuracy: 100.0 | Test Loss: 0.051965389400720596 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 582 | Train Loss: 0.04906952381134033 | Train Accuracy: 100.0 | Test Loss: 0.05179975554347038 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 583 | Train Loss: 0.04891280084848404 | Train Accuracy: 100.0 | Test Loss: 0.05163470655679703 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 584 | Train Loss: 0.048757150769233704 | Train Accuracy: 100.0 | Test Loss: 0.05147237330675125 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 585 | Train Loss: 0.048602648079395294 | Train Accuracy: 100.0 | Test Loss: 0.051311444491147995 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 586 | Train Loss: 0.048449113965034485 | Train Accuracy: 100.0 | Test Loss: 0.05115118250250816 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 587 | Train Loss: 0.04829676076769829 | Train Accuracy: 100.0 | Test Loss: 0.05099288001656532 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 588 | Train Loss: 0.048143643885850906 | Train Accuracy: 100.0 | Test Loss: 0.050829194486141205 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 589 | Train Loss: 0.04798654839396477 | Train Accuracy: 100.0 | Test Loss: 0.050665706396102905 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 590 | Train Loss: 0.04783066734671593 | Train Accuracy: 100.0 | Test Loss: 0.05050422623753548 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 591 | Train Loss: 0.04767622426152229 | Train Accuracy: 100.0 | Test Loss: 0.05034518241882324 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 592 | Train Loss: 0.04752301052212715 | Train Accuracy: 100.0 | Test Loss: 0.05018752068281174 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 593 | Train Loss: 0.047372475266456604 | Train Accuracy: 100.0 | Test Loss: 0.050035297870635986 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 594 | Train Loss: 0.047226738184690475 | Train Accuracy: 100.0 | Test Loss: 0.04988698288798332 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 595 | Train Loss: 0.04708312079310417 | Train Accuracy: 100.0 | Test Loss: 0.049747124314308167 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 596 | Train Loss: 0.04694387689232826 | Train Accuracy: 100.0 | Test Loss: 0.049608759582042694 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 597 | Train Loss: 0.04680708795785904 | Train Accuracy: 100.0 | Test Loss: 0.04946935549378395 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 598 | Train Loss: 0.04667117819190025 | Train Accuracy: 100.0 | Test Loss: 0.04933253675699234 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 599 | Train Loss: 0.04653625562787056 | Train Accuracy: 100.0 | Test Loss: 0.04920222982764244 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 600 | Train Loss: 0.04640227183699608 | Train Accuracy: 100.0 | Test Loss: 0.04907241091132164 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 601 | Train Loss: 0.046270743012428284 | Train Accuracy: 100.0 | Test Loss: 0.04894357919692993 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 602 | Train Loss: 0.04614073783159256 | Train Accuracy: 100.0 | Test Loss: 0.048817701637744904 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 603 | Train Loss: 0.04601274058222771 | Train Accuracy: 100.0 | Test Loss: 0.04869488999247551 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 604 | Train Loss: 0.04588745906949043 | Train Accuracy: 100.0 | Test Loss: 0.04857250675559044 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 605 | Train Loss: 0.04576285555958748 | Train Accuracy: 100.0 | Test Loss: 0.04845205321907997 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 606 | Train Loss: 0.04563967511057854 | Train Accuracy: 100.0 | Test Loss: 0.048332251608371735 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 607 | Train Loss: 0.04551798850297928 | Train Accuracy: 100.0 | Test Loss: 0.04821239039301872 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 608 | Train Loss: 0.04539727047085762 | Train Accuracy: 100.0 | Test Loss: 0.048093050718307495 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 609 | Train Loss: 0.04527738317847252 | Train Accuracy: 100.0 | Test Loss: 0.04797372594475746 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 610 | Train Loss: 0.045158300548791885 | Train Accuracy: 100.0 | Test Loss: 0.04785599559545517 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 611 | Train Loss: 0.04504098743200302 | Train Accuracy: 100.0 | Test Loss: 0.047739189118146896 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 612 | Train Loss: 0.04492463916540146 | Train Accuracy: 100.0 | Test Loss: 0.04762182757258415 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 613 | Train Loss: 0.04480886459350586 | Train Accuracy: 100.0 | Test Loss: 0.04750524088740349 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 614 | Train Loss: 0.04469368979334831 | Train Accuracy: 100.0 | Test Loss: 0.04738979414105415 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 615 | Train Loss: 0.04457930475473404 | Train Accuracy: 100.0 | Test Loss: 0.04727433621883392 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 616 | Train Loss: 0.04446547478437424 | Train Accuracy: 100.0 | Test Loss: 0.0471593402326107 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 617 | Train Loss: 0.04435236006975174 | Train Accuracy: 100.0 | Test Loss: 0.047046057879924774 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 618 | Train Loss: 0.044240109622478485 | Train Accuracy: 100.0 | Test Loss: 0.04693245887756348 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 619 | Train Loss: 0.044128384441137314 | Train Accuracy: 100.0 | Test Loss: 0.04681926220655441 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 620 | Train Loss: 0.04401719942688942 | Train Accuracy: 100.0 | Test Loss: 0.046706631779670715 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 621 | Train Loss: 0.043906524777412415 | Train Accuracy: 100.0 | Test Loss: 0.04659441486001015 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 622 | Train Loss: 0.04379649832844734 | Train Accuracy: 100.0 | Test Loss: 0.04648374021053314 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 623 | Train Loss: 0.0436871312558651 | Train Accuracy: 100.0 | Test Loss: 0.046373236924409866 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 624 | Train Loss: 0.043578337877988815 | Train Accuracy: 100.0 | Test Loss: 0.046263329684734344 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 625 | Train Loss: 0.04347015172243118 | Train Accuracy: 100.0 | Test Loss: 0.04615410789847374 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 626 | Train Loss: 0.04336252063512802 | Train Accuracy: 100.0 | Test Loss: 0.0460452064871788 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 627 | Train Loss: 0.043255385011434555 | Train Accuracy: 100.0 | Test Loss: 0.04593677073717117 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 628 | Train Loss: 0.04314875602722168 | Train Accuracy: 100.0 | Test Loss: 0.0458298958837986 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 629 | Train Loss: 0.04304265230894089 | Train Accuracy: 100.0 | Test Loss: 0.04572276026010513 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 630 | Train Loss: 0.042937032878398895 | Train Accuracy: 100.0 | Test Loss: 0.04561604559421539 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 631 | Train Loss: 0.042831916362047195 | Train Accuracy: 100.0 | Test Loss: 0.045510195195674896 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 632 | Train Loss: 0.04272737354040146 | Train Accuracy: 100.0 | Test Loss: 0.045405227690935135 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 633 | Train Loss: 0.04262339323759079 | Train Accuracy: 100.0 | Test Loss: 0.04530033469200134 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 634 | Train Loss: 0.04251988232135773 | Train Accuracy: 100.0 | Test Loss: 0.0451955609023571 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 635 | Train Loss: 0.04241684824228287 | Train Accuracy: 100.0 | Test Loss: 0.04509129375219345 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 636 | Train Loss: 0.04231427237391472 | Train Accuracy: 100.0 | Test Loss: 0.04498700052499771 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 637 | Train Loss: 0.04221215099096298 | Train Accuracy: 100.0 | Test Loss: 0.0448831170797348 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 638 | Train Loss: 0.042110491544008255 | Train Accuracy: 100.0 | Test Loss: 0.04478003829717636 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 639 | Train Loss: 0.042009275406599045 | Train Accuracy: 100.0 | Test Loss: 0.04467620328068733 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 640 | Train Loss: 0.04190853610634804 | Train Accuracy: 100.0 | Test Loss: 0.0445735938847065 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 641 | Train Loss: 0.04180823266506195 | Train Accuracy: 100.0 | Test Loss: 0.04447133094072342 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 642 | Train Loss: 0.041708387434482574 | Train Accuracy: 100.0 | Test Loss: 0.04437003657221794 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 643 | Train Loss: 0.041608989238739014 | Train Accuracy: 100.0 | Test Loss: 0.044269390404224396 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 644 | Train Loss: 0.04151003807783127 | Train Accuracy: 100.0 | Test Loss: 0.04416913539171219 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 645 | Train Loss: 0.04141151160001755 | Train Accuracy: 100.0 | Test Loss: 0.04406937584280968 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 646 | Train Loss: 0.04131341725587845 | Train Accuracy: 100.0 | Test Loss: 0.04397051781415939 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 647 | Train Loss: 0.041215747594833374 | Train Accuracy: 100.0 | Test Loss: 0.04387206584215164 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 648 | Train Loss: 0.04111851751804352 | Train Accuracy: 100.0 | Test Loss: 0.04377397522330284 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 649 | Train Loss: 0.041021693497896194 | Train Accuracy: 100.0 | Test Loss: 0.04367631673812866 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 650 | Train Loss: 0.0409252867102623 | Train Accuracy: 100.0 | Test Loss: 0.04357894882559776 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 651 | Train Loss: 0.040829189121723175 | Train Accuracy: 100.0 | Test Loss: 0.0434827096760273 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 652 | Train Loss: 0.04073338583111763 | Train Accuracy: 100.0 | Test Loss: 0.04338674619793892 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 653 | Train Loss: 0.040637992322444916 | Train Accuracy: 100.0 | Test Loss: 0.04329105466604233 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 654 | Train Loss: 0.04054301232099533 | Train Accuracy: 100.0 | Test Loss: 0.04319567233324051 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 655 | Train Loss: 0.04044844210147858 | Train Accuracy: 100.0 | Test Loss: 0.04309976473450661 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 656 | Train Loss: 0.04035430774092674 | Train Accuracy: 100.0 | Test Loss: 0.04300553351640701 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 657 | Train Loss: 0.04026065766811371 | Train Accuracy: 100.0 | Test Loss: 0.042911600321531296 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 658 | Train Loss: 0.04016739875078201 | Train Accuracy: 100.0 | Test Loss: 0.04281768202781677 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 659 | Train Loss: 0.04007453843951225 | Train Accuracy: 100.0 | Test Loss: 0.04272456467151642 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 660 | Train Loss: 0.039982061833143234 | Train Accuracy: 100.0 | Test Loss: 0.04263200983405113 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 661 | Train Loss: 0.039889976382255554 | Train Accuracy: 100.0 | Test Loss: 0.04253985360264778 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 662 | Train Loss: 0.039798278361558914 | Train Accuracy: 100.0 | Test Loss: 0.04244812950491905 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 663 | Train Loss: 0.03970696032047272 | Train Accuracy: 100.0 | Test Loss: 0.042356546968221664 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 664 | Train Loss: 0.03961603343486786 | Train Accuracy: 100.0 | Test Loss: 0.04226543381810188 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 665 | Train Loss: 0.03952546417713165 | Train Accuracy: 100.0 | Test Loss: 0.04217473417520523 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 666 | Train Loss: 0.03943528234958649 | Train Accuracy: 100.0 | Test Loss: 0.04208468273282051 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 667 | Train Loss: 0.03934544324874878 | Train Accuracy: 100.0 | Test Loss: 0.04199478030204773 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 668 | Train Loss: 0.039255984127521515 | Train Accuracy: 100.0 | Test Loss: 0.04190511628985405 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 669 | Train Loss: 0.0391668938100338 | Train Accuracy: 100.0 | Test Loss: 0.04181584343314171 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 670 | Train Loss: 0.03907817229628563 | Train Accuracy: 100.0 | Test Loss: 0.04172692075371742 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 671 | Train Loss: 0.03898980841040611 | Train Accuracy: 100.0 | Test Loss: 0.041638243943452835 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 672 | Train Loss: 0.03890182077884674 | Train Accuracy: 100.0 | Test Loss: 0.04154997318983078 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 673 | Train Loss: 0.03881419077515602 | Train Accuracy: 100.0 | Test Loss: 0.041460998356342316 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 674 | Train Loss: 0.03872692584991455 | Train Accuracy: 100.0 | Test Loss: 0.04137382283806801 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 675 | Train Loss: 0.03864004835486412 | Train Accuracy: 100.0 | Test Loss: 0.041286762803792953 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 676 | Train Loss: 0.038553595542907715 | Train Accuracy: 100.0 | Test Loss: 0.041194744408130646 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 677 | Train Loss: 0.038467783480882645 | Train Accuracy: 100.0 | Test Loss: 0.04110497236251831 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 678 | Train Loss: 0.03838232904672623 | Train Accuracy: 100.0 | Test Loss: 0.04101657122373581 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 679 | Train Loss: 0.03829720988869667 | Train Accuracy: 100.0 | Test Loss: 0.04092894867062569 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 680 | Train Loss: 0.03821243718266487 | Train Accuracy: 100.0 | Test Loss: 0.04084199666976929 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 681 | Train Loss: 0.03812800720334053 | Train Accuracy: 100.0 | Test Loss: 0.04075559973716736 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 682 | Train Loss: 0.03804391622543335 | Train Accuracy: 100.0 | Test Loss: 0.04066966101527214 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 683 | Train Loss: 0.03796016052365303 | Train Accuracy: 100.0 | Test Loss: 0.04058420658111572 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 684 | Train Loss: 0.037876732647418976 | Train Accuracy: 100.0 | Test Loss: 0.04049920290708542 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 685 | Train Loss: 0.03779364377260208 | Train Accuracy: 100.0 | Test Loss: 0.04041493311524391 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 686 | Train Loss: 0.037710897624492645 | Train Accuracy: 100.0 | Test Loss: 0.04033088684082031 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 687 | Train Loss: 0.037628427147865295 | Train Accuracy: 100.0 | Test Loss: 0.04024805501103401 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 688 | Train Loss: 0.037546101957559586 | Train Accuracy: 100.0 | Test Loss: 0.04016517475247383 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 689 | Train Loss: 0.03746410459280014 | Train Accuracy: 100.0 | Test Loss: 0.040082547813653946 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 690 | Train Loss: 0.037382423877716064 | Train Accuracy: 100.0 | Test Loss: 0.040000248700380325 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 691 | Train Loss: 0.03730108216404915 | Train Accuracy: 100.0 | Test Loss: 0.03991829603910446 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 692 | Train Loss: 0.03722004219889641 | Train Accuracy: 100.0 | Test Loss: 0.03983606398105621 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 693 | Train Loss: 0.03713931888341904 | Train Accuracy: 100.0 | Test Loss: 0.039754368364810944 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 694 | Train Loss: 0.037058912217617035 | Train Accuracy: 100.0 | Test Loss: 0.03967273607850075 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 695 | Train Loss: 0.03697880730032921 | Train Accuracy: 100.0 | Test Loss: 0.03958858922123909 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 696 | Train Loss: 0.03689902275800705 | Train Accuracy: 100.0 | Test Loss: 0.03950483724474907 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 697 | Train Loss: 0.03681955859065056 | Train Accuracy: 100.0 | Test Loss: 0.03942149505019188 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 698 | Train Loss: 0.03674037754535675 | Train Accuracy: 100.0 | Test Loss: 0.03933826833963394 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 699 | Train Loss: 0.03666146844625473 | Train Accuracy: 100.0 | Test Loss: 0.03925561159849167 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 700 | Train Loss: 0.03658287227153778 | Train Accuracy: 100.0 | Test Loss: 0.039173346012830734 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 701 | Train Loss: 0.036504581570625305 | Train Accuracy: 100.0 | Test Loss: 0.03909146785736084 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 702 | Train Loss: 0.036426592618227005 | Train Accuracy: 100.0 | Test Loss: 0.039006493985652924 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 703 | Train Loss: 0.03634880110621452 | Train Accuracy: 100.0 | Test Loss: 0.03892352804541588 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 704 | Train Loss: 0.03627132251858711 | Train Accuracy: 100.0 | Test Loss: 0.03884151950478554 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 705 | Train Loss: 0.03619414567947388 | Train Accuracy: 100.0 | Test Loss: 0.0387602262198925 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 706 | Train Loss: 0.03611726686358452 | Train Accuracy: 100.0 | Test Loss: 0.03867945447564125 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 707 | Train Loss: 0.03604068607091904 | Train Accuracy: 100.0 | Test Loss: 0.038599155843257904 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 708 | Train Loss: 0.03596440330147743 | Train Accuracy: 100.0 | Test Loss: 0.038519296795129776 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 709 | Train Loss: 0.035888414829969406 | Train Accuracy: 100.0 | Test Loss: 0.03843983635306358 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 710 | Train Loss: 0.035812705755233765 | Train Accuracy: 100.0 | Test Loss: 0.03836078196763992 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 711 | Train Loss: 0.035737279802560806 | Train Accuracy: 100.0 | Test Loss: 0.038282427936792374 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 712 | Train Loss: 0.03566212207078934 | Train Accuracy: 100.0 | Test Loss: 0.03820406273007393 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 713 | Train Loss: 0.035587240010499954 | Train Accuracy: 100.0 | Test Loss: 0.03812607377767563 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 714 | Train Loss: 0.03551265224814415 | Train Accuracy: 100.0 | Test Loss: 0.038048386573791504 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 715 | Train Loss: 0.03543834388256073 | Train Accuracy: 100.0 | Test Loss: 0.03797108680009842 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 716 | Train Loss: 0.03536432608962059 | Train Accuracy: 100.0 | Test Loss: 0.03789317235350609 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 717 | Train Loss: 0.035290587693452835 | Train Accuracy: 100.0 | Test Loss: 0.037816207855939865 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 718 | Train Loss: 0.03521713986992836 | Train Accuracy: 100.0 | Test Loss: 0.037739720195531845 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 719 | Train Loss: 0.035143982619047165 | Train Accuracy: 100.0 | Test Loss: 0.03766364976763725 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 720 | Train Loss: 0.035071082413196564 | Train Accuracy: 100.0 | Test Loss: 0.037587955594062805 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 721 | Train Loss: 0.034998469054698944 | Train Accuracy: 100.0 | Test Loss: 0.03751259297132492 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 722 | Train Loss: 0.034926120191812515 | Train Accuracy: 100.0 | Test Loss: 0.037437550723552704 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 723 | Train Loss: 0.03485405445098877 | Train Accuracy: 100.0 | Test Loss: 0.03736284747719765 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 724 | Train Loss: 0.03478224575519562 | Train Accuracy: 100.0 | Test Loss: 0.03728845715522766 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 725 | Train Loss: 0.034710727632045746 | Train Accuracy: 100.0 | Test Loss: 0.037214361131191254 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 726 | Train Loss: 0.03463945910334587 | Train Accuracy: 100.0 | Test Loss: 0.0371406227350235 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 727 | Train Loss: 0.034568462520837784 | Train Accuracy: 100.0 | Test Loss: 0.037066929042339325 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 728 | Train Loss: 0.03449772298336029 | Train Accuracy: 100.0 | Test Loss: 0.036993563175201416 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 729 | Train Loss: 0.03442725911736488 | Train Accuracy: 100.0 | Test Loss: 0.03692018613219261 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 730 | Train Loss: 0.034357067197561264 | Train Accuracy: 100.0 | Test Loss: 0.03684705123305321 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 731 | Train Loss: 0.03428712859749794 | Train Accuracy: 100.0 | Test Loss: 0.036774542182683945 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 732 | Train Loss: 0.03421744704246521 | Train Accuracy: 100.0 | Test Loss: 0.03670224919915199 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 733 | Train Loss: 0.034148022532463074 | Train Accuracy: 100.0 | Test Loss: 0.03663032129406929 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 734 | Train Loss: 0.03407885879278183 | Train Accuracy: 100.0 | Test Loss: 0.036558590829372406 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 735 | Train Loss: 0.034009940922260284 | Train Accuracy: 100.0 | Test Loss: 0.03648732602596283 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 736 | Train Loss: 0.03394129127264023 | Train Accuracy: 100.0 | Test Loss: 0.03641536086797714 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 737 | Train Loss: 0.03387289121747017 | Train Accuracy: 100.0 | Test Loss: 0.036344245076179504 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 738 | Train Loss: 0.0338047556579113 | Train Accuracy: 100.0 | Test Loss: 0.036273494362831116 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 739 | Train Loss: 0.033736858516931534 | Train Accuracy: 100.0 | Test Loss: 0.03620319440960884 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 740 | Train Loss: 0.033669210970401764 | Train Accuracy: 100.0 | Test Loss: 0.03613322600722313 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 741 | Train Loss: 0.03360181301832199 | Train Accuracy: 100.0 | Test Loss: 0.03606369346380234 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 742 | Train Loss: 0.03353464975953102 | Train Accuracy: 100.0 | Test Loss: 0.0359942764043808 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 743 | Train Loss: 0.033467743545770645 | Train Accuracy: 100.0 | Test Loss: 0.03592550754547119 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 744 | Train Loss: 0.033401068300008774 | Train Accuracy: 100.0 | Test Loss: 0.035857729613780975 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 745 | Train Loss: 0.033334627747535706 | Train Accuracy: 100.0 | Test Loss: 0.03578959405422211 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 746 | Train Loss: 0.03326844424009323 | Train Accuracy: 100.0 | Test Loss: 0.035721659660339355 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 747 | Train Loss: 0.03320249170064926 | Train Accuracy: 100.0 | Test Loss: 0.035653840750455856 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 748 | Train Loss: 0.03313678130507469 | Train Accuracy: 100.0 | Test Loss: 0.03558627516031265 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 749 | Train Loss: 0.03307131305336952 | Train Accuracy: 100.0 | Test Loss: 0.03551890701055527 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 750 | Train Loss: 0.03300606831908226 | Train Accuracy: 100.0 | Test Loss: 0.03545178845524788 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 751 | Train Loss: 0.0329410657286644 | Train Accuracy: 100.0 | Test Loss: 0.03538491949439049 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 752 | Train Loss: 0.03287629410624504 | Train Accuracy: 100.0 | Test Loss: 0.035318270325660706 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 753 | Train Loss: 0.03281176835298538 | Train Accuracy: 100.0 | Test Loss: 0.03525131195783615 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 754 | Train Loss: 0.03274748846888542 | Train Accuracy: 100.0 | Test Loss: 0.035184916108846664 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 755 | Train Loss: 0.03268343210220337 | Train Accuracy: 100.0 | Test Loss: 0.035118892788887024 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 756 | Train Loss: 0.03261961042881012 | Train Accuracy: 100.0 | Test Loss: 0.03505343943834305 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 757 | Train Loss: 0.03255601227283478 | Train Accuracy: 100.0 | Test Loss: 0.034988079220056534 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 758 | Train Loss: 0.03249265253543854 | Train Accuracy: 100.0 | Test Loss: 0.034922998398542404 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 759 | Train Loss: 0.03242950513958931 | Train Accuracy: 100.0 | Test Loss: 0.03485811501741409 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 760 | Train Loss: 0.03236658498644829 | Train Accuracy: 100.0 | Test Loss: 0.03479347378015518 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 761 | Train Loss: 0.03230386972427368 | Train Accuracy: 100.0 | Test Loss: 0.034729085862636566 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 762 | Train Loss: 0.03224139288067818 | Train Accuracy: 100.0 | Test Loss: 0.03466492146253586 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 763 | Train Loss: 0.03217913210391998 | Train Accuracy: 100.0 | Test Loss: 0.034600984305143356 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 764 | Train Loss: 0.0321170799434185 | Train Accuracy: 100.0 | Test Loss: 0.03453625738620758 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 765 | Train Loss: 0.032055266201496124 | Train Accuracy: 100.0 | Test Loss: 0.03447241336107254 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 766 | Train Loss: 0.03199366480112076 | Train Accuracy: 100.0 | Test Loss: 0.03440885990858078 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 767 | Train Loss: 0.0319322906434536 | Train Accuracy: 100.0 | Test Loss: 0.03434576094150543 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 768 | Train Loss: 0.03187112137675285 | Train Accuracy: 100.0 | Test Loss: 0.0342828705906868 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 769 | Train Loss: 0.03181018307805061 | Train Accuracy: 100.0 | Test Loss: 0.03422022983431816 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 770 | Train Loss: 0.03174943849444389 | Train Accuracy: 100.0 | Test Loss: 0.03415779396891594 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 771 | Train Loss: 0.03168889880180359 | Train Accuracy: 100.0 | Test Loss: 0.03409559652209282 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 772 | Train Loss: 0.031628627330064774 | Train Accuracy: 100.0 | Test Loss: 0.0340329147875309 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 773 | Train Loss: 0.03156871348619461 | Train Accuracy: 100.0 | Test Loss: 0.03397126495838165 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 774 | Train Loss: 0.03150900825858116 | Train Accuracy: 100.0 | Test Loss: 0.03391006216406822 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 775 | Train Loss: 0.03144949674606323 | Train Accuracy: 100.0 | Test Loss: 0.03384910523891449 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 776 | Train Loss: 0.031390201300382614 | Train Accuracy: 100.0 | Test Loss: 0.03378838300704956 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 777 | Train Loss: 0.03133111074566841 | Train Accuracy: 100.0 | Test Loss: 0.03372718766331673 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 778 | Train Loss: 0.03127221018075943 | Train Accuracy: 100.0 | Test Loss: 0.0336664579808712 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 779 | Train Loss: 0.031213531270623207 | Train Accuracy: 100.0 | Test Loss: 0.03360617533326149 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 780 | Train Loss: 0.031155042350292206 | Train Accuracy: 100.0 | Test Loss: 0.03354618325829506 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 781 | Train Loss: 0.03109675645828247 | Train Accuracy: 100.0 | Test Loss: 0.03348647430539131 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 782 | Train Loss: 0.031038669869303703 | Train Accuracy: 100.0 | Test Loss: 0.03342697396874428 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 783 | Train Loss: 0.030980776995420456 | Train Accuracy: 100.0 | Test Loss: 0.03336770087480545 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 784 | Train Loss: 0.03092307038605213 | Train Accuracy: 100.0 | Test Loss: 0.033308617770671844 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 785 | Train Loss: 0.030865570530295372 | Train Accuracy: 100.0 | Test Loss: 0.03324975445866585 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 786 | Train Loss: 0.03080827184021473 | Train Accuracy: 100.0 | Test Loss: 0.03319104388356209 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 787 | Train Loss: 0.03075115568935871 | Train Accuracy: 100.0 | Test Loss: 0.033133164048194885 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 788 | Train Loss: 0.03069423697888851 | Train Accuracy: 100.0 | Test Loss: 0.03307504206895828 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 789 | Train Loss: 0.030637502670288086 | Train Accuracy: 100.0 | Test Loss: 0.03301740065217018 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 790 | Train Loss: 0.03058091551065445 | Train Accuracy: 100.0 | Test Loss: 0.0329597033560276 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 791 | Train Loss: 0.030524520203471184 | Train Accuracy: 100.0 | Test Loss: 0.032902155071496964 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 792 | Train Loss: 0.03046831488609314 | Train Accuracy: 100.0 | Test Loss: 0.03284476324915886 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 793 | Train Loss: 0.03041229210793972 | Train Accuracy: 100.0 | Test Loss: 0.03278754651546478 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 794 | Train Loss: 0.030356459319591522 | Train Accuracy: 100.0 | Test Loss: 0.032730527222156525 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 795 | Train Loss: 0.030300822108983994 | Train Accuracy: 100.0 | Test Loss: 0.03267379105091095 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 796 | Train Loss: 0.030245356261730194 | Train Accuracy: 100.0 | Test Loss: 0.032617196440696716 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 797 | Train Loss: 0.030190080404281616 | Train Accuracy: 100.0 | Test Loss: 0.03256076201796532 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 798 | Train Loss: 0.03013499267399311 | Train Accuracy: 100.0 | Test Loss: 0.032504674047231674 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 799 | Train Loss: 0.03008008375763893 | Train Accuracy: 100.0 | Test Loss: 0.03244873136281967 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 800 | Train Loss: 0.030025357380509377 | Train Accuracy: 100.0 | Test Loss: 0.032392870634794235 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 801 | Train Loss: 0.029970817267894745 | Train Accuracy: 100.0 | Test Loss: 0.03233742713928223 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 802 | Train Loss: 0.029916461557149887 | Train Accuracy: 100.0 | Test Loss: 0.03228211775422096 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 803 | Train Loss: 0.029862279072403908 | Train Accuracy: 100.0 | Test Loss: 0.03222696855664253 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 804 | Train Loss: 0.029808295890688896 | Train Accuracy: 100.0 | Test Loss: 0.032171979546546936 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 805 | Train Loss: 0.02975446544587612 | Train Accuracy: 100.0 | Test Loss: 0.032117169350385666 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 806 | Train Loss: 0.02970082499086857 | Train Accuracy: 100.0 | Test Loss: 0.03206252679228783 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 807 | Train Loss: 0.029647307470440865 | Train Accuracy: 100.0 | Test Loss: 0.03200875222682953 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 808 | Train Loss: 0.029593847692012787 | Train Accuracy: 100.0 | Test Loss: 0.03195464611053467 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 809 | Train Loss: 0.029540561139583588 | Train Accuracy: 100.0 | Test Loss: 0.031900566071271896 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 810 | Train Loss: 0.029487453401088715 | Train Accuracy: 100.0 | Test Loss: 0.0318465493619442 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 811 | Train Loss: 0.02943452261388302 | Train Accuracy: 100.0 | Test Loss: 0.03179354593157768 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 812 | Train Loss: 0.029381774365901947 | Train Accuracy: 100.0 | Test Loss: 0.03174009174108505 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 813 | Train Loss: 0.029329197481274605 | Train Accuracy: 100.0 | Test Loss: 0.031688351184129715 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 814 | Train Loss: 0.029276814311742783 | Train Accuracy: 100.0 | Test Loss: 0.031636081635951996 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 815 | Train Loss: 0.029224595054984093 | Train Accuracy: 100.0 | Test Loss: 0.03158382698893547 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 816 | Train Loss: 0.029172562062740326 | Train Accuracy: 100.0 | Test Loss: 0.03153092786669731 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 817 | Train Loss: 0.02912082150578499 | Train Accuracy: 100.0 | Test Loss: 0.031478628516197205 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 818 | Train Loss: 0.029069244861602783 | Train Accuracy: 100.0 | Test Loss: 0.03142639622092247 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 819 | Train Loss: 0.02901780791580677 | Train Accuracy: 100.0 | Test Loss: 0.03137451037764549 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 820 | Train Loss: 0.028966540470719337 | Train Accuracy: 100.0 | Test Loss: 0.031322795897722244 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 821 | Train Loss: 0.02891543321311474 | Train Accuracy: 100.0 | Test Loss: 0.03127126768231392 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 822 | Train Loss: 0.028864488005638123 | Train Accuracy: 100.0 | Test Loss: 0.03121992014348507 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 823 | Train Loss: 0.028813712298870087 | Train Accuracy: 100.0 | Test Loss: 0.031168732792139053 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 824 | Train Loss: 0.028763100504875183 | Train Accuracy: 100.0 | Test Loss: 0.031117266044020653 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 825 | Train Loss: 0.028712648898363113 | Train Accuracy: 100.0 | Test Loss: 0.031066348776221275 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 826 | Train Loss: 0.028662366792559624 | Train Accuracy: 100.0 | Test Loss: 0.031015601009130478 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 827 | Train Loss: 0.028612256050109863 | Train Accuracy: 100.0 | Test Loss: 0.030965080484747887 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 828 | Train Loss: 0.028562292456626892 | Train Accuracy: 100.0 | Test Loss: 0.03091462142765522 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 829 | Train Loss: 0.0285124983638525 | Train Accuracy: 100.0 | Test Loss: 0.030863497406244278 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 830 | Train Loss: 0.028462881222367287 | Train Accuracy: 100.0 | Test Loss: 0.030813068151474 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 831 | Train Loss: 0.02841341122984886 | Train Accuracy: 100.0 | Test Loss: 0.030762886628508568 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 832 | Train Loss: 0.02836410515010357 | Train Accuracy: 100.0 | Test Loss: 0.03071296587586403 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 833 | Train Loss: 0.028314955532550812 | Train Accuracy: 100.0 | Test Loss: 0.03066321834921837 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 834 | Train Loss: 0.028265956789255142 | Train Accuracy: 100.0 | Test Loss: 0.03061363659799099 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 835 | Train Loss: 0.028217114508152008 | Train Accuracy: 100.0 | Test Loss: 0.030564026907086372 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 836 | Train Loss: 0.02816843055188656 | Train Accuracy: 100.0 | Test Loss: 0.03051469288766384 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 837 | Train Loss: 0.0281198900192976 | Train Accuracy: 100.0 | Test Loss: 0.030465569347143173 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 838 | Train Loss: 0.02807151898741722 | Train Accuracy: 100.0 | Test Loss: 0.03041660413146019 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 839 | Train Loss: 0.028023289516568184 | Train Accuracy: 100.0 | Test Loss: 0.03036779724061489 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 840 | Train Loss: 0.027975205332040787 | Train Accuracy: 100.0 | Test Loss: 0.030318608507514 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 841 | Train Loss: 0.02792728878557682 | Train Accuracy: 100.0 | Test Loss: 0.030269745737314224 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 842 | Train Loss: 0.0278795026242733 | Train Accuracy: 100.0 | Test Loss: 0.030221257358789444 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 843 | Train Loss: 0.02783188223838806 | Train Accuracy: 100.0 | Test Loss: 0.03017309680581093 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 844 | Train Loss: 0.02778441645205021 | Train Accuracy: 100.0 | Test Loss: 0.030124898999929428 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 845 | Train Loss: 0.027737097814679146 | Train Accuracy: 100.0 | Test Loss: 0.030077099800109863 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 846 | Train Loss: 0.02768992818892002 | Train Accuracy: 100.0 | Test Loss: 0.03002927079796791 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 847 | Train Loss: 0.027642907574772835 | Train Accuracy: 100.0 | Test Loss: 0.029981669038534164 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 848 | Train Loss: 0.027596034109592438 | Train Accuracy: 100.0 | Test Loss: 0.02993406169116497 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 849 | Train Loss: 0.02754930593073368 | Train Accuracy: 100.0 | Test Loss: 0.02988693118095398 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 850 | Train Loss: 0.02750273235142231 | Train Accuracy: 100.0 | Test Loss: 0.02983999252319336 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 851 | Train Loss: 0.027456287294626236 | Train Accuracy: 100.0 | Test Loss: 0.029792899265885353 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 852 | Train Loss: 0.0274099912494421 | Train Accuracy: 100.0 | Test Loss: 0.029745982959866524 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 853 | Train Loss: 0.027363844215869904 | Train Accuracy: 100.0 | Test Loss: 0.029699089005589485 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 854 | Train Loss: 0.027317840605974197 | Train Accuracy: 100.0 | Test Loss: 0.02965254709124565 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 855 | Train Loss: 0.027271965518593788 | Train Accuracy: 100.0 | Test Loss: 0.029605984687805176 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 856 | Train Loss: 0.027226243168115616 | Train Accuracy: 100.0 | Test Loss: 0.029559649527072906 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 857 | Train Loss: 0.027180645614862442 | Train Accuracy: 100.0 | Test Loss: 0.02951345406472683 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 858 | Train Loss: 0.02713521011173725 | Train Accuracy: 100.0 | Test Loss: 0.029467320069670677 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 859 | Train Loss: 0.02708989754319191 | Train Accuracy: 100.0 | Test Loss: 0.029421530663967133 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 860 | Train Loss: 0.02704472467303276 | Train Accuracy: 100.0 | Test Loss: 0.029375292360782623 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 861 | Train Loss: 0.026999706402420998 | Train Accuracy: 100.0 | Test Loss: 0.029329422861337662 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 862 | Train Loss: 0.026954809203743935 | Train Accuracy: 100.0 | Test Loss: 0.029283851385116577 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 863 | Train Loss: 0.02691005729138851 | Train Accuracy: 100.0 | Test Loss: 0.02923845686018467 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 864 | Train Loss: 0.026865433901548386 | Train Accuracy: 100.0 | Test Loss: 0.02919314242899418 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 865 | Train Loss: 0.026820944622159004 | Train Accuracy: 100.0 | Test Loss: 0.029148243367671967 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 866 | Train Loss: 0.026776589453220367 | Train Accuracy: 100.0 | Test Loss: 0.029103316366672516 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 867 | Train Loss: 0.026732372120022774 | Train Accuracy: 100.0 | Test Loss: 0.02905859239399433 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 868 | Train Loss: 0.026688294485211372 | Train Accuracy: 100.0 | Test Loss: 0.029013987630605698 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 869 | Train Loss: 0.02664434351027012 | Train Accuracy: 100.0 | Test Loss: 0.028969531878829002 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 870 | Train Loss: 0.02660052478313446 | Train Accuracy: 100.0 | Test Loss: 0.028925219550728798 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 871 | Train Loss: 0.026556845754384995 | Train Accuracy: 100.0 | Test Loss: 0.02888103388249874 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 872 | Train Loss: 0.026513295248150826 | Train Accuracy: 100.0 | Test Loss: 0.028836984187364578 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 873 | Train Loss: 0.026469862088561058 | Train Accuracy: 100.0 | Test Loss: 0.02879304252564907 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 874 | Train Loss: 0.02642657235264778 | Train Accuracy: 100.0 | Test Loss: 0.028749283403158188 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 875 | Train Loss: 0.026383409276604652 | Train Accuracy: 100.0 | Test Loss: 0.02870565839111805 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 876 | Train Loss: 0.02634037472307682 | Train Accuracy: 100.0 | Test Loss: 0.028662171214818954 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 877 | Train Loss: 0.026297468692064285 | Train Accuracy: 100.0 | Test Loss: 0.0286188255995512 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 878 | Train Loss: 0.026254691183567047 | Train Accuracy: 100.0 | Test Loss: 0.02857552468776703 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 879 | Train Loss: 0.026212038472294807 | Train Accuracy: 100.0 | Test Loss: 0.028532564640045166 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 880 | Train Loss: 0.026169518008828163 | Train Accuracy: 100.0 | Test Loss: 0.02848958969116211 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 881 | Train Loss: 0.026127122342586517 | Train Accuracy: 100.0 | Test Loss: 0.028446784242987633 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 882 | Train Loss: 0.02608485147356987 | Train Accuracy: 100.0 | Test Loss: 0.02840408682823181 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 883 | Train Loss: 0.026042712852358818 | Train Accuracy: 100.0 | Test Loss: 0.028361499309539795 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 884 | Train Loss: 0.026000697165727615 | Train Accuracy: 100.0 | Test Loss: 0.028319090604782104 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 885 | Train Loss: 0.02595881186425686 | Train Accuracy: 100.0 | Test Loss: 0.028276881203055382 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 886 | Train Loss: 0.02591705322265625 | Train Accuracy: 100.0 | Test Loss: 0.028234809637069702 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 887 | Train Loss: 0.025875424966216087 | Train Accuracy: 100.0 | Test Loss: 0.028192780911922455 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 888 | Train Loss: 0.025833912193775177 | Train Accuracy: 100.0 | Test Loss: 0.028150901198387146 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 889 | Train Loss: 0.025792526081204414 | Train Accuracy: 100.0 | Test Loss: 0.028109168633818626 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 890 | Train Loss: 0.025751261040568352 | Train Accuracy: 100.0 | Test Loss: 0.028067564591765404 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 891 | Train Loss: 0.02571011334657669 | Train Accuracy: 100.0 | Test Loss: 0.028026064857840538 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 892 | Train Loss: 0.025669092312455177 | Train Accuracy: 100.0 | Test Loss: 0.027984723448753357 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 893 | Train Loss: 0.025628183037042618 | Train Accuracy: 100.0 | Test Loss: 0.027943486347794533 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 894 | Train Loss: 0.025587400421500206 | Train Accuracy: 100.0 | Test Loss: 0.02790239080786705 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 895 | Train Loss: 0.025546729564666748 | Train Accuracy: 100.0 | Test Loss: 0.02786140888929367 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 896 | Train Loss: 0.025506190955638885 | Train Accuracy: 100.0 | Test Loss: 0.0278205294162035 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 897 | Train Loss: 0.025465765967965126 | Train Accuracy: 100.0 | Test Loss: 0.027779344469308853 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 898 | Train Loss: 0.025425462052226067 | Train Accuracy: 100.0 | Test Loss: 0.027739038690924644 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 899 | Train Loss: 0.02538527362048626 | Train Accuracy: 100.0 | Test Loss: 0.027698349207639694 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 900 | Train Loss: 0.025345202535390854 | Train Accuracy: 100.0 | Test Loss: 0.027657905593514442 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 901 | Train Loss: 0.025305250659585 | Train Accuracy: 100.0 | Test Loss: 0.02761821635067463 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 902 | Train Loss: 0.025265416130423546 | Train Accuracy: 100.0 | Test Loss: 0.027577906847000122 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 903 | Train Loss: 0.025225691497325897 | Train Accuracy: 100.0 | Test Loss: 0.02753782458603382 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 904 | Train Loss: 0.02518608421087265 | Train Accuracy: 100.0 | Test Loss: 0.027498025447130203 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 905 | Train Loss: 0.025146596133708954 | Train Accuracy: 100.0 | Test Loss: 0.027458345517516136 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 906 | Train Loss: 0.025107214227318764 | Train Accuracy: 100.0 | Test Loss: 0.027419202029705048 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 907 | Train Loss: 0.025067945942282677 | Train Accuracy: 100.0 | Test Loss: 0.027379440143704414 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 908 | Train Loss: 0.02502880059182644 | Train Accuracy: 100.0 | Test Loss: 0.02733985334634781 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 909 | Train Loss: 0.02498975768685341 | Train Accuracy: 100.0 | Test Loss: 0.027300549671053886 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 910 | Train Loss: 0.024950822815299034 | Train Accuracy: 100.0 | Test Loss: 0.027261370792984962 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 911 | Train Loss: 0.02491200715303421 | Train Accuracy: 100.0 | Test Loss: 0.027222326025366783 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 912 | Train Loss: 0.02487330138683319 | Train Accuracy: 100.0 | Test Loss: 0.02718336507678032 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 913 | Train Loss: 0.024834703654050827 | Train Accuracy: 100.0 | Test Loss: 0.027144527062773705 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 914 | Train Loss: 0.024796223267912865 | Train Accuracy: 100.0 | Test Loss: 0.02710620127618313 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 915 | Train Loss: 0.02475784160196781 | Train Accuracy: 100.0 | Test Loss: 0.027067257091403008 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 916 | Train Loss: 0.02471958100795746 | Train Accuracy: 100.0 | Test Loss: 0.027028478682041168 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 917 | Train Loss: 0.024681424722075462 | Train Accuracy: 100.0 | Test Loss: 0.02698998712003231 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 918 | Train Loss: 0.024643372744321823 | Train Accuracy: 100.0 | Test Loss: 0.0269516222178936 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 919 | Train Loss: 0.024605436250567436 | Train Accuracy: 100.0 | Test Loss: 0.026913395151495934 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 920 | Train Loss: 0.024567604064941406 | Train Accuracy: 100.0 | Test Loss: 0.02687527798116207 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 921 | Train Loss: 0.024529870599508286 | Train Accuracy: 100.0 | Test Loss: 0.026837263256311417 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 922 | Train Loss: 0.024492258206009865 | Train Accuracy: 100.0 | Test Loss: 0.026798633858561516 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 923 | Train Loss: 0.024454740807414055 | Train Accuracy: 100.0 | Test Loss: 0.02676059678196907 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 924 | Train Loss: 0.024417342618107796 | Train Accuracy: 100.0 | Test Loss: 0.02672269195318222 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 925 | Train Loss: 0.024380046874284744 | Train Accuracy: 100.0 | Test Loss: 0.02668500691652298 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 926 | Train Loss: 0.024342846125364304 | Train Accuracy: 100.0 | Test Loss: 0.026647444814443588 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 927 | Train Loss: 0.02430574782192707 | Train Accuracy: 100.0 | Test Loss: 0.026610007509589195 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 928 | Train Loss: 0.024268772453069687 | Train Accuracy: 100.0 | Test Loss: 0.02657267265021801 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 929 | Train Loss: 0.024231918156147003 | Train Accuracy: 100.0 | Test Loss: 0.02653728425502777 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 930 | Train Loss: 0.024195261299610138 | Train Accuracy: 100.0 | Test Loss: 0.02649872563779354 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 931 | Train Loss: 0.024158593267202377 | Train Accuracy: 100.0 | Test Loss: 0.026463279500603676 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 932 | Train Loss: 0.024122152477502823 | Train Accuracy: 100.0 | Test Loss: 0.02642458863556385 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 933 | Train Loss: 0.024085674434900284 | Train Accuracy: 100.0 | Test Loss: 0.02638760209083557 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 934 | Train Loss: 0.024049414321780205 | Train Accuracy: 100.0 | Test Loss: 0.026352591812610626 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 935 | Train Loss: 0.024013128131628036 | Train Accuracy: 100.0 | Test Loss: 0.026314467191696167 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 936 | Train Loss: 0.023977059870958328 | Train Accuracy: 100.0 | Test Loss: 0.026279350742697716 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 937 | Train Loss: 0.02394099347293377 | Train Accuracy: 100.0 | Test Loss: 0.026240935549139977 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 938 | Train Loss: 0.023905092850327492 | Train Accuracy: 100.0 | Test Loss: 0.026206182315945625 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 939 | Train Loss: 0.02386919967830181 | Train Accuracy: 100.0 | Test Loss: 0.0261679794639349 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 940 | Train Loss: 0.02383347973227501 | Train Accuracy: 100.0 | Test Loss: 0.026133069768548012 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 941 | Train Loss: 0.0237977746874094 | Train Accuracy: 100.0 | Test Loss: 0.026094907894730568 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 942 | Train Loss: 0.02376224286854267 | Train Accuracy: 100.0 | Test Loss: 0.026060141623020172 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 943 | Train Loss: 0.023726746439933777 | Train Accuracy: 100.0 | Test Loss: 0.026022132486104965 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 944 | Train Loss: 0.023691415786743164 | Train Accuracy: 100.0 | Test Loss: 0.025987517088651657 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 945 | Train Loss: 0.02365611493587494 | Train Accuracy: 100.0 | Test Loss: 0.025949696078896523 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 946 | Train Loss: 0.02362096682190895 | Train Accuracy: 100.0 | Test Loss: 0.025915231555700302 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 947 | Train Loss: 0.023585867136716843 | Train Accuracy: 100.0 | Test Loss: 0.025877613574266434 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 948 | Train Loss: 0.02355092018842697 | Train Accuracy: 100.0 | Test Loss: 0.02584335207939148 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 949 | Train Loss: 0.023516006767749786 | Train Accuracy: 100.0 | Test Loss: 0.025805899873375893 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 950 | Train Loss: 0.02348124422132969 | Train Accuracy: 100.0 | Test Loss: 0.025772111490368843 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 951 | Train Loss: 0.02344653010368347 | Train Accuracy: 100.0 | Test Loss: 0.025734614580869675 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 952 | Train Loss: 0.02341196872293949 | Train Accuracy: 100.0 | Test Loss: 0.025700723752379417 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 953 | Train Loss: 0.02337743155658245 | Train Accuracy: 100.0 | Test Loss: 0.025663521140813828 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 954 | Train Loss: 0.023343060165643692 | Train Accuracy: 100.0 | Test Loss: 0.025630269199609756 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 955 | Train Loss: 0.02330872230231762 | Train Accuracy: 100.0 | Test Loss: 0.02559301257133484 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 956 | Train Loss: 0.023274540901184082 | Train Accuracy: 100.0 | Test Loss: 0.02555980160832405 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 957 | Train Loss: 0.02324037067592144 | Train Accuracy: 100.0 | Test Loss: 0.025522857904434204 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 958 | Train Loss: 0.02320639044046402 | Train Accuracy: 100.0 | Test Loss: 0.02548985369503498 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 959 | Train Loss: 0.0231724064797163 | Train Accuracy: 100.0 | Test Loss: 0.025453371927142143 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 960 | Train Loss: 0.023138608783483505 | Train Accuracy: 100.0 | Test Loss: 0.025420300662517548 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 961 | Train Loss: 0.023104794323444366 | Train Accuracy: 100.0 | Test Loss: 0.02538374625146389 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 962 | Train Loss: 0.02307119406759739 | Train Accuracy: 100.0 | Test Loss: 0.02535109408199787 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 963 | Train Loss: 0.023037560284137726 | Train Accuracy: 100.0 | Test Loss: 0.025314735248684883 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 964 | Train Loss: 0.023004135116934776 | Train Accuracy: 100.0 | Test Loss: 0.025282330811023712 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 965 | Train Loss: 0.02297068014740944 | Train Accuracy: 100.0 | Test Loss: 0.025248251855373383 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 966 | Train Loss: 0.02293745055794716 | Train Accuracy: 100.0 | Test Loss: 0.02521250955760479 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 967 | Train Loss: 0.022904178127646446 | Train Accuracy: 100.0 | Test Loss: 0.025179820135235786 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 968 | Train Loss: 0.022871101275086403 | Train Accuracy: 100.0 | Test Loss: 0.02514391392469406 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 969 | Train Loss: 0.022838030010461807 | Train Accuracy: 100.0 | Test Loss: 0.025111841037869453 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 970 | Train Loss: 0.022805118933320045 | Train Accuracy: 100.0 | Test Loss: 0.025076188147068024 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 971 | Train Loss: 0.02277223952114582 | Train Accuracy: 100.0 | Test Loss: 0.025044111534953117 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 972 | Train Loss: 0.022739488631486893 | Train Accuracy: 100.0 | Test Loss: 0.025008542463183403 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 973 | Train Loss: 0.02270679734647274 | Train Accuracy: 100.0 | Test Loss: 0.024976927787065506 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 974 | Train Loss: 0.022674206644296646 | Train Accuracy: 100.0 | Test Loss: 0.024941591545939445 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 975 | Train Loss: 0.02264171466231346 | Train Accuracy: 100.0 | Test Loss: 0.02491018734872341 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 976 | Train Loss: 0.02260926179587841 | Train Accuracy: 100.0 | Test Loss: 0.02487531676888466 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 977 | Train Loss: 0.022576961666345596 | Train Accuracy: 100.0 | Test Loss: 0.02484387345612049 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 978 | Train Loss: 0.02254466898739338 | Train Accuracy: 100.0 | Test Loss: 0.024808937683701515 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 979 | Train Loss: 0.022512564435601234 | Train Accuracy: 100.0 | Test Loss: 0.024777915328741074 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 980 | Train Loss: 0.022480428218841553 | Train Accuracy: 100.0 | Test Loss: 0.024743428453803062 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 981 | Train Loss: 0.022448504343628883 | Train Accuracy: 100.0 | Test Loss: 0.024712366983294487 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 982 | Train Loss: 0.022416528314352036 | Train Accuracy: 100.0 | Test Loss: 0.02467959374189377 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 983 | Train Loss: 0.0223847646266222 | Train Accuracy: 100.0 | Test Loss: 0.024645699188113213 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 984 | Train Loss: 0.022352978587150574 | Train Accuracy: 100.0 | Test Loss: 0.024614615365862846 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 985 | Train Loss: 0.02232135646045208 | Train Accuracy: 100.0 | Test Loss: 0.0245803352445364 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 986 | Train Loss: 0.022289765998721123 | Train Accuracy: 100.0 | Test Loss: 0.02454986982047558 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 987 | Train Loss: 0.022258277982473373 | Train Accuracy: 100.0 | Test Loss: 0.024516010656952858 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 988 | Train Loss: 0.022226881235837936 | Train Accuracy: 100.0 | Test Loss: 0.024485548958182335 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 989 | Train Loss: 0.02219552919268608 | Train Accuracy: 100.0 | Test Loss: 0.024451633915305138 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 990 | Train Loss: 0.022164320573210716 | Train Accuracy: 100.0 | Test Loss: 0.024421708658337593 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 991 | Train Loss: 0.02213311567902565 | Train Accuracy: 100.0 | Test Loss: 0.024387892335653305 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 992 | Train Loss: 0.022102097049355507 | Train Accuracy: 100.0 | Test Loss: 0.02435818687081337 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 993 | Train Loss: 0.022071031853556633 | Train Accuracy: 100.0 | Test Loss: 0.02432655543088913 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 994 | Train Loss: 0.022040165960788727 | Train Accuracy: 100.0 | Test Loss: 0.02429341711103916 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 995 | Train Loss: 0.022009292617440224 | Train Accuracy: 100.0 | Test Loss: 0.024263428524136543 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 996 | Train Loss: 0.02197856828570366 | Train Accuracy: 100.0 | Test Loss: 0.024230124428868294 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 997 | Train Loss: 0.021947873756289482 | Train Accuracy: 100.0 | Test Loss: 0.02420061081647873 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 998 | Train Loss: 0.021917276084423065 | Train Accuracy: 100.0 | Test Loss: 0.024167517200112343 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Epoch: 999 | Train Loss: 0.02188676968216896 | Train Accuracy: 100.0 | Test Loss: 0.024138247594237328 | Test Accuracy: 100.0\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACsJJVvCX0Sb",
        "outputId": "a859b17b-d78c-4375-fce9-44de1765ef02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 406,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 420,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 431,\n",
              " 432,\n",
              " 433,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 439,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 458,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 464,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 472,\n",
              " 473,\n",
              " 474,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 479,\n",
              " 480,\n",
              " 481,\n",
              " 482,\n",
              " 483,\n",
              " 484,\n",
              " 485,\n",
              " 486,\n",
              " 487,\n",
              " 488,\n",
              " 489,\n",
              " 490,\n",
              " 491,\n",
              " 492,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 498,\n",
              " 499,\n",
              " 500,\n",
              " 501,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 505,\n",
              " 506,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 521,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 531,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 536,\n",
              " 537,\n",
              " 538,\n",
              " 539,\n",
              " 540,\n",
              " 541,\n",
              " 542,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 549,\n",
              " 550,\n",
              " 551,\n",
              " 552,\n",
              " 553,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 561,\n",
              " 562,\n",
              " 563,\n",
              " 564,\n",
              " 565,\n",
              " 566,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 576,\n",
              " 577,\n",
              " 578,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 582,\n",
              " 583,\n",
              " 584,\n",
              " 585,\n",
              " 586,\n",
              " 587,\n",
              " 588,\n",
              " 589,\n",
              " 590,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 600,\n",
              " 601,\n",
              " 602,\n",
              " 603,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 607,\n",
              " 608,\n",
              " 609,\n",
              " 610,\n",
              " 611,\n",
              " 612,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 617,\n",
              " 618,\n",
              " 619,\n",
              " 620,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 624,\n",
              " 625,\n",
              " 626,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 630,\n",
              " 631,\n",
              " 632,\n",
              " 633,\n",
              " 634,\n",
              " 635,\n",
              " 636,\n",
              " 637,\n",
              " 638,\n",
              " 639,\n",
              " 640,\n",
              " 641,\n",
              " 642,\n",
              " 643,\n",
              " 644,\n",
              " 645,\n",
              " 646,\n",
              " 647,\n",
              " 648,\n",
              " 649,\n",
              " 650,\n",
              " 651,\n",
              " 652,\n",
              " 653,\n",
              " 654,\n",
              " 655,\n",
              " 656,\n",
              " 657,\n",
              " 658,\n",
              " 659,\n",
              " 660,\n",
              " 661,\n",
              " 662,\n",
              " 663,\n",
              " 664,\n",
              " 665,\n",
              " 666,\n",
              " 667,\n",
              " 668,\n",
              " 669,\n",
              " 670,\n",
              " 671,\n",
              " 672,\n",
              " 673,\n",
              " 674,\n",
              " 675,\n",
              " 676,\n",
              " 677,\n",
              " 678,\n",
              " 679,\n",
              " 680,\n",
              " 681,\n",
              " 682,\n",
              " 683,\n",
              " 684,\n",
              " 685,\n",
              " 686,\n",
              " 687,\n",
              " 688,\n",
              " 689,\n",
              " 690,\n",
              " 691,\n",
              " 692,\n",
              " 693,\n",
              " 694,\n",
              " 695,\n",
              " 696,\n",
              " 697,\n",
              " 698,\n",
              " 699,\n",
              " 700,\n",
              " 701,\n",
              " 702,\n",
              " 703,\n",
              " 704,\n",
              " 705,\n",
              " 706,\n",
              " 707,\n",
              " 708,\n",
              " 709,\n",
              " 710,\n",
              " 711,\n",
              " 712,\n",
              " 713,\n",
              " 714,\n",
              " 715,\n",
              " 716,\n",
              " 717,\n",
              " 718,\n",
              " 719,\n",
              " 720,\n",
              " 721,\n",
              " 722,\n",
              " 723,\n",
              " 724,\n",
              " 725,\n",
              " 726,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 732,\n",
              " 733,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 737,\n",
              " 738,\n",
              " 739,\n",
              " 740,\n",
              " 741,\n",
              " 742,\n",
              " 743,\n",
              " 744,\n",
              " 745,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 750,\n",
              " 751,\n",
              " 752,\n",
              " 753,\n",
              " 754,\n",
              " 755,\n",
              " 756,\n",
              " 757,\n",
              " 758,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 762,\n",
              " 763,\n",
              " 764,\n",
              " 765,\n",
              " 766,\n",
              " 767,\n",
              " 768,\n",
              " 769,\n",
              " 770,\n",
              " 771,\n",
              " 772,\n",
              " 773,\n",
              " 774,\n",
              " 775,\n",
              " 776,\n",
              " 777,\n",
              " 778,\n",
              " 779,\n",
              " 780,\n",
              " 781,\n",
              " 782,\n",
              " 783,\n",
              " 784,\n",
              " 785,\n",
              " 786,\n",
              " 787,\n",
              " 788,\n",
              " 789,\n",
              " 790,\n",
              " 791,\n",
              " 792,\n",
              " 793,\n",
              " 794,\n",
              " 795,\n",
              " 796,\n",
              " 797,\n",
              " 798,\n",
              " 799,\n",
              " 800,\n",
              " 801,\n",
              " 802,\n",
              " 803,\n",
              " 804,\n",
              " 805,\n",
              " 806,\n",
              " 807,\n",
              " 808,\n",
              " 809,\n",
              " 810,\n",
              " 811,\n",
              " 812,\n",
              " 813,\n",
              " 814,\n",
              " 815,\n",
              " 816,\n",
              " 817,\n",
              " 818,\n",
              " 819,\n",
              " 820,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 824,\n",
              " 825,\n",
              " 826,\n",
              " 827,\n",
              " 828,\n",
              " 829,\n",
              " 830,\n",
              " 831,\n",
              " 832,\n",
              " 833,\n",
              " 834,\n",
              " 835,\n",
              " 836,\n",
              " 837,\n",
              " 838,\n",
              " 839,\n",
              " 840,\n",
              " 841,\n",
              " 842,\n",
              " 843,\n",
              " 844,\n",
              " 845,\n",
              " 846,\n",
              " 847,\n",
              " 848,\n",
              " 849,\n",
              " 850,\n",
              " 851,\n",
              " 852,\n",
              " 853,\n",
              " 854,\n",
              " 855,\n",
              " 856,\n",
              " 857,\n",
              " 858,\n",
              " 859,\n",
              " 860,\n",
              " 861,\n",
              " 862,\n",
              " 863,\n",
              " 864,\n",
              " 865,\n",
              " 866,\n",
              " 867,\n",
              " 868,\n",
              " 869,\n",
              " 870,\n",
              " 871,\n",
              " 872,\n",
              " 873,\n",
              " 874,\n",
              " 875,\n",
              " 876,\n",
              " 877,\n",
              " 878,\n",
              " 879,\n",
              " 880,\n",
              " 881,\n",
              " 882,\n",
              " 883,\n",
              " 884,\n",
              " 885,\n",
              " 886,\n",
              " 887,\n",
              " 888,\n",
              " 889,\n",
              " 890,\n",
              " 891,\n",
              " 892,\n",
              " 893,\n",
              " 894,\n",
              " 895,\n",
              " 896,\n",
              " 897,\n",
              " 898,\n",
              " 899,\n",
              " 900,\n",
              " 901,\n",
              " 902,\n",
              " 903,\n",
              " 904,\n",
              " 905,\n",
              " 906,\n",
              " 907,\n",
              " 908,\n",
              " 909,\n",
              " 910,\n",
              " 911,\n",
              " 912,\n",
              " 913,\n",
              " 914,\n",
              " 915,\n",
              " 916,\n",
              " 917,\n",
              " 918,\n",
              " 919,\n",
              " 920,\n",
              " 921,\n",
              " 922,\n",
              " 923,\n",
              " 924,\n",
              " 925,\n",
              " 926,\n",
              " 927,\n",
              " 928,\n",
              " 929,\n",
              " 930,\n",
              " 931,\n",
              " 932,\n",
              " 933,\n",
              " 934,\n",
              " 935,\n",
              " 936,\n",
              " 937,\n",
              " 938,\n",
              " 939,\n",
              " 940,\n",
              " 941,\n",
              " 942,\n",
              " 943,\n",
              " 944,\n",
              " 945,\n",
              " 946,\n",
              " 947,\n",
              " 948,\n",
              " 949,\n",
              " 950,\n",
              " 951,\n",
              " 952,\n",
              " 953,\n",
              " 954,\n",
              " 955,\n",
              " 956,\n",
              " 957,\n",
              " 958,\n",
              " 959,\n",
              " 960,\n",
              " 961,\n",
              " 962,\n",
              " 963,\n",
              " 964,\n",
              " 965,\n",
              " 966,\n",
              " 967,\n",
              " 968,\n",
              " 969,\n",
              " 970,\n",
              " 971,\n",
              " 972,\n",
              " 973,\n",
              " 974,\n",
              " 975,\n",
              " 976,\n",
              " 977,\n",
              " 978,\n",
              " 979,\n",
              " 980,\n",
              " 981,\n",
              " 982,\n",
              " 983,\n",
              " 984,\n",
              " 985,\n",
              " 986,\n",
              " 987,\n",
              " 988,\n",
              " 989,\n",
              " 990,\n",
              " 991,\n",
              " 992,\n",
              " 993,\n",
              " 994,\n",
              " 995,\n",
              " 996,\n",
              " 997,\n",
              " 998,\n",
              " 999]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "(epoch_count[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG-n9Mr8WC1E",
        "outputId": "a8a6297a-1ac5-427d-9146-ae003a281445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_values[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RQF4SiTg-Jy",
        "outputId": "d0f22b21-7731-4fbb-d3b9-0fd008fbd446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(0.41622913, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot((epoch_count, float(test_loss_values)) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "dOUrAzD3ZTUH",
        "outputId": "a1e6f2ad-d9cd-4bad-aa1a-a377562ec67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-0d539033e5e9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(epoch_count[2] )"
      ],
      "metadata": {
        "id": "bYa3SKnbZVvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0dedb42-166e-475d-9272-e048c3b20fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_loss_values[2] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmlURHeGxasm",
        "outputId": "e89c9704-2eb6-4169-d6b3-2e3a6fb53336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_values[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p7tNq3nxros",
        "outputId": "5cda8f6a-537a-4833-97fb-df856064dcbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.7012),\n",
              " tensor(0.7004),\n",
              " tensor(0.6996),\n",
              " tensor(0.6989),\n",
              " tensor(0.6983),\n",
              " tensor(0.6976),\n",
              " tensor(0.6971),\n",
              " tensor(0.6966),\n",
              " tensor(0.6961),\n",
              " tensor(0.6956)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BPLk_TJxyUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}